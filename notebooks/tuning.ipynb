{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82aab5fc",
   "metadata": {},
   "source": [
    "## QuestGen-LLM: Fine-Tuning\n",
    "\n",
    "This notebook covers the fine-tuning of various pre-trained _large language models_ (LLMs) on the prepared [\"quest\"](../data/quests_train.json) dataset. Each language model applied is trained and validated on the dataset (with frozen parameters) and the results of these evaluations are compared. The LLMs employed for this application are listed in the following table with their respective parameter count.\n",
    "\n",
    "| S. No. | Large Language Model             | Parameters | Developed By | Notes                                                 |\n",
    "| :----: | :------------------------------- | :--------: | :----------: | :---------------------------------------------------- |\n",
    "|   1.   | GPT-2[^1]                        |    124M    |    OpenAI    | Base model from the GPT-2 family                      |\n",
    "|   2.   | GPT-2 Medium[^2]                 |    355M    |    OpenAI    | Larger variant with improved language modeling        |\n",
    "|   3.   | GPT-2 Large[^3]                  |    774M    |    OpenAI    | Capable of generating more coherent longer text       |\n",
    "|   4.   | Llama-3.2-1B-Instruct[^4] †      |     1B     |     Meta     | Instruction-tuned model for question-answering        |\n",
    "|   5.   | TinyLlama-1.1B-Chat-v1.0[^5] \\*† |    1.1B    |  TinyLlama   | Lightweight chat-tuned model for constrained hardware |\n",
    "\n",
    "> Fine-tuning uses _supervised fine-tuning_\\* (SHF) and _reinforcement learning with human feedback_† (RLHF).\n",
    "\n",
    "<!-- References -->\n",
    "\n",
    "[^1]: https://huggingface.co/openai-community/gpt2\n",
    "[^2]: https://huggingface.co/openai-community/gpt2-medium\n",
    "[^3]: https://huggingface.co/openai-community/gpt2-large\n",
    "[^4]: https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct\n",
    "[^5]: https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7633f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "from typing import Any, Final\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from huggingface_hub import login\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizerFast,\n",
    "    PreTrainedTokenizer,\n",
    "    Trainer,\n",
    "    TrainerCallback,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "from utils.dirpath import get_cache_dirpath, get_target_dirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d946469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HF access token from the environment\n",
    "HF_ACCESS_TOKEN: Final[str] = os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "\n",
    "# Save the HF token to ~/.huggingface/token\n",
    "login(token=HF_ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b883328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map for the model identifiers: (model_key -> model_id)\n",
    "MODEL_IDENTIFIERS: Final[dict[str, str]] = {\n",
    "    \"gpt2\": \"openai-community/gpt2\",\n",
    "    \"gpt2-medium\": \"openai-community/gpt2-medium\",\n",
    "    \"gpt2-large\": \"openai-community/gpt2-large\",\n",
    "    \"llama-3.2-1b-instruct\": \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    \"tinyllama-1.1b-chat\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6fefdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 19954\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2486\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir: Path = get_target_dirpath(\"data\")\n",
    "\n",
    "# Load the quest dataset\n",
    "quest_set: DatasetDict = load_dataset(\n",
    "    \"text\",\n",
    "    data_files={\n",
    "        \"train\": str(data_dir / \"quests_train.txt\"),\n",
    "        \"val\": str(data_dir / \"quests_val.txt\"),\n",
    "        \"test\": str(data_dir / \"quests_test.txt\"),\n",
    "    },\n",
    "    cache_dir=str(data_dir / \".cache\"),\n",
    ")\n",
    "quest_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca1a797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['### Instruction:',\n",
       "  'Generate a video game quest description based on the following structured information.',\n",
       "  '',\n",
       "  '### Input:',\n",
       "  'Quest Name: Perilous Passage',\n",
       "  'Objective: save the Mana Queen',\n",
       "  'First Tasks: go through the gate to the Forsaken Vaults',\n",
       "  'First Task Locations: Forsaken Vaults - a perilous dungeon',\n",
       "  'Quest Giver: NONE - NONE (location: NONE)',\n",
       "  'Reward: NONE -  (amount: 1)',\n",
       "  'Characters: Mana Queen - a good female spirit (location: Forsaken Vaults)',\n",
       "  'Tools: NONE',\n",
       "  'Locations: NONE',\n",
       "  'Items: NONE',\n",
       "  'Enemies: NONE',\n",
       "  'Groups: NONE',\n",
       "  'Title: Torchlight II',\n",
       "  'Motivation: NONE',\n",
       "  '',\n",
       "  '### Response:',\n",
       "  \"The Mana Queen has come and gone Through this gate, she journeyed on. Follow her and pay the cost. Hasten forth, or she'll be lost.\"]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quest_set[\"train\"][:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5335935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Generate a video game quest description based on the following structured information.',\n",
       "  '',\n",
       "  '### Input:',\n",
       "  'Quest Name: A Child in the Lighthouse',\n",
       "  \"Objective: save Ardrouine's little son from worgs\",\n",
       "  'First Tasks: go to the abandoned lighthouse',\n",
       "  'First Task Locations:  - abandoned lighthouse to the northwest',\n",
       "  'Quest Giver: NONE - NONE (location: NONE)',\n",
       "  'Reward:  - coins (amount: 60)',\n",
       "  'Characters: NONE',\n",
       "  'Tools: NONE',\n",
       "  'Locations: NONE',\n",
       "  'Items: NONE',\n",
       "  'Enemies: NONE',\n",
       "  'Groups: NONE',\n",
       "  \"Title: Baldur's Gate\",\n",
       "  'Motivation: NONE',\n",
       "  '',\n",
       "  '### Response:',\n",
       "  \"Please help me, I am just poor Ardrouine! I don't know where else to turn. My little boy was playing in that abandoned lighthouse to the northwest when a pack of worgs surrounded it. Please just turn them back, and I can coax him down. There's not much time! I can pay you 60 coins: this money is all my husband brought back from market this past week. My son's life is worth this and so much more.\",\n",
       "  '']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quest_set[\"val\"][23:44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "188b14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map for the target modules: (model_key -> target_modules)\n",
    "TARGET_MODULES: Final[dict[str, list[str]]] = {\n",
    "    \"gpt2\": [\"c_attn\", \"c_proj\", \"c_fc\"],\n",
    "    \"gpt2-medium\": [\"c_attn\", \"c_proj\", \"c_fc\"],\n",
    "    \"gpt2-large\": [\"c_attn\", \"c_proj\", \"c_fc\"],\n",
    "    \"llama-3.2-1b-instruct\": [\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    \"tinyllama-1.1b-chat\": [\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967a5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the constants for model tuning here\n",
    "MAX_LENGTH: Final[int] = 32\n",
    "BATCH_SIZE: Final[int] = 1\n",
    "N_EPOCHS: Final[int] = 1\n",
    "SEED: Final[int] = 42\n",
    "LR_RATE: Final[float] = 5e-6\n",
    "LOGGING_STEPS: Final[int] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d22831c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QuestGenLLM:\n",
    "    tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast\n",
    "    model: PreTrainedModel\n",
    "    model_key: str  # Alias for the model, e.g, \"gpt2\"\n",
    "    model_id: str  # Hugging Face model name, e.g., \"openai-community/gpt2\"\n",
    "    fp16_available: bool  # Mixed precision\n",
    "    device: str = field(init=False)\n",
    "    dtype: str = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Automatically determine the device used by the model\n",
    "        self.device = str(getattr(self.model, \"device\", \"N/A\"))\n",
    "\n",
    "        # Automatically determine the dtype used by the model\n",
    "        self.dtype = str(getattr(self.model, \"dtype\", \"N/A\")).replace(\"torch.\", \"\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(\n",
    "        cls,\n",
    "        model_key: str,\n",
    "        model_id: str,\n",
    "        cache_dir: PathLike = get_cache_dirpath(\"models\"),\n",
    "        seed: int = SEED,\n",
    "        use_cpu: bool = False,\n",
    "    ) -> QuestGenLLM:\n",
    "        def apply_lora_adapter(\n",
    "            model: PreTrainedModel,\n",
    "            r: int = 8,\n",
    "            alpha: int = 16,\n",
    "            dropout: float = 0.1,\n",
    "            task_type: str = \"CAUSAL_LM\",\n",
    "        ) -> PreTrainedModel:\n",
    "            # Prepare model for k-bit training\n",
    "            model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "            # Define the LoRA config\n",
    "            lora_config: LoraConfig = LoraConfig(\n",
    "                r=r,\n",
    "                lora_alpha=alpha,\n",
    "                lora_dropout=dropout,\n",
    "                target_modules=TARGET_MODULES[model_key],\n",
    "                bias=\"none\",\n",
    "                task_type=task_type,\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                # Apply LoRA adapters to the model\n",
    "                model = get_peft_model(model, lora_config)\n",
    "            except Exception as e:\n",
    "                print(f\"[LoRAINFO] Adapter failed to apply: {e}\")\n",
    "                raise\n",
    "\n",
    "            # Display information about the model parameters\n",
    "            trainable_params: int = sum(\n",
    "                p.numel() for p in model.parameters() if p.requires_grad\n",
    "            )\n",
    "            all_params: int = sum(p.numel() for p in model.parameters())\n",
    "            trainable_percent: float = 100 * trainable_params / all_params\n",
    "            print(\n",
    "                \"[LoRAINFO] trainable params: {:,} || all params: {:,} || trainable%: {:.4f}\".format(\n",
    "                    trainable_params, all_params, trainable_percent\n",
    "                )\n",
    "            )\n",
    "\n",
    "            return model\n",
    "\n",
    "        print(f\"[DOWNLOAD] {model_key} ({model_id})\")\n",
    "        start_time: float = time.time()\n",
    "\n",
    "        # Clear PyTorch's CUDA memory cache\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Set the random seed for reproducibility\n",
    "        set_seed(seed)\n",
    "\n",
    "        # Determine if mixed precision is available\n",
    "        fp16_available: bool = (\n",
    "            torch.cuda.is_available()\n",
    "            and torch.cuda.get_device_capability(0)[0] >= 7\n",
    "            and torch.cuda.get_device_capability(0)[1] >= 0\n",
    "        )\n",
    "\n",
    "        # Download the tokenizer using the model id\n",
    "        tokenizer: PreTrainedTokenizerFast = AutoTokenizer.from_pretrained(\n",
    "            model_id,\n",
    "            cache_dir=(cache_dir / model_key),\n",
    "            use_fast=True,\n",
    "            token=HF_ACCESS_TOKEN,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "        model: PreTrainedModel\n",
    "        if fp16_available and not use_cpu:\n",
    "            # Set the bitsandbytes configuration for quantization\n",
    "            bnb_config: BitsAndBytesConfig = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_use_double_quant=True,\n",
    "                bnb_4bit_compute_dtype=torch.float16,\n",
    "                # llm_int8_enable_fp32_cpu_offload=True,\n",
    "            )\n",
    "\n",
    "            # Download the model using the model id (for GPU)\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_id,\n",
    "                torch_dtype=torch.float16,\n",
    "                quantization_config=bnb_config,\n",
    "                cache_dir=(cache_dir / model_key),\n",
    "                token=HF_ACCESS_TOKEN,\n",
    "                trust_remote_code=True,\n",
    "                low_cpu_mem_usage=True,\n",
    "            )\n",
    "            model.to(\"cuda\")\n",
    "        else:\n",
    "            # Download the model using the model id (for CPU)\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_id,\n",
    "                torch_dtype=torch.float32,\n",
    "                cache_dir=(cache_dir / model_key),\n",
    "                token=HF_ACCESS_TOKEN,\n",
    "                trust_remote_code=True,\n",
    "                low_cpu_mem_usage=True,\n",
    "            )\n",
    "            model.to(\"cpu\")\n",
    "\n",
    "        # Apply the LoRA adapters to the model\n",
    "        model = apply_lora_adapter(model)\n",
    "\n",
    "        end_time: float = time.time()\n",
    "        elapsed: float = end_time - start_time\n",
    "        print(f'[COMPLETE] \"{model_key}\" ready in {elapsed:.2f}s.\\n')\n",
    "\n",
    "        return cls(tokenizer, model, model_key, model_id, fp16_available)\n",
    "\n",
    "    def tokenize_and_train(\n",
    "        self,\n",
    "        dataset: DatasetDict,\n",
    "        max_length: int = MAX_LENGTH,\n",
    "        learning_rate: int = LR_RATE,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        epochs: int = N_EPOCHS,\n",
    "        seed: int = SEED,\n",
    "        logging_steps: int = LOGGING_STEPS,\n",
    "        output_dir: PathLike = get_target_dirpath(\"out\"),\n",
    "        logging_dir: PathLike = get_target_dirpath(\"logs\"),\n",
    "        gradient_checkpointing: bool = True,\n",
    "        load_best_model_at_end: bool = True,\n",
    "        callbacks: list[TrainerCallback] = [\n",
    "            EarlyStoppingCallback(early_stopping_patience=2)\n",
    "        ],\n",
    "        activate_fp16: bool = False,\n",
    "        activate_eval: bool = True,\n",
    "        activate_save: bool = True,\n",
    "        activate_logs: bool = False,\n",
    "        activate_tensorboard: bool = False,\n",
    "        activate_callbacks: bool = True,\n",
    "    ) -> Trainer:\n",
    "        # Ensure the training and validation sets\n",
    "        if not all(split in dataset for split in [\"train\", \"val\"]):\n",
    "            raise ValueError(\"DatasetDict must contain both 'train' and 'val' splits.\")\n",
    "\n",
    "        # Ensure the output and logging directories\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        os.makedirs(logging_dir, exist_ok=True)\n",
    "\n",
    "        start_time: float\n",
    "        end_time: float\n",
    "        elapsed: float\n",
    "\n",
    "        # Set the random seed for reproducibility\n",
    "        set_seed(seed)\n",
    "\n",
    "        # Set the padding token for the tokenizer\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.tokenizer.padding_side = \"right\"\n",
    "\n",
    "        # Tokenize the dataset with `max_length` padding\n",
    "        print(f\"[TOKENIZE] {self.model_key} ({self.model_id})\")\n",
    "        start_time = time.time()\n",
    "        tokenized_data: Dataset = dataset.map(\n",
    "            QuestGenLLM.tokenize_dataset,\n",
    "            batched=True,\n",
    "            remove_columns=[\"text\"],\n",
    "            fn_kwargs={\"tokenizer\": self.tokenizer, \"max_length\": max_length},\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"[COMPLETE] Elapsed: {elapsed:.2f}s\\n\")\n",
    "\n",
    "        # Set the model padding token (from the tokenizer)\n",
    "        self.model.config.pad_token_id = self.tokenizer.pad_token_id\n",
    "\n",
    "        # Turn off `use_cache` if `gradient_checkpointing` is on\n",
    "        self.model.config.use_cache = not gradient_checkpointing\n",
    "\n",
    "        # Set up the training configurations\n",
    "        training_args: TrainingArguments = TrainingArguments(\n",
    "            output_dir=(output_dir / self.model_key),\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=epochs,\n",
    "            log_level=(\"info\" if activate_logs else \"error\"),\n",
    "            logging_steps=logging_steps,\n",
    "            eval_strategy=(\"epoch\" if activate_eval else \"no\"),\n",
    "            save_strategy=(\"epoch\" if activate_save else \"no\"),\n",
    "            logging_dir=(logging_dir / self.model_key),\n",
    "            save_total_limit=2,\n",
    "            eval_accumulation_steps=2,\n",
    "            gradient_accumulation_steps=2,\n",
    "            gradient_checkpointing=gradient_checkpointing,\n",
    "            fp16=(self.fp16_available and activate_fp16),\n",
    "            load_best_model_at_end=load_best_model_at_end,\n",
    "            metric_for_best_model=\"eval_loss\",\n",
    "            seed=seed,\n",
    "            report_to=(\"tensorboard\" if activate_tensorboard else \"none\"),\n",
    "            label_names=[\"labels\"],\n",
    "        )\n",
    "\n",
    "        # Set up the data collator for the model\n",
    "        data_collator: DataCollatorForLanguageModeling = (\n",
    "            DataCollatorForLanguageModeling(tokenizer=self.tokenizer, mlm=False)\n",
    "        )\n",
    "\n",
    "        # Prepare and run the trainer\n",
    "        trainer: Trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            data_collator=data_collator,\n",
    "            train_dataset=tokenized_data[\"train\"],\n",
    "            eval_dataset=(tokenized_data[\"val\"] if activate_eval else None),\n",
    "            callbacks=(callbacks if activate_callbacks else []),\n",
    "        )\n",
    "\n",
    "        print(f\"[FINETUNE] {self.model_key} ({self.model_id})\")\n",
    "        start_time: float = time.time()\n",
    "        trainer.train()\n",
    "        end_time: float = time.time()\n",
    "        elapsed: float = end_time - start_time\n",
    "        print(f\"[COMPLETE] Elapsed: {elapsed:.2f}s\\n\")\n",
    "\n",
    "        # Save the model and tokenizer for later use\n",
    "        if activate_save:\n",
    "            trainer.save_model()\n",
    "            self.tokenizer.save_pretrained(save_directory=training_args.output_dir)\n",
    "\n",
    "        return trainer\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize_dataset(\n",
    "        examples: dict[str, list[str]],\n",
    "        tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast,\n",
    "        max_length: int = MAX_LENGTH,\n",
    "    ) -> dict[str, list[list[int]]]:\n",
    "        encodings: BatchEncoding = tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"longest\",\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids: list[list[int]] = encodings[\"input_ids\"]\n",
    "        attention_mask: list[list[int]] = encodings[\"attention_mask\"]\n",
    "\n",
    "        labels: list[list[int]] = input_ids.clone()\n",
    "        labels[input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids.tolist(),\n",
    "            \"attention_mask\": attention_mask.tolist(),\n",
    "            \"labels\": labels.tolist(),\n",
    "        }\n",
    "\n",
    "    def to_dict(self) -> dict[str, Any]:\n",
    "        return {\n",
    "            \"model_key\": self.model_key,\n",
    "            \"model_id\": self.model_id,\n",
    "            \"device\": self.device,\n",
    "            \"dtype\": self.dtype,\n",
    "            \"vocab_size\": getattr(self.tokenizer, \"vocab_size\", \"unknown\"),\n",
    "            \"max_length\": getattr(self.tokenizer, \"model_max_length\", \"unknown\"),\n",
    "            \"model_type\": getattr(\n",
    "                getattr(self.model, \"config\", None), \"model_type\", \"unknown\"\n",
    "            ),\n",
    "            \"num_parameters\": self.model.num_parameters()\n",
    "            if hasattr(self.model, \"num_parameters\")\n",
    "            else \"N/A\",\n",
    "            \"fp16_available\": self.fp16_available,\n",
    "        }\n",
    "\n",
    "    def clear_cache(self, cache_dir: PathLike = get_cache_dirpath(\"models\")) -> None:\n",
    "        def remove_dir(dir_path: PathLike) -> None:\n",
    "            if os.path.exists(dir_path):\n",
    "                shutil.rmtree(dir_path)\n",
    "                print(f\"Cache directory '{dir_path}' removed.\")\n",
    "            else:\n",
    "                print(f\"No cache directory found at '{dir_path}'.\")\n",
    "\n",
    "        remove_dir(cache_dir / self.model_key)\n",
    "\n",
    "    def print_model_information(self) -> None:\n",
    "        print(json.dumps(self.to_dict(), indent=2))\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.model_key} ({self.model_id})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc25bd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOWNLOAD] gpt2 (openai-community/gpt2)\n",
      "[LoRAINFO] trainable params: 1,179,648 || all params: 83,152,128 || trainable%: 1.4187\n",
      "[COMPLETE] \"gpt2\" ready in 10.91s.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuestGenLLM(tokenizer=GPT2TokenizerFast(name_or_path='openai-community/gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}\n",
       "), model=PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=768, out_features=2304, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "    )\n",
       "  )\n",
       "), model_key='gpt2', model_id='openai-community/gpt2', fp16_available=True, device='cuda:0', dtype='float32')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the GPT-2 Base model\n",
    "gpt2_base_model: QuestGenLLM = QuestGenLLM.from_pretrained(\n",
    "    model_key=\"gpt2\", model_id=MODEL_IDENTIFIERS[\"gpt2\"]\n",
    ")\n",
    "gpt2_base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f85486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOKENIZE] gpt2 (openai-community/gpt2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d296df70f4c449e894d7e932fc611a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMPLETE] Elapsed: 0.36s\n",
      "\n",
      "[FINETUNE] gpt2 (openai-community/gpt2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9977' max='9977' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9977/9977 40:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.240500</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMPLETE] Elapsed: 2446.42s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7fe3306b1a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train the GPT-2 Base model with the quest data\n",
    "gpt2_base_trainer: Trainer = gpt2_base_model.tokenize_and_train(quest_set)\n",
    "gpt2_base_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc7e9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOWNLOAD] gpt2-medium (openai-community/gpt2-medium)\n",
      "[LoRAINFO] trainable params: 3,145,728 || all params: 206,973,952 || trainable%: 1.5199\n",
      "[COMPLETE] \"gpt2-medium\" ready in 32.62s.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuestGenLLM(tokenizer=GPT2TokenizerFast(name_or_path='openai-community/gpt2-medium', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}\n",
       "), model=PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 1024)\n",
       "        (wpe): Embedding(1024, 1024)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-23): 24 x GPT2Block(\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       "    )\n",
       "  )\n",
       "), model_key='gpt2-medium', model_id='openai-community/gpt2-medium', fp16_available=True, device='cuda:0', dtype='float32')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the GPT-2 Medium model\n",
    "gpt2_medium_model: QuestGenLLM = QuestGenLLM.from_pretrained(\n",
    "    model_key=\"gpt2-medium\", model_id=MODEL_IDENTIFIERS[\"gpt2-medium\"]\n",
    ")\n",
    "gpt2_medium_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7f25086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOKENIZE] gpt2-medium (openai-community/gpt2-medium)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce63f83648f74ac49e4452edb69d5386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19954 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdcb81247444d8da5fcf6bb50177da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMPLETE] Elapsed: 1.59s\n",
      "\n",
      "[FINETUNE] gpt2-medium (openai-community/gpt2-medium)\n",
      "{'loss': 4.7756, 'grad_norm': 1.684780240058899, 'learning_rate': 4.994988473489026e-06, 'epoch': 0.0010023053021950487}\n",
      "{'loss': 4.7976, 'grad_norm': 4.057989597320557, 'learning_rate': 4.98997694697805e-06, 'epoch': 0.0020046106043900974}\n",
      "{'loss': 4.8453, 'grad_norm': 2.278386354446411, 'learning_rate': 4.984965420467074e-06, 'epoch': 0.0030069159065851457}\n",
      "{'loss': 4.8711, 'grad_norm': 1.7902874946594238, 'learning_rate': 4.9799538939560996e-06, 'epoch': 0.004009221208780195}\n",
      "{'loss': 5.1045, 'grad_norm': 2.8318560123443604, 'learning_rate': 4.974942367445124e-06, 'epoch': 0.005011526510975243}\n",
      "{'loss': 4.4405, 'grad_norm': 2.982595443725586, 'learning_rate': 4.969930840934149e-06, 'epoch': 0.006013831813170291}\n",
      "{'loss': 4.8737, 'grad_norm': 1.2856559753417969, 'learning_rate': 4.9649193144231735e-06, 'epoch': 0.00701613711536534}\n",
      "{'loss': 4.6095, 'grad_norm': 1.283393144607544, 'learning_rate': 4.959907787912199e-06, 'epoch': 0.00801844241756039}\n",
      "{'loss': 4.2239, 'grad_norm': 1.123895525932312, 'learning_rate': 4.954896261401223e-06, 'epoch': 0.009020747719755437}\n",
      "{'loss': 4.506, 'grad_norm': 1.0399731397628784, 'learning_rate': 4.949884734890248e-06, 'epoch': 0.010023053021950485}\n",
      "{'loss': 4.5461, 'grad_norm': 4.60920524597168, 'learning_rate': 4.944873208379273e-06, 'epoch': 0.011025358324145534}\n",
      "{'loss': 4.5391, 'grad_norm': 1.0709342956542969, 'learning_rate': 4.939861681868298e-06, 'epoch': 0.012027663626340583}\n",
      "{'loss': 4.984, 'grad_norm': 3.4517319202423096, 'learning_rate': 4.934850155357322e-06, 'epoch': 0.013029968928535631}\n",
      "{'loss': 4.3757, 'grad_norm': 1.706668496131897, 'learning_rate': 4.929838628846347e-06, 'epoch': 0.01403227423073068}\n",
      "{'loss': 4.8763, 'grad_norm': 2.1579484939575195, 'learning_rate': 4.924827102335372e-06, 'epoch': 0.015034579532925729}\n",
      "{'loss': 4.4654, 'grad_norm': 1.0627423524856567, 'learning_rate': 4.919815575824396e-06, 'epoch': 0.01603688483512078}\n",
      "{'loss': 4.4906, 'grad_norm': 2.42364239692688, 'learning_rate': 4.914804049313421e-06, 'epoch': 0.017039190137315828}\n",
      "{'loss': 4.4973, 'grad_norm': 6.0271124839782715, 'learning_rate': 4.909792522802447e-06, 'epoch': 0.018041495439510873}\n",
      "{'loss': 4.8497, 'grad_norm': 1.6187541484832764, 'learning_rate': 4.904780996291471e-06, 'epoch': 0.019043800741705922}\n",
      "{'loss': 4.3107, 'grad_norm': 1.5953911542892456, 'learning_rate': 4.899769469780495e-06, 'epoch': 0.02004610604390097}\n",
      "{'loss': 4.6413, 'grad_norm': 1.9668759107589722, 'learning_rate': 4.8947579432695205e-06, 'epoch': 0.02104841134609602}\n",
      "{'loss': 4.1402, 'grad_norm': 1.0959028005599976, 'learning_rate': 4.889746416758545e-06, 'epoch': 0.022050716648291068}\n",
      "{'loss': 5.1071, 'grad_norm': 2.6581947803497314, 'learning_rate': 4.88473489024757e-06, 'epoch': 0.023053021950486117}\n",
      "{'loss': 3.7703, 'grad_norm': 1.9104589223861694, 'learning_rate': 4.8797233637365945e-06, 'epoch': 0.024055327252681166}\n",
      "{'loss': 3.8509, 'grad_norm': 1.7716323137283325, 'learning_rate': 4.874711837225619e-06, 'epoch': 0.025057632554876214}\n",
      "{'loss': 4.4282, 'grad_norm': 1.9116640090942383, 'learning_rate': 4.869700310714644e-06, 'epoch': 0.026059937857071263}\n",
      "{'loss': 4.1502, 'grad_norm': 2.2635796070098877, 'learning_rate': 4.864688784203669e-06, 'epoch': 0.02706224315926631}\n",
      "{'loss': 4.2782, 'grad_norm': 1.7923754453659058, 'learning_rate': 4.859677257692694e-06, 'epoch': 0.02806454846146136}\n",
      "{'loss': 4.1098, 'grad_norm': 1.4000914096832275, 'learning_rate': 4.854665731181719e-06, 'epoch': 0.02906685376365641}\n",
      "{'loss': 4.0981, 'grad_norm': 2.9744412899017334, 'learning_rate': 4.849654204670743e-06, 'epoch': 0.030069159065851458}\n",
      "{'loss': 4.443, 'grad_norm': 1.7733484506607056, 'learning_rate': 4.8446426781597675e-06, 'epoch': 0.031071464368046506}\n",
      "{'loss': 3.9917, 'grad_norm': 3.2322967052459717, 'learning_rate': 4.839631151648793e-06, 'epoch': 0.03207376967024156}\n",
      "{'loss': 3.965, 'grad_norm': 1.8277701139450073, 'learning_rate': 4.834619625137817e-06, 'epoch': 0.03307607497243661}\n",
      "{'loss': 4.2829, 'grad_norm': 3.7202136516571045, 'learning_rate': 4.829608098626842e-06, 'epoch': 0.034078380274631656}\n",
      "{'loss': 4.1636, 'grad_norm': 3.9156885147094727, 'learning_rate': 4.824596572115867e-06, 'epoch': 0.035080685576826705}\n",
      "{'loss': 4.2171, 'grad_norm': 3.982715368270874, 'learning_rate': 4.819585045604892e-06, 'epoch': 0.03608299087902175}\n",
      "{'loss': 4.0752, 'grad_norm': 1.0319076776504517, 'learning_rate': 4.814573519093916e-06, 'epoch': 0.037085296181216795}\n",
      "{'loss': 4.2612, 'grad_norm': 4.744459629058838, 'learning_rate': 4.8095619925829415e-06, 'epoch': 0.038087601483411844}\n",
      "{'loss': 4.6907, 'grad_norm': 2.006385087966919, 'learning_rate': 4.804550466071966e-06, 'epoch': 0.03908990678560689}\n",
      "{'loss': 3.9258, 'grad_norm': 2.5644450187683105, 'learning_rate': 4.799538939560991e-06, 'epoch': 0.04009221208780194}\n",
      "{'loss': 3.9159, 'grad_norm': 1.7647241353988647, 'learning_rate': 4.794527413050015e-06, 'epoch': 0.04109451738999699}\n",
      "{'loss': 4.1875, 'grad_norm': 2.0846059322357178, 'learning_rate': 4.78951588653904e-06, 'epoch': 0.04209682269219204}\n",
      "{'loss': 3.8446, 'grad_norm': 3.495023488998413, 'learning_rate': 4.784504360028065e-06, 'epoch': 0.04309912799438709}\n",
      "{'loss': 4.0986, 'grad_norm': 3.9233131408691406, 'learning_rate': 4.77949283351709e-06, 'epoch': 0.044101433296582136}\n",
      "{'loss': 4.1775, 'grad_norm': 1.6067606210708618, 'learning_rate': 4.7744813070061146e-06, 'epoch': 0.045103738598777185}\n",
      "{'loss': 4.5396, 'grad_norm': 5.248970031738281, 'learning_rate': 4.769469780495139e-06, 'epoch': 0.046106043900972234}\n",
      "{'loss': 4.4967, 'grad_norm': 3.928910970687866, 'learning_rate': 4.764458253984164e-06, 'epoch': 0.04710834920316728}\n",
      "{'loss': 3.7448, 'grad_norm': 2.894655704498291, 'learning_rate': 4.7594467274731885e-06, 'epoch': 0.04811065450536233}\n",
      "{'loss': 4.167, 'grad_norm': 4.387770175933838, 'learning_rate': 4.754435200962214e-06, 'epoch': 0.04911295980755738}\n",
      "{'loss': 3.9099, 'grad_norm': 3.6416549682617188, 'learning_rate': 4.749423674451238e-06, 'epoch': 0.05011526510975243}\n",
      "{'loss': 4.1111, 'grad_norm': 1.731205940246582, 'learning_rate': 4.7444121479402624e-06, 'epoch': 0.05111757041194748}\n",
      "{'loss': 3.8622, 'grad_norm': 3.3795015811920166, 'learning_rate': 4.739400621429288e-06, 'epoch': 0.052119875714142526}\n",
      "{'loss': 4.0862, 'grad_norm': 7.9649457931518555, 'learning_rate': 4.734389094918313e-06, 'epoch': 0.053122181016337575}\n",
      "{'loss': 3.8328, 'grad_norm': 3.272951602935791, 'learning_rate': 4.729377568407337e-06, 'epoch': 0.05412448631853262}\n",
      "{'loss': 3.4132, 'grad_norm': 2.5164411067962646, 'learning_rate': 4.7243660418963624e-06, 'epoch': 0.05512679162072767}\n",
      "{'loss': 3.6406, 'grad_norm': 1.6156638860702515, 'learning_rate': 4.719354515385387e-06, 'epoch': 0.05612909692292272}\n",
      "{'loss': 3.7135, 'grad_norm': 2.7496352195739746, 'learning_rate': 4.714342988874411e-06, 'epoch': 0.05713140222511777}\n",
      "{'loss': 3.9918, 'grad_norm': 3.489121198654175, 'learning_rate': 4.709331462363436e-06, 'epoch': 0.05813370752731282}\n",
      "{'loss': 4.036, 'grad_norm': 4.834736347198486, 'learning_rate': 4.704319935852461e-06, 'epoch': 0.05913601282950787}\n",
      "{'loss': 4.2265, 'grad_norm': 4.994255065917969, 'learning_rate': 4.699308409341486e-06, 'epoch': 0.060138318131702916}\n",
      "{'loss': 3.4989, 'grad_norm': 3.435833692550659, 'learning_rate': 4.694296882830511e-06, 'epoch': 0.061140623433897964}\n",
      "{'loss': 3.2203, 'grad_norm': 2.304192543029785, 'learning_rate': 4.689285356319535e-06, 'epoch': 0.06214292873609301}\n",
      "{'loss': 4.202, 'grad_norm': 2.054452657699585, 'learning_rate': 4.68427382980856e-06, 'epoch': 0.06314523403828806}\n",
      "{'loss': 3.5337, 'grad_norm': 7.300156116485596, 'learning_rate': 4.679262303297585e-06, 'epoch': 0.06414753934048312}\n",
      "{'loss': 3.7964, 'grad_norm': 4.722812652587891, 'learning_rate': 4.6742507767866095e-06, 'epoch': 0.06514984464267816}\n",
      "{'loss': 3.5577, 'grad_norm': 4.074814319610596, 'learning_rate': 4.669239250275635e-06, 'epoch': 0.06615214994487321}\n",
      "{'loss': 3.6861, 'grad_norm': 2.7537124156951904, 'learning_rate': 4.664227723764659e-06, 'epoch': 0.06715445524706826}\n",
      "{'loss': 2.8067, 'grad_norm': 3.2352209091186523, 'learning_rate': 4.659216197253683e-06, 'epoch': 0.06815676054926331}\n",
      "{'loss': 3.4196, 'grad_norm': 2.952815532684326, 'learning_rate': 4.654204670742709e-06, 'epoch': 0.06915906585145835}\n",
      "{'loss': 3.7667, 'grad_norm': 12.679258346557617, 'learning_rate': 4.649193144231734e-06, 'epoch': 0.07016137115365341}\n",
      "{'loss': 3.3767, 'grad_norm': 5.480439186096191, 'learning_rate': 4.644181617720758e-06, 'epoch': 0.07116367645584845}\n",
      "{'loss': 3.2059, 'grad_norm': 3.412400007247925, 'learning_rate': 4.639170091209783e-06, 'epoch': 0.0721659817580435}\n",
      "{'loss': 3.3328, 'grad_norm': 6.668332576751709, 'learning_rate': 4.634158564698808e-06, 'epoch': 0.07316828706023855}\n",
      "{'loss': 3.881, 'grad_norm': 8.513764381408691, 'learning_rate': 4.629147038187832e-06, 'epoch': 0.07417059236243359}\n",
      "{'loss': 4.0385, 'grad_norm': 7.696507930755615, 'learning_rate': 4.624135511676857e-06, 'epoch': 0.07517289766462865}\n",
      "{'loss': 3.3847, 'grad_norm': 2.633544683456421, 'learning_rate': 4.619123985165882e-06, 'epoch': 0.07617520296682369}\n",
      "{'loss': 3.9985, 'grad_norm': 6.198056697845459, 'learning_rate': 4.614112458654907e-06, 'epoch': 0.07717750826901874}\n",
      "{'loss': 3.2864, 'grad_norm': 5.893591403961182, 'learning_rate': 4.609100932143931e-06, 'epoch': 0.07817981357121379}\n",
      "{'loss': 3.5474, 'grad_norm': 6.6294732093811035, 'learning_rate': 4.604089405632956e-06, 'epoch': 0.07918211887340884}\n",
      "{'loss': 3.4715, 'grad_norm': 2.26865816116333, 'learning_rate': 4.599077879121981e-06, 'epoch': 0.08018442417560388}\n",
      "{'loss': 3.4721, 'grad_norm': 4.2507548332214355, 'learning_rate': 4.594066352611006e-06, 'epoch': 0.08118672947779894}\n",
      "{'loss': 4.3364, 'grad_norm': 3.320772647857666, 'learning_rate': 4.58905482610003e-06, 'epoch': 0.08218903477999398}\n",
      "{'loss': 3.27, 'grad_norm': 4.182019233703613, 'learning_rate': 4.584043299589056e-06, 'epoch': 0.08319134008218904}\n",
      "{'loss': 2.9576, 'grad_norm': 3.8082234859466553, 'learning_rate': 4.57903177307808e-06, 'epoch': 0.08419364538438408}\n",
      "{'loss': 2.7103, 'grad_norm': 3.7997992038726807, 'learning_rate': 4.574020246567104e-06, 'epoch': 0.08519595068657913}\n",
      "{'loss': 3.4707, 'grad_norm': 4.063302993774414, 'learning_rate': 4.5690087200561296e-06, 'epoch': 0.08619825598877418}\n",
      "{'loss': 3.4549, 'grad_norm': 3.288280725479126, 'learning_rate': 4.563997193545155e-06, 'epoch': 0.08720056129096923}\n",
      "{'loss': 3.5118, 'grad_norm': 7.491491794586182, 'learning_rate': 4.558985667034179e-06, 'epoch': 0.08820286659316427}\n",
      "{'loss': 3.5451, 'grad_norm': 4.819094181060791, 'learning_rate': 4.5539741405232035e-06, 'epoch': 0.08920517189535933}\n",
      "{'loss': 3.6504, 'grad_norm': 5.748506546020508, 'learning_rate': 4.548962614012229e-06, 'epoch': 0.09020747719755437}\n",
      "{'loss': 3.6014, 'grad_norm': 4.7150421142578125, 'learning_rate': 4.543951087501253e-06, 'epoch': 0.09120978249974943}\n",
      "{'loss': 3.3497, 'grad_norm': 4.657111644744873, 'learning_rate': 4.538939560990278e-06, 'epoch': 0.09221208780194447}\n",
      "{'loss': 3.5676, 'grad_norm': 2.970820903778076, 'learning_rate': 4.533928034479303e-06, 'epoch': 0.09321439310413952}\n",
      "{'loss': 3.1827, 'grad_norm': 9.811932563781738, 'learning_rate': 4.528916507968327e-06, 'epoch': 0.09421669840633456}\n",
      "{'loss': 3.8137, 'grad_norm': 6.867745399475098, 'learning_rate': 4.523904981457352e-06, 'epoch': 0.09521900370852962}\n",
      "{'loss': 3.4274, 'grad_norm': 1.8147445917129517, 'learning_rate': 4.518893454946377e-06, 'epoch': 0.09622130901072466}\n",
      "{'loss': 3.4848, 'grad_norm': 5.631458759307861, 'learning_rate': 4.513881928435402e-06, 'epoch': 0.09722361431291972}\n",
      "{'loss': 3.3483, 'grad_norm': 2.510547399520874, 'learning_rate': 4.508870401924427e-06, 'epoch': 0.09822591961511476}\n",
      "{'loss': 4.0833, 'grad_norm': 3.543694019317627, 'learning_rate': 4.503858875413451e-06, 'epoch': 0.09922822491730982}\n",
      "{'loss': 3.5478, 'grad_norm': 6.920427322387695, 'learning_rate': 4.498847348902476e-06, 'epoch': 0.10023053021950486}\n",
      "{'loss': 3.517, 'grad_norm': 0.0, 'learning_rate': 4.493835822391501e-06, 'epoch': 0.10123283552169991}\n",
      "{'loss': 3.4616, 'grad_norm': 7.325642108917236, 'learning_rate': 4.488824295880525e-06, 'epoch': 0.10223514082389495}\n",
      "{'loss': 3.5256, 'grad_norm': 4.941600799560547, 'learning_rate': 4.4838127693695505e-06, 'epoch': 0.10323744612609001}\n",
      "{'loss': 4.0493, 'grad_norm': 5.027078628540039, 'learning_rate': 4.478801242858576e-06, 'epoch': 0.10423975142828505}\n",
      "{'loss': 3.3658, 'grad_norm': 2.105665922164917, 'learning_rate': 4.473789716347599e-06, 'epoch': 0.10524205673048011}\n",
      "{'loss': 3.0004, 'grad_norm': 4.278846263885498, 'learning_rate': 4.4687781898366245e-06, 'epoch': 0.10624436203267515}\n",
      "{'loss': 2.6134, 'grad_norm': 3.872943639755249, 'learning_rate': 4.46376666332565e-06, 'epoch': 0.1072466673348702}\n",
      "{'loss': 3.4777, 'grad_norm': 4.1967620849609375, 'learning_rate': 4.458755136814674e-06, 'epoch': 0.10824897263706525}\n",
      "{'loss': 2.4153, 'grad_norm': 8.97281265258789, 'learning_rate': 4.453743610303699e-06, 'epoch': 0.1092512779392603}\n",
      "{'loss': 4.1999, 'grad_norm': 2.610853910446167, 'learning_rate': 4.448732083792724e-06, 'epoch': 0.11025358324145534}\n",
      "{'loss': 3.666, 'grad_norm': 3.0239670276641846, 'learning_rate': 4.443720557281748e-06, 'epoch': 0.1112558885436504}\n",
      "{'loss': 2.9702, 'grad_norm': 8.473845481872559, 'learning_rate': 4.438709030770773e-06, 'epoch': 0.11225819384584544}\n",
      "{'loss': 2.9205, 'grad_norm': 5.772531032562256, 'learning_rate': 4.4336975042597976e-06, 'epoch': 0.1132604991480405}\n",
      "{'loss': 2.6832, 'grad_norm': 3.549534797668457, 'learning_rate': 4.428685977748823e-06, 'epoch': 0.11426280445023554}\n",
      "{'loss': 3.7808, 'grad_norm': 0.0, 'learning_rate': 4.423674451237848e-06, 'epoch': 0.1152651097524306}\n",
      "{'loss': 3.477, 'grad_norm': 3.842773914337158, 'learning_rate': 4.418662924726872e-06, 'epoch': 0.11626741505462564}\n",
      "{'loss': 3.4764, 'grad_norm': 3.55806827545166, 'learning_rate': 4.413651398215897e-06, 'epoch': 0.11726972035682069}\n",
      "{'loss': 3.1485, 'grad_norm': 6.043538570404053, 'learning_rate': 4.408639871704922e-06, 'epoch': 0.11827202565901573}\n",
      "{'loss': 2.9842, 'grad_norm': 5.497226715087891, 'learning_rate': 4.403628345193946e-06, 'epoch': 0.11927433096121079}\n",
      "{'loss': 2.7976, 'grad_norm': 3.1281182765960693, 'learning_rate': 4.3986168186829715e-06, 'epoch': 0.12027663626340583}\n",
      "{'loss': 3.2219, 'grad_norm': 10.308083534240723, 'learning_rate': 4.393605292171996e-06, 'epoch': 0.12127894156560089}\n",
      "{'loss': 2.5044, 'grad_norm': 4.726230144500732, 'learning_rate': 4.38859376566102e-06, 'epoch': 0.12228124686779593}\n",
      "{'loss': 2.8622, 'grad_norm': 2.945610284805298, 'learning_rate': 4.3835822391500454e-06, 'epoch': 0.12328355216999098}\n",
      "{'loss': 2.9079, 'grad_norm': 4.412807464599609, 'learning_rate': 4.378570712639071e-06, 'epoch': 0.12428585747218603}\n",
      "{'loss': 2.6891, 'grad_norm': 3.537097930908203, 'learning_rate': 4.373559186128095e-06, 'epoch': 0.12528816277438107}\n",
      "{'loss': 2.9968, 'grad_norm': 4.082335948944092, 'learning_rate': 4.368547659617119e-06, 'epoch': 0.12629046807657612}\n",
      "{'loss': 3.5793, 'grad_norm': 3.648050546646118, 'learning_rate': 4.3635361331061446e-06, 'epoch': 0.12729277337877118}\n",
      "{'loss': 2.89, 'grad_norm': 5.606015682220459, 'learning_rate': 4.358524606595169e-06, 'epoch': 0.12829507868096623}\n",
      "{'loss': 2.9713, 'grad_norm': 5.451874256134033, 'learning_rate': 4.353513080084194e-06, 'epoch': 0.12929738398316126}\n",
      "{'loss': 2.4655, 'grad_norm': 3.192469358444214, 'learning_rate': 4.3485015535732185e-06, 'epoch': 0.13029968928535632}\n",
      "{'loss': 2.8621, 'grad_norm': 3.1598362922668457, 'learning_rate': 4.343490027062244e-06, 'epoch': 0.13130199458755137}\n",
      "{'loss': 3.0352, 'grad_norm': 5.595625877380371, 'learning_rate': 4.338478500551268e-06, 'epoch': 0.13230429988974643}\n",
      "{'loss': 2.8236, 'grad_norm': 3.937927484512329, 'learning_rate': 4.333466974040293e-06, 'epoch': 0.13330660519194146}\n",
      "{'loss': 2.5138, 'grad_norm': 6.514238357543945, 'learning_rate': 4.328455447529318e-06, 'epoch': 0.1343089104941365}\n",
      "{'loss': 2.7743, 'grad_norm': 4.805252552032471, 'learning_rate': 4.323443921018343e-06, 'epoch': 0.13531121579633157}\n",
      "{'loss': 3.5816, 'grad_norm': 3.892761707305908, 'learning_rate': 4.318432394507367e-06, 'epoch': 0.13631352109852662}\n",
      "{'loss': 3.2332, 'grad_norm': 7.958944320678711, 'learning_rate': 4.313420867996392e-06, 'epoch': 0.13731582640072165}\n",
      "{'loss': 3.1805, 'grad_norm': 7.410809516906738, 'learning_rate': 4.308409341485417e-06, 'epoch': 0.1383181317029167}\n",
      "{'loss': 2.8237, 'grad_norm': 4.380032539367676, 'learning_rate': 4.303397814974441e-06, 'epoch': 0.13932043700511176}\n",
      "{'loss': 2.8294, 'grad_norm': 4.871628284454346, 'learning_rate': 4.298386288463466e-06, 'epoch': 0.14032274230730682}\n",
      "{'loss': 3.5498, 'grad_norm': 5.3252692222595215, 'learning_rate': 4.293374761952492e-06, 'epoch': 0.14132504760950185}\n",
      "{'loss': 3.203, 'grad_norm': 3.828634023666382, 'learning_rate': 4.288363235441516e-06, 'epoch': 0.1423273529116969}\n",
      "{'loss': 3.0751, 'grad_norm': 5.546029567718506, 'learning_rate': 4.28335170893054e-06, 'epoch': 0.14332965821389196}\n",
      "{'loss': 3.0389, 'grad_norm': 12.456971168518066, 'learning_rate': 4.2783401824195655e-06, 'epoch': 0.144331963516087}\n",
      "{'loss': 3.5437, 'grad_norm': 7.464714527130127, 'learning_rate': 4.27332865590859e-06, 'epoch': 0.14533426881828204}\n",
      "{'loss': 2.6732, 'grad_norm': 4.675004959106445, 'learning_rate': 4.268317129397615e-06, 'epoch': 0.1463365741204771}\n",
      "{'loss': 2.7864, 'grad_norm': 3.2793993949890137, 'learning_rate': 4.2633056028866395e-06, 'epoch': 0.14733887942267215}\n",
      "{'loss': 3.2106, 'grad_norm': 4.828976631164551, 'learning_rate': 4.258294076375664e-06, 'epoch': 0.14834118472486718}\n",
      "{'loss': 2.7529, 'grad_norm': 5.3078227043151855, 'learning_rate': 4.253282549864689e-06, 'epoch': 0.14934349002706224}\n",
      "{'loss': 2.9045, 'grad_norm': 6.414243221282959, 'learning_rate': 4.248271023353714e-06, 'epoch': 0.1503457953292573}\n",
      "{'loss': 2.8615, 'grad_norm': 8.099117279052734, 'learning_rate': 4.243259496842739e-06, 'epoch': 0.15134810063145235}\n",
      "{'loss': 2.9431, 'grad_norm': 3.9607980251312256, 'learning_rate': 4.238247970331764e-06, 'epoch': 0.15235040593364738}\n",
      "{'loss': 3.0898, 'grad_norm': 3.876866102218628, 'learning_rate': 4.233236443820788e-06, 'epoch': 0.15335271123584243}\n",
      "{'loss': 2.9906, 'grad_norm': 2.615067720413208, 'learning_rate': 4.2282249173098126e-06, 'epoch': 0.1543550165380375}\n",
      "{'loss': 2.2632, 'grad_norm': 7.417427062988281, 'learning_rate': 4.223213390798838e-06, 'epoch': 0.15535732184023254}\n",
      "{'loss': 3.0357, 'grad_norm': 8.036249160766602, 'learning_rate': 4.218201864287862e-06, 'epoch': 0.15635962714242757}\n",
      "{'loss': 2.6391, 'grad_norm': 5.6107025146484375, 'learning_rate': 4.213190337776887e-06, 'epoch': 0.15736193244462263}\n",
      "{'loss': 2.8021, 'grad_norm': 8.035567283630371, 'learning_rate': 4.2081788112659126e-06, 'epoch': 0.15836423774681768}\n",
      "{'loss': 2.9877, 'grad_norm': 4.250155925750732, 'learning_rate': 4.203167284754937e-06, 'epoch': 0.15936654304901274}\n",
      "{'loss': 3.1135, 'grad_norm': 6.851327419281006, 'learning_rate': 4.198155758243961e-06, 'epoch': 0.16036884835120777}\n",
      "{'loss': 2.8192, 'grad_norm': 5.816251277923584, 'learning_rate': 4.1931442317329865e-06, 'epoch': 0.16137115365340282}\n",
      "{'loss': 3.3951, 'grad_norm': 5.776486873626709, 'learning_rate': 4.188132705222011e-06, 'epoch': 0.16237345895559788}\n",
      "{'loss': 3.0174, 'grad_norm': 5.944570541381836, 'learning_rate': 4.183121178711036e-06, 'epoch': 0.16337576425779293}\n",
      "{'loss': 3.3213, 'grad_norm': 6.100156784057617, 'learning_rate': 4.1781096522000604e-06, 'epoch': 0.16437806955998796}\n",
      "{'loss': 2.7212, 'grad_norm': 4.123201370239258, 'learning_rate': 4.173098125689085e-06, 'epoch': 0.16538037486218302}\n",
      "{'loss': 2.804, 'grad_norm': 4.847041606903076, 'learning_rate': 4.16808659917811e-06, 'epoch': 0.16638268016437807}\n",
      "{'loss': 2.2363, 'grad_norm': 5.722286224365234, 'learning_rate': 4.163075072667135e-06, 'epoch': 0.16738498546657313}\n",
      "{'loss': 3.0134, 'grad_norm': 2.294451951980591, 'learning_rate': 4.15806354615616e-06, 'epoch': 0.16838729076876816}\n",
      "{'loss': 3.3808, 'grad_norm': 4.048816680908203, 'learning_rate': 4.153052019645184e-06, 'epoch': 0.1693895960709632}\n",
      "{'loss': 3.241, 'grad_norm': 8.514033317565918, 'learning_rate': 4.148040493134209e-06, 'epoch': 0.17039190137315827}\n",
      "{'loss': 3.2511, 'grad_norm': 4.708037853240967, 'learning_rate': 4.1430289666232335e-06, 'epoch': 0.17139420667535332}\n",
      "{'loss': 2.9189, 'grad_norm': 6.461031436920166, 'learning_rate': 4.138017440112259e-06, 'epoch': 0.17239651197754835}\n",
      "{'loss': 3.1523, 'grad_norm': 5.182599067687988, 'learning_rate': 4.133005913601283e-06, 'epoch': 0.1733988172797434}\n",
      "{'loss': 2.3868, 'grad_norm': 6.61176872253418, 'learning_rate': 4.127994387090308e-06, 'epoch': 0.17440112258193846}\n",
      "{'loss': 2.4913, 'grad_norm': 8.477311134338379, 'learning_rate': 4.122982860579333e-06, 'epoch': 0.17540342788413352}\n",
      "{'loss': 2.8934, 'grad_norm': 3.2941396236419678, 'learning_rate': 4.117971334068358e-06, 'epoch': 0.17640573318632854}\n",
      "{'loss': 2.283, 'grad_norm': 17.411678314208984, 'learning_rate': 4.112959807557382e-06, 'epoch': 0.1774080384885236}\n",
      "{'loss': 2.836, 'grad_norm': 2.858764171600342, 'learning_rate': 4.1079482810464075e-06, 'epoch': 0.17841034379071866}\n",
      "{'loss': 2.8102, 'grad_norm': 13.996556282043457, 'learning_rate': 4.102936754535432e-06, 'epoch': 0.1794126490929137}\n",
      "{'loss': 2.2317, 'grad_norm': 7.722621917724609, 'learning_rate': 4.097925228024456e-06, 'epoch': 0.18041495439510874}\n",
      "{'loss': 1.7946, 'grad_norm': 8.809852600097656, 'learning_rate': 4.092913701513481e-06, 'epoch': 0.1814172596973038}\n",
      "{'loss': 3.1212, 'grad_norm': 4.650112628936768, 'learning_rate': 4.087902175002506e-06, 'epoch': 0.18241956499949885}\n",
      "{'loss': 1.8467, 'grad_norm': 8.888916969299316, 'learning_rate': 4.082890648491531e-06, 'epoch': 0.1834218703016939}\n",
      "{'loss': 3.0625, 'grad_norm': 13.588767051696777, 'learning_rate': 4.077879121980556e-06, 'epoch': 0.18442417560388893}\n",
      "{'loss': 2.9088, 'grad_norm': 12.001953125, 'learning_rate': 4.07286759546958e-06, 'epoch': 0.185426480906084}\n",
      "{'loss': 2.4653, 'grad_norm': 10.220800399780273, 'learning_rate': 4.067856068958605e-06, 'epoch': 0.18642878620827905}\n",
      "{'loss': 3.9505, 'grad_norm': 3.3740875720977783, 'learning_rate': 4.06284454244763e-06, 'epoch': 0.1874310915104741}\n",
      "{'loss': 3.3725, 'grad_norm': 6.601017475128174, 'learning_rate': 4.0578330159366545e-06, 'epoch': 0.18843339681266913}\n",
      "{'loss': 2.8162, 'grad_norm': 7.583829402923584, 'learning_rate': 4.05282148942568e-06, 'epoch': 0.18943570211486419}\n",
      "{'loss': 2.6614, 'grad_norm': 3.616518259048462, 'learning_rate': 4.047809962914704e-06, 'epoch': 0.19043800741705924}\n",
      "{'loss': 2.6083, 'grad_norm': 5.6325578689575195, 'learning_rate': 4.042798436403728e-06, 'epoch': 0.1914403127192543}\n",
      "{'loss': 2.9487, 'grad_norm': 7.111791133880615, 'learning_rate': 4.037786909892754e-06, 'epoch': 0.19244261802144932}\n",
      "{'loss': 2.4823, 'grad_norm': 9.168219566345215, 'learning_rate': 4.032775383381779e-06, 'epoch': 0.19344492332364438}\n",
      "{'loss': 3.4328, 'grad_norm': 8.33929443359375, 'learning_rate': 4.027763856870803e-06, 'epoch': 0.19444722862583944}\n",
      "{'loss': 2.104, 'grad_norm': 6.140384674072266, 'learning_rate': 4.022752330359828e-06, 'epoch': 0.1954495339280345}\n",
      "{'loss': 1.8644, 'grad_norm': 7.589504241943359, 'learning_rate': 4.017740803848853e-06, 'epoch': 0.19645183923022952}\n",
      "{'loss': 3.3218, 'grad_norm': 13.83841609954834, 'learning_rate': 4.012729277337877e-06, 'epoch': 0.19745414453242457}\n",
      "{'loss': 3.091, 'grad_norm': 7.808671951293945, 'learning_rate': 4.007717750826902e-06, 'epoch': 0.19845644983461963}\n",
      "{'loss': 2.6618, 'grad_norm': 9.476399421691895, 'learning_rate': 4.002706224315927e-06, 'epoch': 0.19945875513681469}\n",
      "{'loss': 2.633, 'grad_norm': 21.03312873840332, 'learning_rate': 3.997694697804952e-06, 'epoch': 0.20046106043900971}\n",
      "{'loss': 3.5747, 'grad_norm': 11.158278465270996, 'learning_rate': 3.992683171293976e-06, 'epoch': 0.20146336574120477}\n",
      "{'loss': 2.4289, 'grad_norm': 9.268777847290039, 'learning_rate': 3.987671644783001e-06, 'epoch': 0.20246567104339983}\n",
      "{'loss': 2.7238, 'grad_norm': 9.5995512008667, 'learning_rate': 3.982660118272026e-06, 'epoch': 0.20346797634559488}\n",
      "{'loss': 2.5493, 'grad_norm': 9.356980323791504, 'learning_rate': 3.977648591761051e-06, 'epoch': 0.2044702816477899}\n",
      "{'loss': 3.3, 'grad_norm': 5.5598554611206055, 'learning_rate': 3.9726370652500754e-06, 'epoch': 0.20547258694998496}\n",
      "{'loss': 2.1045, 'grad_norm': 4.769287109375, 'learning_rate': 3.967625538739101e-06, 'epoch': 0.20647489225218002}\n",
      "{'loss': 3.0022, 'grad_norm': 3.1276674270629883, 'learning_rate': 3.962614012228125e-06, 'epoch': 0.20747719755437508}\n",
      "{'loss': 3.3337, 'grad_norm': 5.36343240737915, 'learning_rate': 3.957602485717149e-06, 'epoch': 0.2084795028565701}\n",
      "{'loss': 2.9832, 'grad_norm': 5.329224109649658, 'learning_rate': 3.952590959206175e-06, 'epoch': 0.20948180815876516}\n",
      "{'loss': 2.5266, 'grad_norm': 4.217756748199463, 'learning_rate': 3.9475794326952e-06, 'epoch': 0.21048411346096021}\n",
      "{'loss': 2.368, 'grad_norm': 8.286527633666992, 'learning_rate': 3.942567906184224e-06, 'epoch': 0.21148641876315527}\n",
      "{'loss': 2.2162, 'grad_norm': 8.9613676071167, 'learning_rate': 3.9375563796732485e-06, 'epoch': 0.2124887240653503}\n",
      "{'loss': 3.0547, 'grad_norm': 4.862099647521973, 'learning_rate': 3.932544853162274e-06, 'epoch': 0.21349102936754535}\n",
      "{'loss': 3.0902, 'grad_norm': 5.8996124267578125, 'learning_rate': 3.927533326651298e-06, 'epoch': 0.2144933346697404}\n",
      "{'loss': 2.2605, 'grad_norm': 10.64082145690918, 'learning_rate': 3.922521800140323e-06, 'epoch': 0.21549563997193547}\n",
      "{'loss': 3.2461, 'grad_norm': 7.5192060470581055, 'learning_rate': 3.917510273629348e-06, 'epoch': 0.2164979452741305}\n",
      "{'loss': 3.4723, 'grad_norm': 4.877266883850098, 'learning_rate': 3.912498747118373e-06, 'epoch': 0.21750025057632555}\n",
      "{'loss': 2.4486, 'grad_norm': 2.8113815784454346, 'learning_rate': 3.907487220607397e-06, 'epoch': 0.2185025558785206}\n",
      "{'loss': 2.4064, 'grad_norm': 0.0, 'learning_rate': 3.902475694096422e-06, 'epoch': 0.21950486118071563}\n",
      "{'loss': 2.7885, 'grad_norm': 3.6682515144348145, 'learning_rate': 3.897464167585447e-06, 'epoch': 0.2205071664829107}\n",
      "{'loss': 2.1241, 'grad_norm': 1.7705563306808472, 'learning_rate': 3.892452641074472e-06, 'epoch': 0.22150947178510574}\n",
      "{'loss': 2.0084, 'grad_norm': 5.568841457366943, 'learning_rate': 3.887441114563496e-06, 'epoch': 0.2225117770873008}\n",
      "{'loss': 2.4506, 'grad_norm': 7.598016262054443, 'learning_rate': 3.882429588052521e-06, 'epoch': 0.22351408238949583}\n",
      "{'loss': 2.3775, 'grad_norm': 3.000760078430176, 'learning_rate': 3.877418061541546e-06, 'epoch': 0.22451638769169088}\n",
      "{'loss': 3.0364, 'grad_norm': 3.85306978225708, 'learning_rate': 3.87240653503057e-06, 'epoch': 0.22551869299388594}\n",
      "{'loss': 2.8791, 'grad_norm': 4.427515983581543, 'learning_rate': 3.8673950085195955e-06, 'epoch': 0.226520998296081}\n",
      "{'loss': 3.1653, 'grad_norm': 6.967957973480225, 'learning_rate': 3.862383482008621e-06, 'epoch': 0.22752330359827602}\n",
      "{'loss': 2.9851, 'grad_norm': 6.19866418838501, 'learning_rate': 3.857371955497644e-06, 'epoch': 0.22852560890047108}\n",
      "{'loss': 2.1992, 'grad_norm': 4.086309909820557, 'learning_rate': 3.8523604289866695e-06, 'epoch': 0.22952791420266613}\n",
      "{'loss': 2.0741, 'grad_norm': 5.049746990203857, 'learning_rate': 3.847348902475695e-06, 'epoch': 0.2305302195048612}\n",
      "{'loss': 2.7246, 'grad_norm': 3.5744569301605225, 'learning_rate': 3.842337375964719e-06, 'epoch': 0.23153252480705622}\n",
      "{'loss': 3.6787, 'grad_norm': 7.710533142089844, 'learning_rate': 3.837325849453744e-06, 'epoch': 0.23253483010925127}\n",
      "{'loss': 2.7966, 'grad_norm': 3.4966180324554443, 'learning_rate': 3.832314322942769e-06, 'epoch': 0.23353713541144633}\n",
      "{'loss': 2.9313, 'grad_norm': 4.473230838775635, 'learning_rate': 3.827302796431793e-06, 'epoch': 0.23453944071364138}\n",
      "{'loss': 2.2413, 'grad_norm': 7.48297643661499, 'learning_rate': 3.822291269920818e-06, 'epoch': 0.2355417460158364}\n",
      "{'loss': 2.4369, 'grad_norm': 4.2923078536987305, 'learning_rate': 3.8172797434098426e-06, 'epoch': 0.23654405131803147}\n",
      "{'loss': 2.9614, 'grad_norm': 9.227703094482422, 'learning_rate': 3.8122682168988678e-06, 'epoch': 0.23754635662022652}\n",
      "{'loss': 1.7831, 'grad_norm': 9.898566246032715, 'learning_rate': 3.8072566903878926e-06, 'epoch': 0.23854866192242158}\n",
      "{'loss': 2.2362, 'grad_norm': 9.180255889892578, 'learning_rate': 3.802245163876917e-06, 'epoch': 0.2395509672246166}\n",
      "{'loss': 3.3557, 'grad_norm': 16.555551528930664, 'learning_rate': 3.7972336373659417e-06, 'epoch': 0.24055327252681166}\n",
      "{'loss': 2.3727, 'grad_norm': 3.763414144515991, 'learning_rate': 3.792222110854967e-06, 'epoch': 0.24155557782900672}\n",
      "{'loss': 3.2535, 'grad_norm': 16.399517059326172, 'learning_rate': 3.7872105843439917e-06, 'epoch': 0.24255788313120177}\n",
      "{'loss': 2.3001, 'grad_norm': 5.361484527587891, 'learning_rate': 3.7821990578330165e-06, 'epoch': 0.2435601884333968}\n",
      "{'loss': 2.4915, 'grad_norm': 4.085471153259277, 'learning_rate': 3.777187531322041e-06, 'epoch': 0.24456249373559186}\n",
      "{'loss': 2.2163, 'grad_norm': 5.4262847900390625, 'learning_rate': 3.7721760048110657e-06, 'epoch': 0.2455647990377869}\n",
      "{'loss': 2.9194, 'grad_norm': 0.0, 'learning_rate': 3.7671644783000904e-06, 'epoch': 0.24656710433998197}\n",
      "{'loss': 2.7631, 'grad_norm': 5.966495037078857, 'learning_rate': 3.7621529517891152e-06, 'epoch': 0.247569409642177}\n",
      "{'loss': 2.8831, 'grad_norm': 4.673837184906006, 'learning_rate': 3.75714142527814e-06, 'epoch': 0.24857171494437205}\n",
      "{'loss': 2.0164, 'grad_norm': 7.356858730316162, 'learning_rate': 3.7521298987671652e-06, 'epoch': 0.2495740202465671}\n",
      "{'loss': 2.4285, 'grad_norm': 11.58426284790039, 'learning_rate': 3.747118372256189e-06, 'epoch': 0.25057632554876214}\n",
      "{'loss': 3.0732, 'grad_norm': 5.075815677642822, 'learning_rate': 3.7421068457452144e-06, 'epoch': 0.2515786308509572}\n",
      "{'loss': 2.6235, 'grad_norm': 2.886383295059204, 'learning_rate': 3.737095319234239e-06, 'epoch': 0.25258093615315225}\n",
      "{'loss': 2.757, 'grad_norm': 4.143489360809326, 'learning_rate': 3.732083792723264e-06, 'epoch': 0.2535832414553473}\n",
      "{'loss': 2.5358, 'grad_norm': 26.65129280090332, 'learning_rate': 3.7270722662122887e-06, 'epoch': 0.25458554675754236}\n",
      "{'loss': 3.0482, 'grad_norm': 9.986878395080566, 'learning_rate': 3.722060739701313e-06, 'epoch': 0.2555878520597374}\n",
      "{'loss': 1.8866, 'grad_norm': 1.4524210691452026, 'learning_rate': 3.717049213190338e-06, 'epoch': 0.25659015736193247}\n",
      "{'loss': 2.7976, 'grad_norm': 5.340603828430176, 'learning_rate': 3.7120376866793627e-06, 'epoch': 0.2575924626641275}\n",
      "{'loss': 1.6995, 'grad_norm': 5.147479057312012, 'learning_rate': 3.707026160168388e-06, 'epoch': 0.2585947679663225}\n",
      "{'loss': 2.7332, 'grad_norm': 19.228544235229492, 'learning_rate': 3.7020146336574127e-06, 'epoch': 0.2595970732685176}\n",
      "{'loss': 2.9187, 'grad_norm': 8.755763053894043, 'learning_rate': 3.697003107146437e-06, 'epoch': 0.26059937857071264}\n",
      "{'loss': 2.3233, 'grad_norm': 5.430501461029053, 'learning_rate': 3.691991580635462e-06, 'epoch': 0.26160168387290766}\n",
      "{'loss': 2.6562, 'grad_norm': 5.991010665893555, 'learning_rate': 3.6869800541244866e-06, 'epoch': 0.26260398917510275}\n",
      "{'loss': 1.9006, 'grad_norm': 7.820087909698486, 'learning_rate': 3.6819685276135114e-06, 'epoch': 0.2636062944772978}\n",
      "{'loss': 2.3469, 'grad_norm': 5.43897819519043, 'learning_rate': 3.676957001102536e-06, 'epoch': 0.26460859977949286}\n",
      "{'loss': 3.0808, 'grad_norm': 4.889864921569824, 'learning_rate': 3.671945474591561e-06, 'epoch': 0.2656109050816879}\n",
      "{'loss': 2.4666, 'grad_norm': 5.522496223449707, 'learning_rate': 3.6669339480805853e-06, 'epoch': 0.2666132103838829}\n",
      "{'loss': 2.3449, 'grad_norm': 13.832853317260742, 'learning_rate': 3.66192242156961e-06, 'epoch': 0.267615515686078}\n",
      "{'loss': 2.1315, 'grad_norm': 6.325582504272461, 'learning_rate': 3.6569108950586353e-06, 'epoch': 0.268617820988273}\n",
      "{'loss': 2.3351, 'grad_norm': 4.697901725769043, 'learning_rate': 3.65189936854766e-06, 'epoch': 0.26962012629046805}\n",
      "{'loss': 2.6272, 'grad_norm': 10.561613082885742, 'learning_rate': 3.646887842036685e-06, 'epoch': 0.27062243159266314}\n",
      "{'loss': 2.6976, 'grad_norm': 5.965565204620361, 'learning_rate': 3.6418763155257093e-06, 'epoch': 0.27162473689485817}\n",
      "{'loss': 2.3323, 'grad_norm': 4.662708282470703, 'learning_rate': 3.636864789014734e-06, 'epoch': 0.27262704219705325}\n",
      "{'loss': 2.1044, 'grad_norm': 9.33105182647705, 'learning_rate': 3.631853262503759e-06, 'epoch': 0.2736293474992483}\n",
      "{'loss': 1.9059, 'grad_norm': 2.1098098754882812, 'learning_rate': 3.6268417359927836e-06, 'epoch': 0.2746316528014433}\n",
      "{'loss': 2.0648, 'grad_norm': 3.769129514694214, 'learning_rate': 3.6218302094818084e-06, 'epoch': 0.2756339581036384}\n",
      "{'loss': 1.54, 'grad_norm': 5.938310623168945, 'learning_rate': 3.616818682970833e-06, 'epoch': 0.2766362634058334}\n",
      "{'loss': 1.5354, 'grad_norm': 4.731953144073486, 'learning_rate': 3.611807156459858e-06, 'epoch': 0.27763856870802844}\n",
      "{'loss': 2.0418, 'grad_norm': 6.68377161026001, 'learning_rate': 3.6067956299488828e-06, 'epoch': 0.2786408740102235}\n",
      "{'loss': 1.9632, 'grad_norm': 6.5891876220703125, 'learning_rate': 3.6017841034379076e-06, 'epoch': 0.27964317931241855}\n",
      "{'loss': 2.8584, 'grad_norm': 4.38326358795166, 'learning_rate': 3.5967725769269324e-06, 'epoch': 0.28064548461461364}\n",
      "{'loss': 2.6217, 'grad_norm': 20.659841537475586, 'learning_rate': 3.591761050415957e-06, 'epoch': 0.28164778991680867}\n",
      "{'loss': 2.2817, 'grad_norm': 3.23598313331604, 'learning_rate': 3.5867495239049815e-06, 'epoch': 0.2826500952190037}\n",
      "{'loss': 2.6846, 'grad_norm': 4.2439775466918945, 'learning_rate': 3.5817379973940063e-06, 'epoch': 0.2836524005211988}\n",
      "{'loss': 3.0156, 'grad_norm': 4.294175148010254, 'learning_rate': 3.576726470883031e-06, 'epoch': 0.2846547058233938}\n",
      "{'loss': 2.1754, 'grad_norm': 1.9559415578842163, 'learning_rate': 3.5717149443720563e-06, 'epoch': 0.28565701112558883}\n",
      "{'loss': 3.3154, 'grad_norm': 4.115640163421631, 'learning_rate': 3.566703417861081e-06, 'epoch': 0.2866593164277839}\n",
      "{'loss': 2.5086, 'grad_norm': 5.589547157287598, 'learning_rate': 3.5616918913501054e-06, 'epoch': 0.28766162172997894}\n",
      "{'loss': 3.0899, 'grad_norm': 6.035782814025879, 'learning_rate': 3.5566803648391302e-06, 'epoch': 0.288663927032174}\n",
      "{'loss': 2.013, 'grad_norm': 4.647012233734131, 'learning_rate': 3.551668838328155e-06, 'epoch': 0.28966623233436906}\n",
      "{'loss': 3.4793, 'grad_norm': 4.704859256744385, 'learning_rate': 3.54665731181718e-06, 'epoch': 0.2906685376365641}\n",
      "{'loss': 3.2938, 'grad_norm': 0.0, 'learning_rate': 3.5416457853062046e-06, 'epoch': 0.29167084293875917}\n",
      "{'loss': 2.5878, 'grad_norm': 3.8762567043304443, 'learning_rate': 3.5366342587952294e-06, 'epoch': 0.2926731482409542}\n",
      "{'loss': 2.375, 'grad_norm': 5.470832824707031, 'learning_rate': 3.5316227322842537e-06, 'epoch': 0.2936754535431492}\n",
      "{'loss': 1.5597, 'grad_norm': 4.3815765380859375, 'learning_rate': 3.526611205773279e-06, 'epoch': 0.2946777588453443}\n",
      "{'loss': 2.4564, 'grad_norm': 5.303766250610352, 'learning_rate': 3.5215996792623037e-06, 'epoch': 0.29568006414753933}\n",
      "{'loss': 1.9325, 'grad_norm': 1.7463417053222656, 'learning_rate': 3.5165881527513285e-06, 'epoch': 0.29668236944973436}\n",
      "{'loss': 2.4689, 'grad_norm': 2.8411107063293457, 'learning_rate': 3.5115766262403533e-06, 'epoch': 0.29768467475192945}\n",
      "{'loss': 2.97, 'grad_norm': 10.844931602478027, 'learning_rate': 3.5065650997293777e-06, 'epoch': 0.2986869800541245}\n",
      "{'loss': 2.4973, 'grad_norm': 6.178677082061768, 'learning_rate': 3.5015535732184025e-06, 'epoch': 0.29968928535631956}\n",
      "{'loss': 2.4424, 'grad_norm': 8.318792343139648, 'learning_rate': 3.4965420467074273e-06, 'epoch': 0.3006915906585146}\n",
      "{'loss': 2.6424, 'grad_norm': 5.273805141448975, 'learning_rate': 3.491530520196452e-06, 'epoch': 0.3016938959607096}\n",
      "{'loss': 2.5208, 'grad_norm': 7.842569351196289, 'learning_rate': 3.4865189936854773e-06, 'epoch': 0.3026962012629047}\n",
      "{'loss': 1.78, 'grad_norm': 10.224260330200195, 'learning_rate': 3.481507467174501e-06, 'epoch': 0.3036985065650997}\n",
      "{'loss': 1.8532, 'grad_norm': 4.269545078277588, 'learning_rate': 3.4764959406635264e-06, 'epoch': 0.30470081186729475}\n",
      "{'loss': 2.3479, 'grad_norm': 3.698432445526123, 'learning_rate': 3.471484414152551e-06, 'epoch': 0.30570311716948984}\n",
      "{'loss': 1.874, 'grad_norm': 1.7786035537719727, 'learning_rate': 3.466472887641576e-06, 'epoch': 0.30670542247168486}\n",
      "{'loss': 2.5543, 'grad_norm': 6.450999736785889, 'learning_rate': 3.4614613611306008e-06, 'epoch': 0.30770772777387995}\n",
      "{'loss': 2.1872, 'grad_norm': 5.356010913848877, 'learning_rate': 3.4564498346196256e-06, 'epoch': 0.308710033076075}\n",
      "{'loss': 2.2301, 'grad_norm': 6.091745853424072, 'learning_rate': 3.45143830810865e-06, 'epoch': 0.30971233837827}\n",
      "{'loss': 2.6642, 'grad_norm': 4.5881242752075195, 'learning_rate': 3.4464267815976747e-06, 'epoch': 0.3107146436804651}\n",
      "{'loss': 1.7577, 'grad_norm': 3.5499346256256104, 'learning_rate': 3.4414152550867e-06, 'epoch': 0.3117169489826601}\n",
      "{'loss': 2.7572, 'grad_norm': 7.814870834350586, 'learning_rate': 3.4364037285757247e-06, 'epoch': 0.31271925428485514}\n",
      "{'loss': 2.1794, 'grad_norm': 5.625129699707031, 'learning_rate': 3.4313922020647495e-06, 'epoch': 0.3137215595870502}\n",
      "{'loss': 1.8626, 'grad_norm': 9.566298484802246, 'learning_rate': 3.426380675553774e-06, 'epoch': 0.31472386488924525}\n",
      "{'loss': 1.6681, 'grad_norm': 5.389977931976318, 'learning_rate': 3.4213691490427986e-06, 'epoch': 0.31572617019144034}\n",
      "{'loss': 1.6495, 'grad_norm': 4.468438625335693, 'learning_rate': 3.4163576225318234e-06, 'epoch': 0.31672847549363536}\n",
      "{'loss': 2.5444, 'grad_norm': 7.164989948272705, 'learning_rate': 3.4113460960208482e-06, 'epoch': 0.3177307807958304}\n",
      "{'loss': 2.4306, 'grad_norm': 4.284827709197998, 'learning_rate': 3.406334569509873e-06, 'epoch': 0.3187330860980255}\n",
      "{'loss': 1.8297, 'grad_norm': 9.010871887207031, 'learning_rate': 3.4013230429988974e-06, 'epoch': 0.3197353914002205}\n",
      "{'loss': 2.8587, 'grad_norm': 5.461872100830078, 'learning_rate': 3.396311516487922e-06, 'epoch': 0.32073769670241553}\n",
      "{'loss': 2.4917, 'grad_norm': 14.17972469329834, 'learning_rate': 3.3912999899769474e-06, 'epoch': 0.3217400020046106}\n",
      "{'loss': 2.4465, 'grad_norm': 12.10483169555664, 'learning_rate': 3.386288463465972e-06, 'epoch': 0.32274230730680564}\n",
      "{'loss': 2.8361, 'grad_norm': 8.216643333435059, 'learning_rate': 3.381276936954997e-06, 'epoch': 0.3237446126090007}\n",
      "{'loss': 2.4735, 'grad_norm': 6.487447738647461, 'learning_rate': 3.3762654104440217e-06, 'epoch': 0.32474691791119575}\n",
      "{'loss': 2.8942, 'grad_norm': 6.63485050201416, 'learning_rate': 3.371253883933046e-06, 'epoch': 0.3257492232133908}\n",
      "{'loss': 2.9003, 'grad_norm': 9.483602523803711, 'learning_rate': 3.366242357422071e-06, 'epoch': 0.32675152851558587}\n",
      "{'loss': 1.8847, 'grad_norm': 6.141849994659424, 'learning_rate': 3.3612308309110957e-06, 'epoch': 0.3277538338177809}\n",
      "{'loss': 3.2349, 'grad_norm': 8.037038803100586, 'learning_rate': 3.356219304400121e-06, 'epoch': 0.3287561391199759}\n",
      "{'loss': 2.2672, 'grad_norm': 5.861199855804443, 'learning_rate': 3.3512077778891457e-06, 'epoch': 0.329758444422171}\n",
      "{'loss': 1.8523, 'grad_norm': 6.774704456329346, 'learning_rate': 3.34619625137817e-06, 'epoch': 0.33076074972436603}\n",
      "{'loss': 1.5165, 'grad_norm': 8.073539733886719, 'learning_rate': 3.341184724867195e-06, 'epoch': 0.3317630550265611}\n",
      "{'loss': 2.1096, 'grad_norm': 5.67478609085083, 'learning_rate': 3.3361731983562196e-06, 'epoch': 0.33276536032875614}\n",
      "{'loss': 2.2428, 'grad_norm': 4.953406810760498, 'learning_rate': 3.3311616718452444e-06, 'epoch': 0.33376766563095117}\n",
      "{'loss': 2.1802, 'grad_norm': 10.622106552124023, 'learning_rate': 3.326150145334269e-06, 'epoch': 0.33476997093314625}\n",
      "{'loss': 2.0045, 'grad_norm': 4.469037055969238, 'learning_rate': 3.3211386188232935e-06, 'epoch': 0.3357722762353413}\n",
      "{'loss': 2.3207, 'grad_norm': 5.994816303253174, 'learning_rate': 3.3161270923123183e-06, 'epoch': 0.3367745815375363}\n",
      "{'loss': 2.9586, 'grad_norm': 4.688416957855225, 'learning_rate': 3.311115565801343e-06, 'epoch': 0.3377768868397314}\n",
      "{'loss': 2.7614, 'grad_norm': 2.057157278060913, 'learning_rate': 3.3061040392903683e-06, 'epoch': 0.3387791921419264}\n",
      "{'loss': 2.3124, 'grad_norm': 4.668344020843506, 'learning_rate': 3.301092512779393e-06, 'epoch': 0.3397814974441215}\n",
      "{'loss': 1.6271, 'grad_norm': 7.83156681060791, 'learning_rate': 3.296080986268418e-06, 'epoch': 0.34078380274631653}\n",
      "{'loss': 1.8577, 'grad_norm': 8.576399803161621, 'learning_rate': 3.2910694597574423e-06, 'epoch': 0.34178610804851156}\n",
      "{'loss': 2.7111, 'grad_norm': 17.242753982543945, 'learning_rate': 3.286057933246467e-06, 'epoch': 0.34278841335070664}\n",
      "{'loss': 2.3599, 'grad_norm': 8.182806015014648, 'learning_rate': 3.281046406735492e-06, 'epoch': 0.3437907186529017}\n",
      "{'loss': 2.2732, 'grad_norm': 6.85988712310791, 'learning_rate': 3.2760348802245166e-06, 'epoch': 0.3447930239550967}\n",
      "{'loss': 2.7341, 'grad_norm': 7.976256847381592, 'learning_rate': 3.271023353713542e-06, 'epoch': 0.3457953292572918}\n",
      "{'loss': 1.5086, 'grad_norm': 19.0728702545166, 'learning_rate': 3.2660118272025658e-06, 'epoch': 0.3467976345594868}\n",
      "{'loss': 2.1274, 'grad_norm': 3.282703161239624, 'learning_rate': 3.261000300691591e-06, 'epoch': 0.3477999398616819}\n",
      "{'loss': 2.2209, 'grad_norm': 7.879927635192871, 'learning_rate': 3.2559887741806158e-06, 'epoch': 0.3488022451638769}\n",
      "{'loss': 1.1771, 'grad_norm': 6.546483993530273, 'learning_rate': 3.2509772476696406e-06, 'epoch': 0.34980455046607195}\n",
      "{'loss': 1.723, 'grad_norm': 6.140710830688477, 'learning_rate': 3.2459657211586653e-06, 'epoch': 0.35080685576826703}\n",
      "{'loss': 1.766, 'grad_norm': 6.895328521728516, 'learning_rate': 3.2409541946476897e-06, 'epoch': 0.35180916107046206}\n",
      "{'loss': 2.2945, 'grad_norm': 3.327061176300049, 'learning_rate': 3.2359426681367145e-06, 'epoch': 0.3528114663726571}\n",
      "{'loss': 2.5832, 'grad_norm': 3.9161479473114014, 'learning_rate': 3.2309311416257393e-06, 'epoch': 0.3538137716748522}\n",
      "{'loss': 2.2717, 'grad_norm': 13.604774475097656, 'learning_rate': 3.225919615114764e-06, 'epoch': 0.3548160769770472}\n",
      "{'loss': 2.8408, 'grad_norm': 4.925273418426514, 'learning_rate': 3.2209080886037893e-06, 'epoch': 0.3558183822792423}\n",
      "{'loss': 3.3295, 'grad_norm': 5.373022079467773, 'learning_rate': 3.215896562092814e-06, 'epoch': 0.3568206875814373}\n",
      "{'loss': 2.3198, 'grad_norm': 4.4040937423706055, 'learning_rate': 3.2108850355818384e-06, 'epoch': 0.35782299288363234}\n",
      "{'loss': 1.5311, 'grad_norm': 3.578099489212036, 'learning_rate': 3.2058735090708632e-06, 'epoch': 0.3588252981858274}\n",
      "{'loss': 2.0167, 'grad_norm': 10.789600372314453, 'learning_rate': 3.200861982559888e-06, 'epoch': 0.35982760348802245}\n",
      "{'loss': 1.6924, 'grad_norm': 7.9600911140441895, 'learning_rate': 3.195850456048913e-06, 'epoch': 0.3608299087902175}\n",
      "{'loss': 1.6356, 'grad_norm': 5.065760612487793, 'learning_rate': 3.1908389295379376e-06, 'epoch': 0.36183221409241256}\n",
      "{'loss': 2.6235, 'grad_norm': 11.07030200958252, 'learning_rate': 3.185827403026962e-06, 'epoch': 0.3628345193946076}\n",
      "{'loss': 1.4336, 'grad_norm': 11.434943199157715, 'learning_rate': 3.1808158765159867e-06, 'epoch': 0.3638368246968026}\n",
      "{'loss': 2.2204, 'grad_norm': 4.4464640617370605, 'learning_rate': 3.175804350005012e-06, 'epoch': 0.3648391299989977}\n",
      "{'loss': 2.5478, 'grad_norm': 4.370051383972168, 'learning_rate': 3.1707928234940367e-06, 'epoch': 0.36584143530119273}\n",
      "{'loss': 1.5374, 'grad_norm': 0.0, 'learning_rate': 3.1657812969830615e-06, 'epoch': 0.3668437406033878}\n",
      "{'loss': 2.2523, 'grad_norm': 9.086613655090332, 'learning_rate': 3.1607697704720863e-06, 'epoch': 0.36784604590558284}\n",
      "{'loss': 2.2603, 'grad_norm': 9.122641563415527, 'learning_rate': 3.1557582439611107e-06, 'epoch': 0.36884835120777787}\n",
      "{'loss': 2.4392, 'grad_norm': 6.253925323486328, 'learning_rate': 3.1507467174501355e-06, 'epoch': 0.36985065650997295}\n",
      "{'loss': 1.8744, 'grad_norm': 15.467220306396484, 'learning_rate': 3.1457351909391602e-06, 'epoch': 0.370852961812168}\n",
      "{'loss': 2.7626, 'grad_norm': 6.370115756988525, 'learning_rate': 3.140723664428185e-06, 'epoch': 0.371855267114363}\n",
      "{'loss': 2.3443, 'grad_norm': 14.721809387207031, 'learning_rate': 3.1357121379172102e-06, 'epoch': 0.3728575724165581}\n",
      "{'loss': 2.2865, 'grad_norm': 3.1288135051727295, 'learning_rate': 3.130700611406234e-06, 'epoch': 0.3738598777187531}\n",
      "{'loss': 2.368, 'grad_norm': 8.820817947387695, 'learning_rate': 3.1256890848952594e-06, 'epoch': 0.3748621830209482}\n",
      "{'loss': 2.0684, 'grad_norm': 21.995954513549805, 'learning_rate': 3.120677558384284e-06, 'epoch': 0.37586448832314323}\n",
      "{'loss': 2.51, 'grad_norm': 5.852783203125, 'learning_rate': 3.115666031873309e-06, 'epoch': 0.37686679362533826}\n",
      "{'loss': 2.6305, 'grad_norm': 5.762824535369873, 'learning_rate': 3.1106545053623338e-06, 'epoch': 0.37786909892753334}\n",
      "{'loss': 2.1439, 'grad_norm': 6.438563346862793, 'learning_rate': 3.105642978851358e-06, 'epoch': 0.37887140422972837}\n",
      "{'loss': 2.9201, 'grad_norm': 6.93837308883667, 'learning_rate': 3.100631452340383e-06, 'epoch': 0.3798737095319234}\n",
      "{'loss': 2.4524, 'grad_norm': 7.564433574676514, 'learning_rate': 3.0956199258294077e-06, 'epoch': 0.3808760148341185}\n",
      "{'loss': 1.2525, 'grad_norm': 5.60962438583374, 'learning_rate': 3.090608399318433e-06, 'epoch': 0.3818783201363135}\n",
      "{'loss': 1.7163, 'grad_norm': 20.591400146484375, 'learning_rate': 3.0855968728074577e-06, 'epoch': 0.3828806254385086}\n",
      "{'loss': 1.5798, 'grad_norm': 4.112328052520752, 'learning_rate': 3.0805853462964825e-06, 'epoch': 0.3838829307407036}\n",
      "{'loss': 2.0847, 'grad_norm': 4.535954475402832, 'learning_rate': 3.075573819785507e-06, 'epoch': 0.38488523604289865}\n",
      "{'loss': 2.4176, 'grad_norm': 4.97664737701416, 'learning_rate': 3.0705622932745316e-06, 'epoch': 0.38588754134509373}\n",
      "{'loss': 2.35, 'grad_norm': 4.537809371948242, 'learning_rate': 3.0655507667635564e-06, 'epoch': 0.38688984664728876}\n",
      "{'loss': 1.7916, 'grad_norm': 6.826305866241455, 'learning_rate': 3.060539240252581e-06, 'epoch': 0.3878921519494838}\n",
      "{'loss': 2.5588, 'grad_norm': 6.706798553466797, 'learning_rate': 3.055527713741606e-06, 'epoch': 0.38889445725167887}\n",
      "{'loss': 2.0247, 'grad_norm': 6.4519219398498535, 'learning_rate': 3.0505161872306304e-06, 'epoch': 0.3898967625538739}\n",
      "{'loss': 3.146, 'grad_norm': 5.9981513023376465, 'learning_rate': 3.045504660719655e-06, 'epoch': 0.390899067856069}\n",
      "{'loss': 2.1039, 'grad_norm': 7.074691295623779, 'learning_rate': 3.0404931342086804e-06, 'epoch': 0.391901373158264}\n",
      "{'loss': 2.3009, 'grad_norm': 10.273667335510254, 'learning_rate': 3.035481607697705e-06, 'epoch': 0.39290367846045904}\n",
      "{'loss': 2.6602, 'grad_norm': 2.793617010116577, 'learning_rate': 3.03047008118673e-06, 'epoch': 0.3939059837626541}\n",
      "{'loss': 1.1173, 'grad_norm': 6.235503673553467, 'learning_rate': 3.0254585546757543e-06, 'epoch': 0.39490828906484915}\n",
      "{'loss': 1.4941, 'grad_norm': 16.892610549926758, 'learning_rate': 3.020447028164779e-06, 'epoch': 0.3959105943670442}\n",
      "{'loss': 1.7965, 'grad_norm': 8.1223783493042, 'learning_rate': 3.015435501653804e-06, 'epoch': 0.39691289966923926}\n",
      "{'loss': 1.8757, 'grad_norm': 6.417757034301758, 'learning_rate': 3.0104239751428287e-06, 'epoch': 0.3979152049714343}\n",
      "{'loss': 1.8712, 'grad_norm': 6.945756912231445, 'learning_rate': 3.005412448631854e-06, 'epoch': 0.39891751027362937}\n",
      "{'loss': 2.8536, 'grad_norm': 8.335477828979492, 'learning_rate': 3.0004009221208787e-06, 'epoch': 0.3999198155758244}\n",
      "{'loss': 2.1636, 'grad_norm': 9.88039779663086, 'learning_rate': 2.995389395609903e-06, 'epoch': 0.40092212087801943}\n",
      "{'loss': 1.4148, 'grad_norm': 37.70711135864258, 'learning_rate': 2.990377869098928e-06, 'epoch': 0.4019244261802145}\n",
      "{'loss': 1.7483, 'grad_norm': 0.984139084815979, 'learning_rate': 2.9853663425879526e-06, 'epoch': 0.40292673148240954}\n",
      "{'loss': 2.2593, 'grad_norm': 7.330048084259033, 'learning_rate': 2.9803548160769774e-06, 'epoch': 0.40392903678460457}\n",
      "{'loss': 2.3796, 'grad_norm': 4.235602855682373, 'learning_rate': 2.975343289566002e-06, 'epoch': 0.40493134208679965}\n",
      "{'loss': 1.8604, 'grad_norm': 10.754222869873047, 'learning_rate': 2.9703317630550265e-06, 'epoch': 0.4059336473889947}\n",
      "{'loss': 2.5577, 'grad_norm': 4.449010848999023, 'learning_rate': 2.9653202365440513e-06, 'epoch': 0.40693595269118976}\n",
      "{'loss': 2.0021, 'grad_norm': 6.321417331695557, 'learning_rate': 2.960308710033076e-06, 'epoch': 0.4079382579933848}\n",
      "{'loss': 2.1516, 'grad_norm': 4.377049446105957, 'learning_rate': 2.9552971835221013e-06, 'epoch': 0.4089405632955798}\n",
      "{'loss': 1.9333, 'grad_norm': 7.185559272766113, 'learning_rate': 2.950285657011126e-06, 'epoch': 0.4099428685977749}\n",
      "{'loss': 2.3719, 'grad_norm': 4.923543453216553, 'learning_rate': 2.9452741305001505e-06, 'epoch': 0.41094517389996993}\n",
      "{'loss': 2.6752, 'grad_norm': 9.322296142578125, 'learning_rate': 2.9402626039891753e-06, 'epoch': 0.41194747920216496}\n",
      "{'loss': 2.584, 'grad_norm': 6.2320661544799805, 'learning_rate': 2.9352510774782e-06, 'epoch': 0.41294978450436004}\n",
      "{'loss': 2.8096, 'grad_norm': 9.803314208984375, 'learning_rate': 2.930239550967225e-06, 'epoch': 0.41395208980655507}\n",
      "{'loss': 1.9296, 'grad_norm': 6.210744857788086, 'learning_rate': 2.9252280244562496e-06, 'epoch': 0.41495439510875015}\n",
      "{'loss': 2.5599, 'grad_norm': 20.6085147857666, 'learning_rate': 2.920216497945275e-06, 'epoch': 0.4159567004109452}\n",
      "{'loss': 2.133, 'grad_norm': 6.9793009757995605, 'learning_rate': 2.9152049714342988e-06, 'epoch': 0.4169590057131402}\n",
      "{'loss': 1.7462, 'grad_norm': 1.212149977684021, 'learning_rate': 2.910193444923324e-06, 'epoch': 0.4179613110153353}\n",
      "{'loss': 2.3817, 'grad_norm': 0.0, 'learning_rate': 2.9051819184123488e-06, 'epoch': 0.4189636163175303}\n",
      "{'loss': 2.4778, 'grad_norm': 10.93693733215332, 'learning_rate': 2.9001703919013735e-06, 'epoch': 0.41996592161972535}\n",
      "{'loss': 1.9794, 'grad_norm': 3.554055690765381, 'learning_rate': 2.8951588653903983e-06, 'epoch': 0.42096822692192043}\n",
      "{'loss': 2.6096, 'grad_norm': 9.812811851501465, 'learning_rate': 2.8901473388794227e-06, 'epoch': 0.42197053222411546}\n",
      "{'loss': 2.58, 'grad_norm': 7.036639213562012, 'learning_rate': 2.8851358123684475e-06, 'epoch': 0.42297283752631054}\n",
      "{'loss': 2.1541, 'grad_norm': 5.882443428039551, 'learning_rate': 2.8801242858574723e-06, 'epoch': 0.42397514282850557}\n",
      "{'loss': 1.9307, 'grad_norm': 8.979750633239746, 'learning_rate': 2.875112759346497e-06, 'epoch': 0.4249774481307006}\n",
      "{'loss': 2.2452, 'grad_norm': 6.585143566131592, 'learning_rate': 2.8701012328355223e-06, 'epoch': 0.4259797534328957}\n",
      "{'loss': 2.0475, 'grad_norm': 9.821420669555664, 'learning_rate': 2.8650897063245462e-06, 'epoch': 0.4269820587350907}\n",
      "{'loss': 3.0726, 'grad_norm': 9.128169059753418, 'learning_rate': 2.8600781798135714e-06, 'epoch': 0.42798436403728574}\n",
      "{'loss': 2.1076, 'grad_norm': 24.143041610717773, 'learning_rate': 2.855066653302596e-06, 'epoch': 0.4289866693394808}\n",
      "{'loss': 1.7788, 'grad_norm': 3.7063426971435547, 'learning_rate': 2.850055126791621e-06, 'epoch': 0.42998897464167585}\n",
      "{'loss': 1.7464, 'grad_norm': 2.3524038791656494, 'learning_rate': 2.8450436002806458e-06, 'epoch': 0.43099127994387093}\n",
      "{'loss': 2.9608, 'grad_norm': 10.611016273498535, 'learning_rate': 2.8400320737696706e-06, 'epoch': 0.43199358524606596}\n",
      "{'loss': 1.7419, 'grad_norm': 12.159051895141602, 'learning_rate': 2.835020547258695e-06, 'epoch': 0.432995890548261}\n",
      "{'loss': 1.9825, 'grad_norm': 5.679717540740967, 'learning_rate': 2.8300090207477197e-06, 'epoch': 0.43399819585045607}\n",
      "{'loss': 2.5665, 'grad_norm': 6.07413911819458, 'learning_rate': 2.824997494236745e-06, 'epoch': 0.4350005011526511}\n",
      "{'loss': 2.6405, 'grad_norm': 11.531157493591309, 'learning_rate': 2.8199859677257697e-06, 'epoch': 0.4360028064548461}\n",
      "{'loss': 2.7815, 'grad_norm': 7.056028366088867, 'learning_rate': 2.8149744412147945e-06, 'epoch': 0.4370051117570412}\n",
      "{'loss': 2.6573, 'grad_norm': 4.851510524749756, 'learning_rate': 2.809962914703819e-06, 'epoch': 0.43800741705923624}\n",
      "{'loss': 1.9647, 'grad_norm': 13.780204772949219, 'learning_rate': 2.8049513881928437e-06, 'epoch': 0.43900972236143126}\n",
      "{'loss': 1.9027, 'grad_norm': 6.673356533050537, 'learning_rate': 2.7999398616818684e-06, 'epoch': 0.44001202766362635}\n",
      "{'loss': 2.5715, 'grad_norm': 4.309848785400391, 'learning_rate': 2.7949283351708932e-06, 'epoch': 0.4410143329658214}\n",
      "{'loss': 2.0565, 'grad_norm': 15.04824161529541, 'learning_rate': 2.789916808659918e-06, 'epoch': 0.44201663826801646}\n",
      "{'loss': 2.6914, 'grad_norm': 6.4732890129089355, 'learning_rate': 2.7849052821489432e-06, 'epoch': 0.4430189435702115}\n",
      "{'loss': 2.7005, 'grad_norm': 12.043770790100098, 'learning_rate': 2.779893755637967e-06, 'epoch': 0.4440212488724065}\n",
      "{'loss': 1.3645, 'grad_norm': 5.8098859786987305, 'learning_rate': 2.7748822291269924e-06, 'epoch': 0.4450235541746016}\n",
      "{'loss': 2.1236, 'grad_norm': 6.28004789352417, 'learning_rate': 2.769870702616017e-06, 'epoch': 0.4460258594767966}\n",
      "{'loss': 2.2552, 'grad_norm': 6.843757152557373, 'learning_rate': 2.764859176105042e-06, 'epoch': 0.44702816477899165}\n",
      "{'loss': 2.2907, 'grad_norm': 4.110901832580566, 'learning_rate': 2.7598476495940667e-06, 'epoch': 0.44803047008118674}\n",
      "{'loss': 1.7151, 'grad_norm': 6.647161960601807, 'learning_rate': 2.754836123083091e-06, 'epoch': 0.44903277538338177}\n",
      "{'loss': 1.9276, 'grad_norm': 4.74801778793335, 'learning_rate': 2.749824596572116e-06, 'epoch': 0.45003508068557685}\n",
      "{'loss': 2.4842, 'grad_norm': 8.128872871398926, 'learning_rate': 2.7448130700611407e-06, 'epoch': 0.4510373859877719}\n",
      "{'loss': 1.9973, 'grad_norm': 9.268205642700195, 'learning_rate': 2.739801543550166e-06, 'epoch': 0.4520396912899669}\n",
      "{'loss': 1.9032, 'grad_norm': 9.304488182067871, 'learning_rate': 2.7347900170391907e-06, 'epoch': 0.453041996592162}\n",
      "{'loss': 1.7244, 'grad_norm': 4.093609809875488, 'learning_rate': 2.729778490528215e-06, 'epoch': 0.454044301894357}\n",
      "{'loss': 0.9755, 'grad_norm': 8.585129737854004, 'learning_rate': 2.72476696401724e-06, 'epoch': 0.45504660719655204}\n",
      "{'loss': 1.9043, 'grad_norm': 4.9836344718933105, 'learning_rate': 2.7197554375062646e-06, 'epoch': 0.4560489124987471}\n",
      "{'loss': 1.5039, 'grad_norm': 9.766236305236816, 'learning_rate': 2.7147439109952894e-06, 'epoch': 0.45705121780094216}\n",
      "{'loss': 1.7678, 'grad_norm': 12.426896095275879, 'learning_rate': 2.709732384484314e-06, 'epoch': 0.45805352310313724}\n",
      "{'loss': 1.9061, 'grad_norm': 4.014437675476074, 'learning_rate': 2.704720857973339e-06, 'epoch': 0.45905582840533227}\n",
      "{'loss': 2.2183, 'grad_norm': 22.355131149291992, 'learning_rate': 2.6997093314623633e-06, 'epoch': 0.4600581337075273}\n",
      "{'loss': 2.274, 'grad_norm': 9.372868537902832, 'learning_rate': 2.694697804951388e-06, 'epoch': 0.4610604390097224}\n",
      "{'loss': 2.5268, 'grad_norm': 5.313300609588623, 'learning_rate': 2.6896862784404133e-06, 'epoch': 0.4620627443119174}\n",
      "{'loss': 2.4942, 'grad_norm': 3.850689172744751, 'learning_rate': 2.684674751929438e-06, 'epoch': 0.46306504961411243}\n",
      "{'loss': 2.7836, 'grad_norm': 9.635771751403809, 'learning_rate': 2.679663225418463e-06, 'epoch': 0.4640673549163075}\n",
      "{'loss': 2.2605, 'grad_norm': 14.028840065002441, 'learning_rate': 2.6746516989074873e-06, 'epoch': 0.46506966021850255}\n",
      "{'loss': 2.1779, 'grad_norm': 9.487627029418945, 'learning_rate': 2.669640172396512e-06, 'epoch': 0.46607196552069763}\n",
      "{'loss': 2.3469, 'grad_norm': 5.998764991760254, 'learning_rate': 2.664628645885537e-06, 'epoch': 0.46707427082289266}\n",
      "{'loss': 2.5554, 'grad_norm': 0.0, 'learning_rate': 2.6596171193745616e-06, 'epoch': 0.4680765761250877}\n",
      "{'loss': 2.229, 'grad_norm': 9.752408981323242, 'learning_rate': 2.654605592863587e-06, 'epoch': 0.46907888142728277}\n",
      "{'loss': 1.164, 'grad_norm': 8.085792541503906, 'learning_rate': 2.649594066352611e-06, 'epoch': 0.4700811867294778}\n",
      "{'loss': 2.4588, 'grad_norm': 8.429322242736816, 'learning_rate': 2.644582539841636e-06, 'epoch': 0.4710834920316728}\n",
      "{'loss': 2.7694, 'grad_norm': 0.0, 'learning_rate': 2.639571013330661e-06, 'epoch': 0.4720857973338679}\n",
      "{'loss': 2.628, 'grad_norm': 10.59199047088623, 'learning_rate': 2.6345594868196856e-06, 'epoch': 0.47308810263606293}\n",
      "{'loss': 1.0864, 'grad_norm': 7.098574161529541, 'learning_rate': 2.6295479603087104e-06, 'epoch': 0.474090407938258}\n",
      "{'loss': 2.6355, 'grad_norm': 13.952662467956543, 'learning_rate': 2.624536433797735e-06, 'epoch': 0.47509271324045305}\n",
      "{'loss': 1.5065, 'grad_norm': 7.604560375213623, 'learning_rate': 2.6195249072867595e-06, 'epoch': 0.4760950185426481}\n",
      "{'loss': 1.9452, 'grad_norm': 2.3884224891662598, 'learning_rate': 2.6145133807757843e-06, 'epoch': 0.47709732384484316}\n",
      "{'loss': 1.6773, 'grad_norm': 17.599210739135742, 'learning_rate': 2.609501854264809e-06, 'epoch': 0.4780996291470382}\n",
      "{'loss': 1.5418, 'grad_norm': 6.154376029968262, 'learning_rate': 2.6044903277538343e-06, 'epoch': 0.4791019344492332}\n",
      "{'loss': 2.1636, 'grad_norm': 9.734192848205566, 'learning_rate': 2.599478801242859e-06, 'epoch': 0.4801042397514283}\n",
      "{'loss': 1.7174, 'grad_norm': 7.201836585998535, 'learning_rate': 2.5944672747318835e-06, 'epoch': 0.4811065450536233}\n",
      "{'loss': 1.9787, 'grad_norm': 5.941685676574707, 'learning_rate': 2.5894557482209082e-06, 'epoch': 0.4821088503558184}\n",
      "{'loss': 1.1522, 'grad_norm': 6.330550670623779, 'learning_rate': 2.584444221709933e-06, 'epoch': 0.48311115565801344}\n",
      "{'loss': 2.9963, 'grad_norm': 6.945063591003418, 'learning_rate': 2.579432695198958e-06, 'epoch': 0.48411346096020846}\n",
      "{'loss': 2.381, 'grad_norm': 7.137120246887207, 'learning_rate': 2.5744211686879826e-06, 'epoch': 0.48511576626240355}\n",
      "{'loss': 1.4271, 'grad_norm': 9.706936836242676, 'learning_rate': 2.569409642177007e-06, 'epoch': 0.4861180715645986}\n",
      "{'loss': 2.7767, 'grad_norm': 10.11169719696045, 'learning_rate': 2.5643981156660318e-06, 'epoch': 0.4871203768667936}\n",
      "{'loss': 2.1461, 'grad_norm': 3.325638771057129, 'learning_rate': 2.559386589155057e-06, 'epoch': 0.4881226821689887}\n",
      "{'loss': 1.7798, 'grad_norm': 4.3815460205078125, 'learning_rate': 2.5543750626440818e-06, 'epoch': 0.4891249874711837}\n",
      "{'loss': 2.3957, 'grad_norm': 4.103870868682861, 'learning_rate': 2.5493635361331065e-06, 'epoch': 0.4901272927733788}\n",
      "{'loss': 2.6049, 'grad_norm': 7.721207141876221, 'learning_rate': 2.5443520096221313e-06, 'epoch': 0.4911295980755738}\n",
      "{'loss': 2.4233, 'grad_norm': 5.627880573272705, 'learning_rate': 2.5393404831111557e-06, 'epoch': 0.49213190337776885}\n",
      "{'loss': 1.9274, 'grad_norm': 5.791383266448975, 'learning_rate': 2.5343289566001805e-06, 'epoch': 0.49313420867996394}\n",
      "{'loss': 1.3189, 'grad_norm': 5.805241107940674, 'learning_rate': 2.5293174300892053e-06, 'epoch': 0.49413651398215896}\n",
      "{'loss': 3.136, 'grad_norm': 0.0, 'learning_rate': 2.52430590357823e-06, 'epoch': 0.495138819284354}\n",
      "{'loss': 2.9308, 'grad_norm': 13.816866874694824, 'learning_rate': 2.5192943770672553e-06, 'epoch': 0.4961411245865491}\n",
      "{'loss': 1.5161, 'grad_norm': 11.572671890258789, 'learning_rate': 2.514282850556279e-06, 'epoch': 0.4971434298887441}\n",
      "{'loss': 1.9471, 'grad_norm': 7.742220401763916, 'learning_rate': 2.5092713240453044e-06, 'epoch': 0.4981457351909392}\n",
      "{'loss': 1.1285, 'grad_norm': 5.917020320892334, 'learning_rate': 2.504259797534329e-06, 'epoch': 0.4991480404931342}\n",
      "{'loss': 1.8255, 'grad_norm': 9.77000617980957, 'learning_rate': 2.499248271023354e-06, 'epoch': 0.5001503457953292}\n",
      "{'loss': 2.2736, 'grad_norm': 4.410143852233887, 'learning_rate': 2.4942367445123788e-06, 'epoch': 0.5011526510975243}\n",
      "{'loss': 1.1185, 'grad_norm': 11.15841007232666, 'learning_rate': 2.4892252180014036e-06, 'epoch': 0.5021549563997194}\n",
      "{'loss': 2.3591, 'grad_norm': 11.320453643798828, 'learning_rate': 2.4842136914904283e-06, 'epoch': 0.5031572617019144}\n",
      "{'loss': 2.0552, 'grad_norm': 4.612081050872803, 'learning_rate': 2.4792021649794527e-06, 'epoch': 0.5041595670041095}\n",
      "{'loss': 2.3649, 'grad_norm': 10.903646469116211, 'learning_rate': 2.474190638468478e-06, 'epoch': 0.5051618723063045}\n",
      "{'loss': 2.1413, 'grad_norm': 6.221031665802002, 'learning_rate': 2.4691791119575027e-06, 'epoch': 0.5061641776084995}\n",
      "{'loss': 2.6203, 'grad_norm': 11.599574089050293, 'learning_rate': 2.464167585446527e-06, 'epoch': 0.5071664829106945}\n",
      "{'loss': 2.3405, 'grad_norm': 9.363826751708984, 'learning_rate': 2.459156058935552e-06, 'epoch': 0.5081687882128897}\n",
      "{'loss': 2.0101, 'grad_norm': 4.505911350250244, 'learning_rate': 2.4541445324245766e-06, 'epoch': 0.5091710935150847}\n",
      "{'loss': 1.6753, 'grad_norm': 8.106419563293457, 'learning_rate': 2.4491330059136014e-06, 'epoch': 0.5101733988172797}\n",
      "{'loss': 1.661, 'grad_norm': 4.5593461990356445, 'learning_rate': 2.4441214794026262e-06, 'epoch': 0.5111757041194748}\n",
      "{'loss': 3.0204, 'grad_norm': 4.936611175537109, 'learning_rate': 2.439109952891651e-06, 'epoch': 0.5121780094216698}\n",
      "{'loss': 1.5384, 'grad_norm': 13.416139602661133, 'learning_rate': 2.434098426380676e-06, 'epoch': 0.5131803147238649}\n",
      "{'loss': 1.686, 'grad_norm': 7.326408386230469, 'learning_rate': 2.4290868998697006e-06, 'epoch': 0.51418262002606}\n",
      "{'loss': 1.3664, 'grad_norm': 8.151982307434082, 'learning_rate': 2.4240753733587254e-06, 'epoch': 0.515184925328255}\n",
      "{'loss': 2.3649, 'grad_norm': 6.528966903686523, 'learning_rate': 2.41906384684775e-06, 'epoch': 0.51618723063045}\n",
      "{'loss': 1.4208, 'grad_norm': 8.974915504455566, 'learning_rate': 2.4140523203367745e-06, 'epoch': 0.517189535932645}\n",
      "{'loss': 2.8872, 'grad_norm': 7.125218868255615, 'learning_rate': 2.4090407938257997e-06, 'epoch': 0.5181918412348401}\n",
      "{'loss': 1.9637, 'grad_norm': 6.125540733337402, 'learning_rate': 2.4040292673148245e-06, 'epoch': 0.5191941465370352}\n",
      "{'loss': 1.4248, 'grad_norm': 1.8544195890426636, 'learning_rate': 2.399017740803849e-06, 'epoch': 0.5201964518392302}\n",
      "{'loss': 1.942, 'grad_norm': 6.890064716339111, 'learning_rate': 2.3940062142928737e-06, 'epoch': 0.5211987571414253}\n",
      "{'loss': 1.6108, 'grad_norm': 10.865046501159668, 'learning_rate': 2.388994687781899e-06, 'epoch': 0.5222010624436203}\n",
      "{'loss': 1.9795, 'grad_norm': 6.675263404846191, 'learning_rate': 2.3839831612709232e-06, 'epoch': 0.5232033677458153}\n",
      "{'loss': 1.7076, 'grad_norm': 24.32338523864746, 'learning_rate': 2.378971634759948e-06, 'epoch': 0.5242056730480105}\n",
      "{'loss': 2.2566, 'grad_norm': 10.778064727783203, 'learning_rate': 2.373960108248973e-06, 'epoch': 0.5252079783502055}\n",
      "{'loss': 2.364, 'grad_norm': 7.007450580596924, 'learning_rate': 2.3689485817379976e-06, 'epoch': 0.5262102836524005}\n",
      "{'loss': 2.0278, 'grad_norm': 3.27766752243042, 'learning_rate': 2.3639370552270224e-06, 'epoch': 0.5272125889545956}\n",
      "{'loss': 1.701, 'grad_norm': 4.880928993225098, 'learning_rate': 2.358925528716047e-06, 'epoch': 0.5282148942567906}\n",
      "{'loss': 2.184, 'grad_norm': 1.5153555870056152, 'learning_rate': 2.353914002205072e-06, 'epoch': 0.5292171995589857}\n",
      "{'loss': 1.4153, 'grad_norm': 3.865709066390991, 'learning_rate': 2.3489024756940968e-06, 'epoch': 0.5302195048611807}\n",
      "{'loss': 1.8085, 'grad_norm': 14.28646183013916, 'learning_rate': 2.343890949183121e-06, 'epoch': 0.5312218101633758}\n",
      "{'loss': 2.3815, 'grad_norm': 7.469528675079346, 'learning_rate': 2.3388794226721463e-06, 'epoch': 0.5322241154655708}\n",
      "{'loss': 1.4744, 'grad_norm': 4.407869338989258, 'learning_rate': 2.3338678961611707e-06, 'epoch': 0.5332264207677658}\n",
      "{'loss': 3.0341, 'grad_norm': 12.846283912658691, 'learning_rate': 2.3288563696501955e-06, 'epoch': 0.5342287260699609}\n",
      "{'loss': 1.8707, 'grad_norm': 6.9862895011901855, 'learning_rate': 2.3238448431392207e-06, 'epoch': 0.535231031372156}\n",
      "{'loss': 2.5339, 'grad_norm': 10.61077880859375, 'learning_rate': 2.318833316628245e-06, 'epoch': 0.536233336674351}\n",
      "{'loss': 1.6985, 'grad_norm': 5.81364107131958, 'learning_rate': 2.31382179011727e-06, 'epoch': 0.537235641976546}\n",
      "{'loss': 1.8885, 'grad_norm': 14.285888671875, 'learning_rate': 2.3088102636062946e-06, 'epoch': 0.5382379472787411}\n",
      "{'loss': 2.9314, 'grad_norm': 6.8169965744018555, 'learning_rate': 2.3037987370953194e-06, 'epoch': 0.5392402525809361}\n",
      "{'loss': 2.6479, 'grad_norm': 7.27169942855835, 'learning_rate': 2.298787210584344e-06, 'epoch': 0.5402425578831312}\n",
      "{'loss': 2.417, 'grad_norm': 9.127899169921875, 'learning_rate': 2.293775684073369e-06, 'epoch': 0.5412448631853263}\n",
      "{'loss': 2.5089, 'grad_norm': 29.448640823364258, 'learning_rate': 2.2887641575623938e-06, 'epoch': 0.5422471684875213}\n",
      "{'loss': 1.8709, 'grad_norm': 9.142671585083008, 'learning_rate': 2.2837526310514186e-06, 'epoch': 0.5432494737897163}\n",
      "{'loss': 2.7675, 'grad_norm': 11.00129222869873, 'learning_rate': 2.278741104540443e-06, 'epoch': 0.5442517790919114}\n",
      "{'loss': 2.0848, 'grad_norm': 15.066951751708984, 'learning_rate': 2.273729578029468e-06, 'epoch': 0.5452540843941065}\n",
      "{'loss': 2.8865, 'grad_norm': 5.881204605102539, 'learning_rate': 2.268718051518493e-06, 'epoch': 0.5462563896963015}\n",
      "{'loss': 2.0283, 'grad_norm': 6.074686050415039, 'learning_rate': 2.2637065250075173e-06, 'epoch': 0.5472586949984966}\n",
      "{'loss': 2.8841, 'grad_norm': 4.075311660766602, 'learning_rate': 2.258694998496542e-06, 'epoch': 0.5482610003006916}\n",
      "{'loss': 2.2921, 'grad_norm': 7.0084733963012695, 'learning_rate': 2.253683471985567e-06, 'epoch': 0.5492633056028866}\n",
      "{'loss': 2.2827, 'grad_norm': 7.121001243591309, 'learning_rate': 2.2486719454745917e-06, 'epoch': 0.5502656109050816}\n",
      "{'loss': 2.1901, 'grad_norm': 23.961015701293945, 'learning_rate': 2.2436604189636164e-06, 'epoch': 0.5512679162072768}\n",
      "{'loss': 3.1768, 'grad_norm': 1.678324818611145, 'learning_rate': 2.2386488924526412e-06, 'epoch': 0.5522702215094718}\n",
      "{'loss': 2.4157, 'grad_norm': 30.744665145874023, 'learning_rate': 2.233637365941666e-06, 'epoch': 0.5532725268116668}\n",
      "{'loss': 1.3959, 'grad_norm': 14.299469947814941, 'learning_rate': 2.228625839430691e-06, 'epoch': 0.5542748321138619}\n",
      "{'loss': 2.2669, 'grad_norm': 5.207494735717773, 'learning_rate': 2.2236143129197156e-06, 'epoch': 0.5552771374160569}\n",
      "{'loss': 1.7346, 'grad_norm': 8.11605167388916, 'learning_rate': 2.2186027864087404e-06, 'epoch': 0.556279442718252}\n",
      "{'loss': 2.0642, 'grad_norm': 12.205958366394043, 'learning_rate': 2.2135912598977647e-06, 'epoch': 0.557281748020447}\n",
      "{'loss': 1.9644, 'grad_norm': 16.38250732421875, 'learning_rate': 2.20857973338679e-06, 'epoch': 0.5582840533226421}\n",
      "{'loss': 2.0843, 'grad_norm': 5.900637149810791, 'learning_rate': 2.2035682068758147e-06, 'epoch': 0.5592863586248371}\n",
      "{'loss': 1.5039, 'grad_norm': 35.053279876708984, 'learning_rate': 2.198556680364839e-06, 'epoch': 0.5602886639270321}\n",
      "{'loss': 2.2199, 'grad_norm': 6.783039569854736, 'learning_rate': 2.193545153853864e-06, 'epoch': 0.5612909692292273}\n",
      "{'loss': 0.5462, 'grad_norm': 5.341706275939941, 'learning_rate': 2.188533627342889e-06, 'epoch': 0.5622932745314223}\n",
      "{'loss': 1.5955, 'grad_norm': 9.300522804260254, 'learning_rate': 2.1835221008319135e-06, 'epoch': 0.5632955798336173}\n",
      "{'loss': 1.684, 'grad_norm': 8.043177604675293, 'learning_rate': 2.1785105743209383e-06, 'epoch': 0.5642978851358124}\n",
      "{'loss': 2.6098, 'grad_norm': 7.59942626953125, 'learning_rate': 2.173499047809963e-06, 'epoch': 0.5653001904380074}\n",
      "{'loss': 2.465, 'grad_norm': 23.605058670043945, 'learning_rate': 2.168487521298988e-06, 'epoch': 0.5663024957402024}\n",
      "{'loss': 1.6853, 'grad_norm': 9.1626615524292, 'learning_rate': 2.1634759947880126e-06, 'epoch': 0.5673048010423976}\n",
      "{'loss': 1.9003, 'grad_norm': 9.712281227111816, 'learning_rate': 2.1584644682770374e-06, 'epoch': 0.5683071063445926}\n",
      "{'loss': 2.4077, 'grad_norm': 4.210596084594727, 'learning_rate': 2.153452941766062e-06, 'epoch': 0.5693094116467876}\n",
      "{'loss': 2.3523, 'grad_norm': 10.670943260192871, 'learning_rate': 2.148441415255087e-06, 'epoch': 0.5703117169489826}\n",
      "{'loss': 2.1506, 'grad_norm': 13.698994636535645, 'learning_rate': 2.1434298887441118e-06, 'epoch': 0.5713140222511777}\n",
      "{'loss': 2.565, 'grad_norm': 4.112212657928467, 'learning_rate': 2.1384183622331365e-06, 'epoch': 0.5723163275533728}\n",
      "{'loss': 1.721, 'grad_norm': 9.121841430664062, 'learning_rate': 2.133406835722161e-06, 'epoch': 0.5733186328555678}\n",
      "{'loss': 1.7658, 'grad_norm': 4.868407726287842, 'learning_rate': 2.1283953092111857e-06, 'epoch': 0.5743209381577629}\n",
      "{'loss': 2.5655, 'grad_norm': 8.191328048706055, 'learning_rate': 2.123383782700211e-06, 'epoch': 0.5753232434599579}\n",
      "{'loss': 2.0312, 'grad_norm': 4.2527899742126465, 'learning_rate': 2.1183722561892353e-06, 'epoch': 0.5763255487621529}\n",
      "{'loss': 1.8941, 'grad_norm': 6.906085014343262, 'learning_rate': 2.11336072967826e-06, 'epoch': 0.577327854064348}\n",
      "{'loss': 2.4153, 'grad_norm': 6.706533908843994, 'learning_rate': 2.108349203167285e-06, 'epoch': 0.5783301593665431}\n",
      "{'loss': 2.0042, 'grad_norm': 1.7332395315170288, 'learning_rate': 2.1033376766563096e-06, 'epoch': 0.5793324646687381}\n",
      "{'loss': 1.7744, 'grad_norm': 4.850251197814941, 'learning_rate': 2.0983261501453344e-06, 'epoch': 0.5803347699709331}\n",
      "{'loss': 1.0692, 'grad_norm': 5.819818019866943, 'learning_rate': 2.093314623634359e-06, 'epoch': 0.5813370752731282}\n",
      "{'loss': 1.79, 'grad_norm': 6.7569403648376465, 'learning_rate': 2.088303097123384e-06, 'epoch': 0.5823393805753232}\n",
      "{'loss': 1.8784, 'grad_norm': 10.032122611999512, 'learning_rate': 2.0832915706124088e-06, 'epoch': 0.5833416858775183}\n",
      "{'loss': 1.9394, 'grad_norm': 0.0, 'learning_rate': 2.078280044101433e-06, 'epoch': 0.5843439911797134}\n",
      "{'loss': 2.2235, 'grad_norm': 7.901099681854248, 'learning_rate': 2.0732685175904584e-06, 'epoch': 0.5853462964819084}\n",
      "{'loss': 2.2612, 'grad_norm': 6.369803428649902, 'learning_rate': 2.068256991079483e-06, 'epoch': 0.5863486017841034}\n",
      "{'loss': 1.476, 'grad_norm': 8.615340232849121, 'learning_rate': 2.0632454645685075e-06, 'epoch': 0.5873509070862984}\n",
      "{'loss': 1.2434, 'grad_norm': 6.099393844604492, 'learning_rate': 2.0582339380575327e-06, 'epoch': 0.5883532123884936}\n",
      "{'loss': 2.3772, 'grad_norm': 0.0, 'learning_rate': 2.0532224115465575e-06, 'epoch': 0.5893555176906886}\n",
      "{'loss': 0.9217, 'grad_norm': 7.262938499450684, 'learning_rate': 2.048210885035582e-06, 'epoch': 0.5903578229928836}\n",
      "{'loss': 2.7867, 'grad_norm': 12.801864624023438, 'learning_rate': 2.0431993585246067e-06, 'epoch': 0.5913601282950787}\n",
      "{'loss': 2.0002, 'grad_norm': 8.102866172790527, 'learning_rate': 2.0381878320136314e-06, 'epoch': 0.5923624335972737}\n",
      "{'loss': 3.3814, 'grad_norm': 5.4036335945129395, 'learning_rate': 2.0331763055026562e-06, 'epoch': 0.5933647388994687}\n",
      "{'loss': 1.7334, 'grad_norm': 9.05364990234375, 'learning_rate': 2.028164778991681e-06, 'epoch': 0.5943670442016639}\n",
      "{'loss': 2.8779, 'grad_norm': 0.0, 'learning_rate': 2.023153252480706e-06, 'epoch': 0.5953693495038589}\n",
      "{'loss': 2.7452, 'grad_norm': 5.7907795906066895, 'learning_rate': 2.0181417259697306e-06, 'epoch': 0.5963716548060539}\n",
      "{'loss': 2.5328, 'grad_norm': 11.209545135498047, 'learning_rate': 2.0131301994587554e-06, 'epoch': 0.597373960108249}\n",
      "{'loss': 2.2842, 'grad_norm': 6.001077651977539, 'learning_rate': 2.00811867294778e-06, 'epoch': 0.598376265410444}\n",
      "{'loss': 1.3591, 'grad_norm': 7.44951868057251, 'learning_rate': 2.003107146436805e-06, 'epoch': 0.5993785707126391}\n",
      "{'loss': 1.3848, 'grad_norm': 11.96550464630127, 'learning_rate': 1.9980956199258293e-06, 'epoch': 0.6003808760148341}\n",
      "{'loss': 1.6188, 'grad_norm': 8.076367378234863, 'learning_rate': 1.993084093414854e-06, 'epoch': 0.6013831813170292}\n",
      "{'loss': 2.6034, 'grad_norm': 6.157778263092041, 'learning_rate': 1.9880725669038793e-06, 'epoch': 0.6023854866192242}\n",
      "{'loss': 1.8548, 'grad_norm': 8.349076271057129, 'learning_rate': 1.9830610403929037e-06, 'epoch': 0.6033877919214192}\n",
      "{'loss': 1.53, 'grad_norm': 5.817690849304199, 'learning_rate': 1.9780495138819285e-06, 'epoch': 0.6043900972236144}\n",
      "{'loss': 2.599, 'grad_norm': 7.192015171051025, 'learning_rate': 1.9730379873709537e-06, 'epoch': 0.6053924025258094}\n",
      "{'loss': 1.8709, 'grad_norm': 8.383106231689453, 'learning_rate': 1.968026460859978e-06, 'epoch': 0.6063947078280044}\n",
      "{'loss': 1.3529, 'grad_norm': 10.100329399108887, 'learning_rate': 1.963014934349003e-06, 'epoch': 0.6073970131301994}\n",
      "{'loss': 2.7845, 'grad_norm': 15.548800468444824, 'learning_rate': 1.9580034078380276e-06, 'epoch': 0.6083993184323945}\n",
      "{'loss': 1.6822, 'grad_norm': 13.35171127319336, 'learning_rate': 1.9529918813270524e-06, 'epoch': 0.6094016237345895}\n",
      "{'loss': 1.3952, 'grad_norm': 1.105226993560791, 'learning_rate': 1.947980354816077e-06, 'epoch': 0.6104039290367846}\n",
      "{'loss': 1.7591, 'grad_norm': 7.949253559112549, 'learning_rate': 1.942968828305102e-06, 'epoch': 0.6114062343389797}\n",
      "{'loss': 1.9456, 'grad_norm': 7.641210079193115, 'learning_rate': 1.9379573017941268e-06, 'epoch': 0.6124085396411747}\n",
      "{'loss': 2.9767, 'grad_norm': 8.162674903869629, 'learning_rate': 1.9329457752831516e-06, 'epoch': 0.6134108449433697}\n",
      "{'loss': 1.8665, 'grad_norm': 25.379201889038086, 'learning_rate': 1.927934248772176e-06, 'epoch': 0.6144131502455648}\n",
      "{'loss': 3.3763, 'grad_norm': 6.784118175506592, 'learning_rate': 1.922922722261201e-06, 'epoch': 0.6154154555477599}\n",
      "{'loss': 2.7102, 'grad_norm': 5.346696376800537, 'learning_rate': 1.9179111957502255e-06, 'epoch': 0.6164177608499549}\n",
      "{'loss': 3.0062, 'grad_norm': 10.22033977508545, 'learning_rate': 1.9128996692392503e-06, 'epoch': 0.61742006615215}\n",
      "{'loss': 1.5189, 'grad_norm': 8.883699417114258, 'learning_rate': 1.907888142728275e-06, 'epoch': 0.618422371454345}\n",
      "{'loss': 1.8672, 'grad_norm': 4.443883419036865, 'learning_rate': 1.9028766162172999e-06, 'epoch': 0.61942467675654}\n",
      "{'loss': 2.1647, 'grad_norm': 7.559616565704346, 'learning_rate': 1.8978650897063246e-06, 'epoch': 0.6204269820587351}\n",
      "{'loss': 2.8872, 'grad_norm': 4.3111796379089355, 'learning_rate': 1.8928535631953496e-06, 'epoch': 0.6214292873609302}\n",
      "{'loss': 1.8175, 'grad_norm': 5.695234775543213, 'learning_rate': 1.8878420366843742e-06, 'epoch': 0.6224315926631252}\n",
      "{'loss': 2.62, 'grad_norm': 3.0448379516601562, 'learning_rate': 1.882830510173399e-06, 'epoch': 0.6234338979653202}\n",
      "{'loss': 2.3691, 'grad_norm': 6.856583595275879, 'learning_rate': 1.8778189836624236e-06, 'epoch': 0.6244362032675153}\n",
      "{'loss': 1.9914, 'grad_norm': 9.605917930603027, 'learning_rate': 1.8728074571514484e-06, 'epoch': 0.6254385085697103}\n",
      "{'loss': 2.2848, 'grad_norm': 5.355528354644775, 'learning_rate': 1.8677959306404734e-06, 'epoch': 0.6264408138719054}\n",
      "{'loss': 2.1486, 'grad_norm': 7.413766860961914, 'learning_rate': 1.862784404129498e-06, 'epoch': 0.6274431191741004}\n",
      "{'loss': 2.3043, 'grad_norm': 5.951940536499023, 'learning_rate': 1.8577728776185227e-06, 'epoch': 0.6284454244762955}\n",
      "{'loss': 1.6972, 'grad_norm': 6.537565231323242, 'learning_rate': 1.8527613511075477e-06, 'epoch': 0.6294477297784905}\n",
      "{'loss': 1.8587, 'grad_norm': 7.612907886505127, 'learning_rate': 1.8477498245965723e-06, 'epoch': 0.6304500350806855}\n",
      "{'loss': 1.4943, 'grad_norm': 0.9988309741020203, 'learning_rate': 1.842738298085597e-06, 'epoch': 0.6314523403828807}\n",
      "{'loss': 1.4266, 'grad_norm': 5.236748695373535, 'learning_rate': 1.8377267715746217e-06, 'epoch': 0.6324546456850757}\n",
      "{'loss': 2.5499, 'grad_norm': 6.915516376495361, 'learning_rate': 1.8327152450636465e-06, 'epoch': 0.6334569509872707}\n",
      "{'loss': 1.8131, 'grad_norm': 7.533609867095947, 'learning_rate': 1.8277037185526715e-06, 'epoch': 0.6344592562894658}\n",
      "{'loss': 1.3303, 'grad_norm': 7.637467861175537, 'learning_rate': 1.822692192041696e-06, 'epoch': 0.6354615615916608}\n",
      "{'loss': 1.841, 'grad_norm': 3.628589153289795, 'learning_rate': 1.8176806655307208e-06, 'epoch': 0.6364638668938559}\n",
      "{'loss': 2.1447, 'grad_norm': 2.386542797088623, 'learning_rate': 1.8126691390197456e-06, 'epoch': 0.637466172196051}\n",
      "{'loss': 1.442, 'grad_norm': 7.0226216316223145, 'learning_rate': 1.8076576125087702e-06, 'epoch': 0.638468477498246}\n",
      "{'loss': 2.6003, 'grad_norm': 13.998659133911133, 'learning_rate': 1.8026460859977952e-06, 'epoch': 0.639470782800441}\n",
      "{'loss': 2.1898, 'grad_norm': 20.089092254638672, 'learning_rate': 1.7976345594868198e-06, 'epoch': 0.640473088102636}\n",
      "{'loss': 1.6327, 'grad_norm': 3.2093162536621094, 'learning_rate': 1.7926230329758445e-06, 'epoch': 0.6414753934048311}\n",
      "{'loss': 2.0454, 'grad_norm': 9.168706893920898, 'learning_rate': 1.7876115064648693e-06, 'epoch': 0.6424776987070262}\n",
      "{'loss': 1.7319, 'grad_norm': 10.249041557312012, 'learning_rate': 1.782599979953894e-06, 'epoch': 0.6434800040092212}\n",
      "{'loss': 1.5771, 'grad_norm': 2.6045567989349365, 'learning_rate': 1.777588453442919e-06, 'epoch': 0.6444823093114163}\n",
      "{'loss': 1.8911, 'grad_norm': 4.105498313903809, 'learning_rate': 1.7725769269319437e-06, 'epoch': 0.6454846146136113}\n",
      "{'loss': 1.9497, 'grad_norm': 20.185073852539062, 'learning_rate': 1.7675654004209683e-06, 'epoch': 0.6464869199158063}\n",
      "{'loss': 2.5702, 'grad_norm': 12.026317596435547, 'learning_rate': 1.7625538739099933e-06, 'epoch': 0.6474892252180015}\n",
      "{'loss': 1.5065, 'grad_norm': 6.114263534545898, 'learning_rate': 1.757542347399018e-06, 'epoch': 0.6484915305201965}\n",
      "{'loss': 1.8291, 'grad_norm': 8.43295669555664, 'learning_rate': 1.7525308208880426e-06, 'epoch': 0.6494938358223915}\n",
      "{'loss': 1.4052, 'grad_norm': 0.0, 'learning_rate': 1.7475192943770674e-06, 'epoch': 0.6504961411245865}\n",
      "{'loss': 1.7114, 'grad_norm': 5.452569484710693, 'learning_rate': 1.742507767866092e-06, 'epoch': 0.6514984464267816}\n",
      "{'loss': 2.2381, 'grad_norm': 9.929913520812988, 'learning_rate': 1.737496241355117e-06, 'epoch': 0.6525007517289766}\n",
      "{'loss': 1.2069, 'grad_norm': 8.369685173034668, 'learning_rate': 1.7324847148441418e-06, 'epoch': 0.6535030570311717}\n",
      "{'loss': 2.1691, 'grad_norm': 6.077352523803711, 'learning_rate': 1.7274731883331663e-06, 'epoch': 0.6545053623333668}\n",
      "{'loss': 2.3809, 'grad_norm': 9.699463844299316, 'learning_rate': 1.7224616618221911e-06, 'epoch': 0.6555076676355618}\n",
      "{'loss': 2.1733, 'grad_norm': 2.257572889328003, 'learning_rate': 1.7174501353112161e-06, 'epoch': 0.6565099729377568}\n",
      "{'loss': 2.0066, 'grad_norm': 3.6269330978393555, 'learning_rate': 1.7124386088002407e-06, 'epoch': 0.6575122782399518}\n",
      "{'loss': 1.9627, 'grad_norm': 9.932120323181152, 'learning_rate': 1.7074270822892655e-06, 'epoch': 0.658514583542147}\n",
      "{'loss': 2.8558, 'grad_norm': 11.120696067810059, 'learning_rate': 1.70241555577829e-06, 'epoch': 0.659516888844342}\n",
      "{'loss': 1.5915, 'grad_norm': 14.790667533874512, 'learning_rate': 1.6974040292673149e-06, 'epoch': 0.660519194146537}\n",
      "{'loss': 2.9171, 'grad_norm': 14.34133529663086, 'learning_rate': 1.6923925027563399e-06, 'epoch': 0.6615214994487321}\n",
      "{'loss': 2.0355, 'grad_norm': 5.342442512512207, 'learning_rate': 1.6873809762453644e-06, 'epoch': 0.6625238047509271}\n",
      "{'loss': 1.4371, 'grad_norm': 3.6300339698791504, 'learning_rate': 1.6823694497343892e-06, 'epoch': 0.6635261100531222}\n",
      "{'loss': 2.215, 'grad_norm': 2.105421304702759, 'learning_rate': 1.6773579232234142e-06, 'epoch': 0.6645284153553173}\n",
      "{'loss': 2.4036, 'grad_norm': 6.268068790435791, 'learning_rate': 1.6723463967124388e-06, 'epoch': 0.6655307206575123}\n",
      "{'loss': 1.9936, 'grad_norm': 4.625000476837158, 'learning_rate': 1.6673348702014636e-06, 'epoch': 0.6665330259597073}\n",
      "{'loss': 1.4444, 'grad_norm': 14.526227951049805, 'learning_rate': 1.6623233436904882e-06, 'epoch': 0.6675353312619023}\n",
      "{'loss': 1.3081, 'grad_norm': 9.549962043762207, 'learning_rate': 1.657311817179513e-06, 'epoch': 0.6685376365640974}\n",
      "{'loss': 2.1531, 'grad_norm': 6.956307888031006, 'learning_rate': 1.652300290668538e-06, 'epoch': 0.6695399418662925}\n",
      "{'loss': 2.0564, 'grad_norm': 4.828098297119141, 'learning_rate': 1.6472887641575625e-06, 'epoch': 0.6705422471684875}\n",
      "{'loss': 1.0406, 'grad_norm': 6.425110340118408, 'learning_rate': 1.6422772376465873e-06, 'epoch': 0.6715445524706826}\n",
      "{'loss': 1.752, 'grad_norm': 7.060353755950928, 'learning_rate': 1.637265711135612e-06, 'epoch': 0.6725468577728776}\n",
      "{'loss': 1.8086, 'grad_norm': 5.658707141876221, 'learning_rate': 1.6322541846246367e-06, 'epoch': 0.6735491630750726}\n",
      "{'loss': 1.1514, 'grad_norm': 7.820405006408691, 'learning_rate': 1.6272426581136617e-06, 'epoch': 0.6745514683772678}\n",
      "{'loss': 2.4515, 'grad_norm': 6.999736785888672, 'learning_rate': 1.6222311316026862e-06, 'epoch': 0.6755537736794628}\n",
      "{'loss': 2.2696, 'grad_norm': 9.913240432739258, 'learning_rate': 1.617219605091711e-06, 'epoch': 0.6765560789816578}\n",
      "{'loss': 2.8861, 'grad_norm': 5.8420729637146, 'learning_rate': 1.6122080785807358e-06, 'epoch': 0.6775583842838528}\n",
      "{'loss': 2.24, 'grad_norm': 12.445527076721191, 'learning_rate': 1.6071965520697604e-06, 'epoch': 0.6785606895860479}\n",
      "{'loss': 1.8374, 'grad_norm': 11.125290870666504, 'learning_rate': 1.6021850255587854e-06, 'epoch': 0.679562994888243}\n",
      "{'loss': 1.5117, 'grad_norm': 8.895265579223633, 'learning_rate': 1.5971734990478102e-06, 'epoch': 0.680565300190438}\n",
      "{'loss': 2.1967, 'grad_norm': 9.90120792388916, 'learning_rate': 1.5921619725368348e-06, 'epoch': 0.6815676054926331}\n",
      "{'loss': 2.5685, 'grad_norm': 4.5962114334106445, 'learning_rate': 1.5871504460258598e-06, 'epoch': 0.6825699107948281}\n",
      "{'loss': 1.821, 'grad_norm': 9.113457679748535, 'learning_rate': 1.5821389195148843e-06, 'epoch': 0.6835722160970231}\n",
      "{'loss': 1.9642, 'grad_norm': 6.277954578399658, 'learning_rate': 1.5771273930039091e-06, 'epoch': 0.6845745213992181}\n",
      "{'loss': 2.0968, 'grad_norm': 20.764732360839844, 'learning_rate': 1.572115866492934e-06, 'epoch': 0.6855768267014133}\n",
      "{'loss': 1.1683, 'grad_norm': 10.538076400756836, 'learning_rate': 1.5671043399819585e-06, 'epoch': 0.6865791320036083}\n",
      "{'loss': 1.4632, 'grad_norm': 23.16264533996582, 'learning_rate': 1.5620928134709835e-06, 'epoch': 0.6875814373058033}\n",
      "{'loss': 2.142, 'grad_norm': 9.861122131347656, 'learning_rate': 1.5570812869600083e-06, 'epoch': 0.6885837426079984}\n",
      "{'loss': 2.2422, 'grad_norm': 2.4821701049804688, 'learning_rate': 1.5520697604490328e-06, 'epoch': 0.6895860479101934}\n",
      "{'loss': 1.7751, 'grad_norm': 10.193720817565918, 'learning_rate': 1.5470582339380576e-06, 'epoch': 0.6905883532123885}\n",
      "{'loss': 2.841, 'grad_norm': 7.390857219696045, 'learning_rate': 1.5420467074270822e-06, 'epoch': 0.6915906585145836}\n",
      "{'loss': 1.976, 'grad_norm': 12.483101844787598, 'learning_rate': 1.5370351809161072e-06, 'epoch': 0.6925929638167786}\n",
      "{'loss': 1.3819, 'grad_norm': 4.343680381774902, 'learning_rate': 1.532023654405132e-06, 'epoch': 0.6935952691189736}\n",
      "{'loss': 2.2869, 'grad_norm': 3.85071063041687, 'learning_rate': 1.5270121278941566e-06, 'epoch': 0.6945975744211687}\n",
      "{'loss': 1.8452, 'grad_norm': 6.277316570281982, 'learning_rate': 1.5220006013831814e-06, 'epoch': 0.6955998797233638}\n",
      "{'loss': 1.5672, 'grad_norm': 19.12667465209961, 'learning_rate': 1.5169890748722064e-06, 'epoch': 0.6966021850255588}\n",
      "{'loss': 1.9779, 'grad_norm': 5.193135738372803, 'learning_rate': 1.511977548361231e-06, 'epoch': 0.6976044903277538}\n",
      "{'loss': 2.2926, 'grad_norm': 5.181163311004639, 'learning_rate': 1.5069660218502557e-06, 'epoch': 0.6986067956299489}\n",
      "{'loss': 2.2058, 'grad_norm': 7.915548801422119, 'learning_rate': 1.5019544953392803e-06, 'epoch': 0.6996091009321439}\n",
      "{'loss': 2.6273, 'grad_norm': 6.1056809425354, 'learning_rate': 1.4969429688283053e-06, 'epoch': 0.7006114062343389}\n",
      "{'loss': 2.2509, 'grad_norm': 7.587652206420898, 'learning_rate': 1.49193144231733e-06, 'epoch': 0.7016137115365341}\n",
      "{'loss': 1.1838, 'grad_norm': 12.023599624633789, 'learning_rate': 1.4869199158063547e-06, 'epoch': 0.7026160168387291}\n",
      "{'loss': 1.8742, 'grad_norm': 9.847370147705078, 'learning_rate': 1.4819083892953794e-06, 'epoch': 0.7036183221409241}\n",
      "{'loss': 1.966, 'grad_norm': 3.67771577835083, 'learning_rate': 1.4768968627844044e-06, 'epoch': 0.7046206274431192}\n",
      "{'loss': 1.8569, 'grad_norm': 11.791457176208496, 'learning_rate': 1.471885336273429e-06, 'epoch': 0.7056229327453142}\n",
      "{'loss': 1.3623, 'grad_norm': 12.39319896697998, 'learning_rate': 1.4668738097624538e-06, 'epoch': 0.7066252380475093}\n",
      "{'loss': 1.6951, 'grad_norm': 13.649429321289062, 'learning_rate': 1.4618622832514784e-06, 'epoch': 0.7076275433497043}\n",
      "{'loss': 3.0686, 'grad_norm': 6.374670505523682, 'learning_rate': 1.4568507567405032e-06, 'epoch': 0.7086298486518994}\n",
      "{'loss': 2.8175, 'grad_norm': 6.919260025024414, 'learning_rate': 1.4518392302295282e-06, 'epoch': 0.7096321539540944}\n",
      "{'loss': 1.7052, 'grad_norm': 14.129009246826172, 'learning_rate': 1.4468277037185527e-06, 'epoch': 0.7106344592562894}\n",
      "{'loss': 2.2553, 'grad_norm': 30.262102127075195, 'learning_rate': 1.4418161772075775e-06, 'epoch': 0.7116367645584846}\n",
      "{'loss': 2.1383, 'grad_norm': 8.129615783691406, 'learning_rate': 1.4368046506966023e-06, 'epoch': 0.7126390698606796}\n",
      "{'loss': 1.323, 'grad_norm': 5.662441730499268, 'learning_rate': 1.4317931241856269e-06, 'epoch': 0.7136413751628746}\n",
      "{'loss': 1.837, 'grad_norm': 1.4038313627243042, 'learning_rate': 1.4267815976746519e-06, 'epoch': 0.7146436804650697}\n",
      "{'loss': 2.0319, 'grad_norm': 5.34879207611084, 'learning_rate': 1.4217700711636765e-06, 'epoch': 0.7156459857672647}\n",
      "{'loss': 1.9814, 'grad_norm': 5.414187431335449, 'learning_rate': 1.4167585446527012e-06, 'epoch': 0.7166482910694597}\n",
      "{'loss': 2.7579, 'grad_norm': 7.941394805908203, 'learning_rate': 1.4117470181417262e-06, 'epoch': 0.7176505963716548}\n",
      "{'loss': 2.6771, 'grad_norm': 6.112852096557617, 'learning_rate': 1.4067354916307508e-06, 'epoch': 0.7186529016738499}\n",
      "{'loss': 1.5252, 'grad_norm': 4.656596660614014, 'learning_rate': 1.4017239651197756e-06, 'epoch': 0.7196552069760449}\n",
      "{'loss': 0.9816, 'grad_norm': 3.7477235794067383, 'learning_rate': 1.3967124386088004e-06, 'epoch': 0.7206575122782399}\n",
      "{'loss': 2.1504, 'grad_norm': 5.721868515014648, 'learning_rate': 1.391700912097825e-06, 'epoch': 0.721659817580435}\n",
      "{'loss': 2.1844, 'grad_norm': 7.313348770141602, 'learning_rate': 1.38668938558685e-06, 'epoch': 0.7226621228826301}\n",
      "{'loss': 2.6993, 'grad_norm': 0.0, 'learning_rate': 1.3816778590758748e-06, 'epoch': 0.7236644281848251}\n",
      "{'loss': 2.897, 'grad_norm': 0.8353546857833862, 'learning_rate': 1.3766663325648993e-06, 'epoch': 0.7246667334870202}\n",
      "{'loss': 0.8528, 'grad_norm': 7.18989372253418, 'learning_rate': 1.3716548060539241e-06, 'epoch': 0.7256690387892152}\n",
      "{'loss': 2.7622, 'grad_norm': 7.352540493011475, 'learning_rate': 1.3666432795429487e-06, 'epoch': 0.7266713440914102}\n",
      "{'loss': 1.7124, 'grad_norm': 6.5824079513549805, 'learning_rate': 1.3616317530319737e-06, 'epoch': 0.7276736493936052}\n",
      "{'loss': 2.6456, 'grad_norm': 21.80428695678711, 'learning_rate': 1.3566202265209985e-06, 'epoch': 0.7286759546958004}\n",
      "{'loss': 3.0708, 'grad_norm': 5.297519683837891, 'learning_rate': 1.351608700010023e-06, 'epoch': 0.7296782599979954}\n",
      "{'loss': 1.1138, 'grad_norm': 2.882167100906372, 'learning_rate': 1.3465971734990478e-06, 'epoch': 0.7306805653001904}\n",
      "{'loss': 2.4804, 'grad_norm': 1.5866386890411377, 'learning_rate': 1.3415856469880728e-06, 'epoch': 0.7316828706023855}\n",
      "{'loss': 2.004, 'grad_norm': 20.24513053894043, 'learning_rate': 1.3365741204770974e-06, 'epoch': 0.7326851759045805}\n",
      "{'loss': 1.2774, 'grad_norm': 11.578173637390137, 'learning_rate': 1.3315625939661222e-06, 'epoch': 0.7336874812067756}\n",
      "{'loss': 1.7636, 'grad_norm': 9.220192909240723, 'learning_rate': 1.3265510674551468e-06, 'epoch': 0.7346897865089707}\n",
      "{'loss': 1.8578, 'grad_norm': 10.539974212646484, 'learning_rate': 1.3215395409441718e-06, 'epoch': 0.7356920918111657}\n",
      "{'loss': 0.8433, 'grad_norm': 7.80841064453125, 'learning_rate': 1.3165280144331966e-06, 'epoch': 0.7366943971133607}\n",
      "{'loss': 1.8839, 'grad_norm': 8.60537052154541, 'learning_rate': 1.3115164879222211e-06, 'epoch': 0.7376967024155557}\n",
      "{'loss': 1.8231, 'grad_norm': 6.607433319091797, 'learning_rate': 1.306504961411246e-06, 'epoch': 0.7386990077177509}\n",
      "{'loss': 2.748, 'grad_norm': 5.23193359375, 'learning_rate': 1.301493434900271e-06, 'epoch': 0.7397013130199459}\n",
      "{'loss': 1.5433, 'grad_norm': 6.544155597686768, 'learning_rate': 1.2964819083892955e-06, 'epoch': 0.7407036183221409}\n",
      "{'loss': 2.2107, 'grad_norm': 3.685346841812134, 'learning_rate': 1.2914703818783203e-06, 'epoch': 0.741705923624336}\n",
      "{'loss': 2.1853, 'grad_norm': 5.556516647338867, 'learning_rate': 1.2864588553673449e-06, 'epoch': 0.742708228926531}\n",
      "{'loss': 1.963, 'grad_norm': 17.652503967285156, 'learning_rate': 1.2814473288563697e-06, 'epoch': 0.743710534228726}\n",
      "{'loss': 2.6811, 'grad_norm': 5.577976226806641, 'learning_rate': 1.2764358023453947e-06, 'epoch': 0.7447128395309212}\n",
      "{'loss': 1.9326, 'grad_norm': 12.209996223449707, 'learning_rate': 1.2714242758344192e-06, 'epoch': 0.7457151448331162}\n",
      "{'loss': 1.413, 'grad_norm': 6.565481185913086, 'learning_rate': 1.266412749323444e-06, 'epoch': 0.7467174501353112}\n",
      "{'loss': 2.2852, 'grad_norm': 10.983399391174316, 'learning_rate': 1.2614012228124688e-06, 'epoch': 0.7477197554375062}\n",
      "{'loss': 2.3325, 'grad_norm': 15.652222633361816, 'learning_rate': 1.2563896963014936e-06, 'epoch': 0.7487220607397013}\n",
      "{'loss': 3.2495, 'grad_norm': 8.832146644592285, 'learning_rate': 1.2513781697905184e-06, 'epoch': 0.7497243660418964}\n",
      "{'loss': 1.9585, 'grad_norm': 4.817775726318359, 'learning_rate': 1.2463666432795432e-06, 'epoch': 0.7507266713440914}\n",
      "{'loss': 1.2731, 'grad_norm': 7.3688812255859375, 'learning_rate': 1.2413551167685677e-06, 'epoch': 0.7517289766462865}\n",
      "{'loss': 1.8267, 'grad_norm': 6.148110389709473, 'learning_rate': 1.2363435902575925e-06, 'epoch': 0.7527312819484815}\n",
      "{'loss': 1.5367, 'grad_norm': 7.422045707702637, 'learning_rate': 1.2313320637466173e-06, 'epoch': 0.7537335872506765}\n",
      "{'loss': 2.2152, 'grad_norm': 7.807162761688232, 'learning_rate': 1.226320537235642e-06, 'epoch': 0.7547358925528717}\n",
      "{'loss': 2.0357, 'grad_norm': 9.749360084533691, 'learning_rate': 1.2213090107246669e-06, 'epoch': 0.7557381978550667}\n",
      "{'loss': 1.8167, 'grad_norm': 5.082282066345215, 'learning_rate': 1.2162974842136915e-06, 'epoch': 0.7567405031572617}\n",
      "{'loss': 2.1438, 'grad_norm': 8.703303337097168, 'learning_rate': 1.2112859577027165e-06, 'epoch': 0.7577428084594567}\n",
      "{'loss': 2.0595, 'grad_norm': 6.922040939331055, 'learning_rate': 1.206274431191741e-06, 'epoch': 0.7587451137616518}\n",
      "{'loss': 2.1631, 'grad_norm': 8.964339256286621, 'learning_rate': 1.2012629046807658e-06, 'epoch': 0.7597474190638468}\n",
      "{'loss': 0.688, 'grad_norm': 11.330771446228027, 'learning_rate': 1.1962513781697906e-06, 'epoch': 0.7607497243660419}\n",
      "{'loss': 1.7572, 'grad_norm': 7.725087642669678, 'learning_rate': 1.1912398516588154e-06, 'epoch': 0.761752029668237}\n",
      "{'loss': 2.6516, 'grad_norm': 5.811122417449951, 'learning_rate': 1.1862283251478402e-06, 'epoch': 0.762754334970432}\n",
      "{'loss': 2.522, 'grad_norm': 10.557212829589844, 'learning_rate': 1.1812167986368648e-06, 'epoch': 0.763756640272627}\n",
      "{'loss': 1.9325, 'grad_norm': 10.897466659545898, 'learning_rate': 1.1762052721258896e-06, 'epoch': 0.764758945574822}\n",
      "{'loss': 0.9171, 'grad_norm': 6.181071758270264, 'learning_rate': 1.1711937456149143e-06, 'epoch': 0.7657612508770172}\n",
      "{'loss': 2.1097, 'grad_norm': 1.722795009613037, 'learning_rate': 1.1661822191039391e-06, 'epoch': 0.7667635561792122}\n",
      "{'loss': 2.0698, 'grad_norm': 9.802445411682129, 'learning_rate': 1.161170692592964e-06, 'epoch': 0.7677658614814072}\n",
      "{'loss': 3.4674, 'grad_norm': 0.0, 'learning_rate': 1.1561591660819887e-06, 'epoch': 0.7687681667836023}\n",
      "{'loss': 2.299, 'grad_norm': 8.728023529052734, 'learning_rate': 1.1511476395710135e-06, 'epoch': 0.7697704720857973}\n",
      "{'loss': 1.7269, 'grad_norm': 14.654706001281738, 'learning_rate': 1.1461361130600383e-06, 'epoch': 0.7707727773879924}\n",
      "{'loss': 2.0248, 'grad_norm': 7.184600830078125, 'learning_rate': 1.1411245865490629e-06, 'epoch': 0.7717750826901875}\n",
      "{'loss': 2.5629, 'grad_norm': 6.638535976409912, 'learning_rate': 1.1361130600380876e-06, 'epoch': 0.7727773879923825}\n",
      "{'loss': 1.5798, 'grad_norm': 10.430630683898926, 'learning_rate': 1.1311015335271124e-06, 'epoch': 0.7737796932945775}\n",
      "{'loss': 1.264, 'grad_norm': 6.543552398681641, 'learning_rate': 1.1260900070161372e-06, 'epoch': 0.7747819985967725}\n",
      "{'loss': 1.5542, 'grad_norm': 9.128188133239746, 'learning_rate': 1.121078480505162e-06, 'epoch': 0.7757843038989676}\n",
      "{'loss': 2.7233, 'grad_norm': 8.627005577087402, 'learning_rate': 1.1160669539941866e-06, 'epoch': 0.7767866092011627}\n",
      "{'loss': 2.4163, 'grad_norm': 4.793460369110107, 'learning_rate': 1.1110554274832116e-06, 'epoch': 0.7777889145033577}\n",
      "{'loss': 1.7867, 'grad_norm': 2.8245768547058105, 'learning_rate': 1.1060439009722362e-06, 'epoch': 0.7787912198055528}\n",
      "{'loss': 1.639, 'grad_norm': 18.38245391845703, 'learning_rate': 1.101032374461261e-06, 'epoch': 0.7797935251077478}\n",
      "{'loss': 1.9924, 'grad_norm': 6.146665096282959, 'learning_rate': 1.0960208479502857e-06, 'epoch': 0.7807958304099428}\n",
      "{'loss': 1.5443, 'grad_norm': 4.853768348693848, 'learning_rate': 1.0910093214393105e-06, 'epoch': 0.781798135712138}\n",
      "{'loss': 1.7111, 'grad_norm': 10.395881652832031, 'learning_rate': 1.0859977949283353e-06, 'epoch': 0.782800441014333}\n",
      "{'loss': 1.1647, 'grad_norm': 6.173584938049316, 'learning_rate': 1.08098626841736e-06, 'epoch': 0.783802746316528}\n",
      "{'loss': 0.9972, 'grad_norm': 12.11539363861084, 'learning_rate': 1.0759747419063847e-06, 'epoch': 0.784805051618723}\n",
      "{'loss': 1.8117, 'grad_norm': 3.064405918121338, 'learning_rate': 1.0709632153954097e-06, 'epoch': 0.7858073569209181}\n",
      "{'loss': 1.7575, 'grad_norm': 5.843647480010986, 'learning_rate': 1.0659516888844342e-06, 'epoch': 0.7868096622231132}\n",
      "{'loss': 2.8621, 'grad_norm': 9.057448387145996, 'learning_rate': 1.060940162373459e-06, 'epoch': 0.7878119675253082}\n",
      "{'loss': 1.9929, 'grad_norm': 8.295588493347168, 'learning_rate': 1.0559286358624838e-06, 'epoch': 0.7888142728275033}\n",
      "{'loss': 1.6923, 'grad_norm': 5.363649368286133, 'learning_rate': 1.0509171093515086e-06, 'epoch': 0.7898165781296983}\n",
      "{'loss': 1.5107, 'grad_norm': 8.563994407653809, 'learning_rate': 1.0459055828405334e-06, 'epoch': 0.7908188834318933}\n",
      "{'loss': 1.7634, 'grad_norm': 7.008777141571045, 'learning_rate': 1.040894056329558e-06, 'epoch': 0.7918211887340884}\n",
      "{'loss': 1.5037, 'grad_norm': 7.127478122711182, 'learning_rate': 1.035882529818583e-06, 'epoch': 0.7928234940362835}\n",
      "{'loss': 1.747, 'grad_norm': 7.965814590454102, 'learning_rate': 1.0308710033076075e-06, 'epoch': 0.7938257993384785}\n",
      "{'loss': 1.1896, 'grad_norm': 8.739702224731445, 'learning_rate': 1.0258594767966323e-06, 'epoch': 0.7948281046406735}\n",
      "{'loss': 0.9959, 'grad_norm': 8.057151794433594, 'learning_rate': 1.0208479502856571e-06, 'epoch': 0.7958304099428686}\n",
      "{'loss': 1.8383, 'grad_norm': 11.978538513183594, 'learning_rate': 1.015836423774682e-06, 'epoch': 0.7968327152450636}\n",
      "{'loss': 1.9854, 'grad_norm': 7.102742671966553, 'learning_rate': 1.0108248972637067e-06, 'epoch': 0.7978350205472587}\n",
      "{'loss': 2.789, 'grad_norm': 7.37729024887085, 'learning_rate': 1.0058133707527313e-06, 'epoch': 0.7988373258494538}\n",
      "{'loss': 1.7082, 'grad_norm': 10.668295860290527, 'learning_rate': 1.000801844241756e-06, 'epoch': 0.7998396311516488}\n",
      "{'loss': 2.5973, 'grad_norm': 7.033603668212891, 'learning_rate': 9.95790317730781e-07, 'epoch': 0.8008419364538438}\n",
      "{'loss': 2.2508, 'grad_norm': 5.278957843780518, 'learning_rate': 9.907787912198056e-07, 'epoch': 0.8018442417560389}\n",
      "{'loss': 1.1686, 'grad_norm': 16.879446029663086, 'learning_rate': 9.857672647088304e-07, 'epoch': 0.8028465470582339}\n",
      "{'loss': 2.5374, 'grad_norm': 7.459007263183594, 'learning_rate': 9.807557381978552e-07, 'epoch': 0.803848852360429}\n",
      "{'loss': 1.4614, 'grad_norm': 3.788233995437622, 'learning_rate': 9.7574421168688e-07, 'epoch': 0.804851157662624}\n",
      "{'loss': 2.214, 'grad_norm': 7.385173797607422, 'learning_rate': 9.707326851759048e-07, 'epoch': 0.8058534629648191}\n",
      "{'loss': 1.5204, 'grad_norm': 6.010647773742676, 'learning_rate': 9.657211586649293e-07, 'epoch': 0.8068557682670141}\n",
      "{'loss': 1.6494, 'grad_norm': 6.999015808105469, 'learning_rate': 9.607096321539541e-07, 'epoch': 0.8078580735692091}\n",
      "{'loss': 1.7483, 'grad_norm': 1.918980598449707, 'learning_rate': 9.55698105642979e-07, 'epoch': 0.8088603788714043}\n",
      "{'loss': 2.7944, 'grad_norm': 6.646276950836182, 'learning_rate': 9.506865791320037e-07, 'epoch': 0.8098626841735993}\n",
      "{'loss': 2.5749, 'grad_norm': 3.888336420059204, 'learning_rate': 9.456750526210284e-07, 'epoch': 0.8108649894757943}\n",
      "{'loss': 1.975, 'grad_norm': 6.134120941162109, 'learning_rate': 9.406635261100532e-07, 'epoch': 0.8118672947779894}\n",
      "{'loss': 1.8508, 'grad_norm': 7.7282328605651855, 'learning_rate': 9.35651999599078e-07, 'epoch': 0.8128696000801844}\n",
      "{'loss': 2.0078, 'grad_norm': 6.193244457244873, 'learning_rate': 9.306404730881028e-07, 'epoch': 0.8138719053823795}\n",
      "{'loss': 1.6307, 'grad_norm': 0.0, 'learning_rate': 9.256289465771274e-07, 'epoch': 0.8148742106845746}\n",
      "{'loss': 1.9313, 'grad_norm': 8.908893585205078, 'learning_rate': 9.206174200661522e-07, 'epoch': 0.8158765159867696}\n",
      "{'loss': 2.135, 'grad_norm': 2.0869529247283936, 'learning_rate': 9.15605893555177e-07, 'epoch': 0.8168788212889646}\n",
      "{'loss': 0.875, 'grad_norm': 6.87637996673584, 'learning_rate': 9.105943670442018e-07, 'epoch': 0.8178811265911596}\n",
      "{'loss': 1.2856, 'grad_norm': 26.666397094726562, 'learning_rate': 9.055828405332265e-07, 'epoch': 0.8188834318933547}\n",
      "{'loss': 1.9075, 'grad_norm': 0.0, 'learning_rate': 9.005713140222512e-07, 'epoch': 0.8198857371955498}\n",
      "{'loss': 1.892, 'grad_norm': 11.238532066345215, 'learning_rate': 8.95559787511276e-07, 'epoch': 0.8208880424977448}\n",
      "{'loss': 2.1739, 'grad_norm': 16.17306900024414, 'learning_rate': 8.905482610003007e-07, 'epoch': 0.8218903477999399}\n",
      "{'loss': 2.0614, 'grad_norm': 12.924162864685059, 'learning_rate': 8.855367344893255e-07, 'epoch': 0.8228926531021349}\n",
      "{'loss': 1.4621, 'grad_norm': 10.554533958435059, 'learning_rate': 8.805252079783502e-07, 'epoch': 0.8238949584043299}\n",
      "{'loss': 2.382, 'grad_norm': 6.627130508422852, 'learning_rate': 8.755136814673751e-07, 'epoch': 0.824897263706525}\n",
      "{'loss': 0.652, 'grad_norm': 7.3316240310668945, 'learning_rate': 8.705021549563998e-07, 'epoch': 0.8258995690087201}\n",
      "{'loss': 2.3466, 'grad_norm': 4.665058135986328, 'learning_rate': 8.654906284454246e-07, 'epoch': 0.8269018743109151}\n",
      "{'loss': 1.9029, 'grad_norm': 6.122093677520752, 'learning_rate': 8.604791019344492e-07, 'epoch': 0.8279041796131101}\n",
      "{'loss': 2.0754, 'grad_norm': 0.0, 'learning_rate': 8.554675754234741e-07, 'epoch': 0.8289064849153052}\n",
      "{'loss': 2.4539, 'grad_norm': 9.320703506469727, 'learning_rate': 8.504560489124988e-07, 'epoch': 0.8299087902175003}\n",
      "{'loss': 2.4134, 'grad_norm': 6.944586277008057, 'learning_rate': 8.454445224015236e-07, 'epoch': 0.8309110955196953}\n",
      "{'loss': 1.944, 'grad_norm': 5.167205810546875, 'learning_rate': 8.404329958905483e-07, 'epoch': 0.8319134008218904}\n",
      "{'loss': 1.9363, 'grad_norm': 14.607102394104004, 'learning_rate': 8.354214693795732e-07, 'epoch': 0.8329157061240854}\n",
      "{'loss': 2.0232, 'grad_norm': 11.398139953613281, 'learning_rate': 8.304099428685979e-07, 'epoch': 0.8339180114262804}\n",
      "{'loss': 2.3486, 'grad_norm': 5.4509196281433105, 'learning_rate': 8.253984163576225e-07, 'epoch': 0.8349203167284754}\n",
      "{'loss': 1.9373, 'grad_norm': 7.065093994140625, 'learning_rate': 8.203868898466473e-07, 'epoch': 0.8359226220306706}\n",
      "{'loss': 1.5141, 'grad_norm': 2.7253260612487793, 'learning_rate': 8.153753633356721e-07, 'epoch': 0.8369249273328656}\n",
      "{'loss': 2.0265, 'grad_norm': 8.739917755126953, 'learning_rate': 8.103638368246969e-07, 'epoch': 0.8379272326350606}\n",
      "{'loss': 2.2173, 'grad_norm': 6.156557559967041, 'learning_rate': 8.053523103137216e-07, 'epoch': 0.8389295379372557}\n",
      "{'loss': 1.9494, 'grad_norm': 4.700882911682129, 'learning_rate': 8.003407838027464e-07, 'epoch': 0.8399318432394507}\n",
      "{'loss': 2.1975, 'grad_norm': 9.961782455444336, 'learning_rate': 7.953292572917712e-07, 'epoch': 0.8409341485416458}\n",
      "{'loss': 2.2666, 'grad_norm': 4.277594566345215, 'learning_rate': 7.903177307807959e-07, 'epoch': 0.8419364538438409}\n",
      "{'loss': 1.8952, 'grad_norm': 9.678955078125, 'learning_rate': 7.853062042698206e-07, 'epoch': 0.8429387591460359}\n",
      "{'loss': 2.5717, 'grad_norm': 8.810920715332031, 'learning_rate': 7.802946777588453e-07, 'epoch': 0.8439410644482309}\n",
      "{'loss': 2.433, 'grad_norm': 19.505821228027344, 'learning_rate': 7.752831512478702e-07, 'epoch': 0.8449433697504259}\n",
      "{'loss': 1.9482, 'grad_norm': 3.8770523071289062, 'learning_rate': 7.702716247368949e-07, 'epoch': 0.8459456750526211}\n",
      "{'loss': 2.1087, 'grad_norm': 12.170919418334961, 'learning_rate': 7.652600982259197e-07, 'epoch': 0.8469479803548161}\n",
      "{'loss': 1.8292, 'grad_norm': 10.752832412719727, 'learning_rate': 7.602485717149444e-07, 'epoch': 0.8479502856570111}\n",
      "{'loss': 1.5294, 'grad_norm': 7.84390926361084, 'learning_rate': 7.552370452039692e-07, 'epoch': 0.8489525909592062}\n",
      "{'loss': 2.3867, 'grad_norm': 26.163646697998047, 'learning_rate': 7.502255186929939e-07, 'epoch': 0.8499548962614012}\n",
      "{'loss': 2.0438, 'grad_norm': 9.912806510925293, 'learning_rate': 7.452139921820187e-07, 'epoch': 0.8509572015635962}\n",
      "{'loss': 2.6182, 'grad_norm': 15.4840726852417, 'learning_rate': 7.402024656710434e-07, 'epoch': 0.8519595068657914}\n",
      "{'loss': 1.7436, 'grad_norm': 10.473655700683594, 'learning_rate': 7.351909391600683e-07, 'epoch': 0.8529618121679864}\n",
      "{'loss': 1.906, 'grad_norm': 5.170804500579834, 'learning_rate': 7.30179412649093e-07, 'epoch': 0.8539641174701814}\n",
      "{'loss': 1.8236, 'grad_norm': 8.129805564880371, 'learning_rate': 7.251678861381177e-07, 'epoch': 0.8549664227723764}\n",
      "{'loss': 1.7792, 'grad_norm': 16.498350143432617, 'learning_rate': 7.201563596271424e-07, 'epoch': 0.8559687280745715}\n",
      "{'loss': 2.9823, 'grad_norm': 8.993426322937012, 'learning_rate': 7.151448331161673e-07, 'epoch': 0.8569710333767666}\n",
      "{'loss': 2.1863, 'grad_norm': 5.028805732727051, 'learning_rate': 7.10133306605192e-07, 'epoch': 0.8579733386789616}\n",
      "{'loss': 1.4692, 'grad_norm': 7.919370651245117, 'learning_rate': 7.051217800942167e-07, 'epoch': 0.8589756439811567}\n",
      "{'loss': 2.5658, 'grad_norm': 3.7026591300964355, 'learning_rate': 7.001102535832415e-07, 'epoch': 0.8599779492833517}\n",
      "{'loss': 1.7551, 'grad_norm': 6.499486923217773, 'learning_rate': 6.950987270722663e-07, 'epoch': 0.8609802545855467}\n",
      "{'loss': 1.8769, 'grad_norm': 3.9880287647247314, 'learning_rate': 6.900872005612911e-07, 'epoch': 0.8619825598877419}\n",
      "{'loss': 2.2874, 'grad_norm': 9.500089645385742, 'learning_rate': 6.850756740503157e-07, 'epoch': 0.8629848651899369}\n",
      "{'loss': 1.7455, 'grad_norm': 7.267412185668945, 'learning_rate': 6.800641475393406e-07, 'epoch': 0.8639871704921319}\n",
      "{'loss': 1.8469, 'grad_norm': 5.881217002868652, 'learning_rate': 6.750526210283653e-07, 'epoch': 0.864989475794327}\n",
      "{'loss': 2.0885, 'grad_norm': 6.561858654022217, 'learning_rate': 6.700410945173901e-07, 'epoch': 0.865991781096522}\n",
      "{'loss': 2.3249, 'grad_norm': 8.992432594299316, 'learning_rate': 6.650295680064148e-07, 'epoch': 0.866994086398717}\n",
      "{'loss': 2.378, 'grad_norm': 6.2817206382751465, 'learning_rate': 6.600180414954397e-07, 'epoch': 0.8679963917009121}\n",
      "{'loss': 2.4412, 'grad_norm': 13.069977760314941, 'learning_rate': 6.550065149844644e-07, 'epoch': 0.8689986970031072}\n",
      "{'loss': 2.2209, 'grad_norm': 6.233887195587158, 'learning_rate': 6.49994988473489e-07, 'epoch': 0.8700010023053022}\n",
      "{'loss': 2.3097, 'grad_norm': 8.60797119140625, 'learning_rate': 6.449834619625138e-07, 'epoch': 0.8710033076074972}\n",
      "{'loss': 1.734, 'grad_norm': 5.750820159912109, 'learning_rate': 6.399719354515386e-07, 'epoch': 0.8720056129096923}\n",
      "{'loss': 1.7726, 'grad_norm': 6.103170871734619, 'learning_rate': 6.349604089405634e-07, 'epoch': 0.8730079182118874}\n",
      "{'loss': 2.3272, 'grad_norm': 8.51630973815918, 'learning_rate': 6.299488824295881e-07, 'epoch': 0.8740102235140824}\n",
      "{'loss': 1.8856, 'grad_norm': 5.059212684631348, 'learning_rate': 6.249373559186129e-07, 'epoch': 0.8750125288162774}\n",
      "{'loss': 1.2324, 'grad_norm': 5.283930778503418, 'learning_rate': 6.199258294076377e-07, 'epoch': 0.8760148341184725}\n",
      "{'loss': 2.7079, 'grad_norm': 9.880249977111816, 'learning_rate': 6.149143028966624e-07, 'epoch': 0.8770171394206675}\n",
      "{'loss': 1.8501, 'grad_norm': 9.749966621398926, 'learning_rate': 6.099027763856871e-07, 'epoch': 0.8780194447228625}\n",
      "{'loss': 1.663, 'grad_norm': 2.7356815338134766, 'learning_rate': 6.048912498747119e-07, 'epoch': 0.8790217500250577}\n",
      "{'loss': 2.5607, 'grad_norm': 5.9407172203063965, 'learning_rate': 5.998797233637366e-07, 'epoch': 0.8800240553272527}\n",
      "{'loss': 1.1044, 'grad_norm': 21.60192108154297, 'learning_rate': 5.948681968527614e-07, 'epoch': 0.8810263606294477}\n",
      "{'loss': 1.3225, 'grad_norm': 19.657608032226562, 'learning_rate': 5.898566703417862e-07, 'epoch': 0.8820286659316428}\n",
      "{'loss': 1.5651, 'grad_norm': 8.542037010192871, 'learning_rate': 5.84845143830811e-07, 'epoch': 0.8830309712338378}\n",
      "{'loss': 1.1556, 'grad_norm': 1.4326525926589966, 'learning_rate': 5.798336173198356e-07, 'epoch': 0.8840332765360329}\n",
      "{'loss': 2.5267, 'grad_norm': 7.0561299324035645, 'learning_rate': 5.748220908088604e-07, 'epoch': 0.885035581838228}\n",
      "{'loss': 2.2418, 'grad_norm': 9.988436698913574, 'learning_rate': 5.698105642978852e-07, 'epoch': 0.886037887140423}\n",
      "{'loss': 2.1016, 'grad_norm': 6.8844780921936035, 'learning_rate': 5.6479903778691e-07, 'epoch': 0.887040192442618}\n",
      "{'loss': 1.6727, 'grad_norm': 11.806565284729004, 'learning_rate': 5.597875112759347e-07, 'epoch': 0.888042497744813}\n",
      "{'loss': 1.5332, 'grad_norm': 2.0585153102874756, 'learning_rate': 5.547759847649595e-07, 'epoch': 0.8890448030470082}\n",
      "{'loss': 2.2426, 'grad_norm': 9.062400817871094, 'learning_rate': 5.497644582539841e-07, 'epoch': 0.8900471083492032}\n",
      "{'loss': 2.6793, 'grad_norm': 5.593208312988281, 'learning_rate': 5.44752931743009e-07, 'epoch': 0.8910494136513982}\n",
      "{'loss': 1.7679, 'grad_norm': 4.743877410888672, 'learning_rate': 5.397414052320337e-07, 'epoch': 0.8920517189535933}\n",
      "{'loss': 2.2968, 'grad_norm': 6.469598293304443, 'learning_rate': 5.347298787210585e-07, 'epoch': 0.8930540242557883}\n",
      "{'loss': 1.4494, 'grad_norm': 3.7868785858154297, 'learning_rate': 5.297183522100832e-07, 'epoch': 0.8940563295579833}\n",
      "{'loss': 1.8836, 'grad_norm': 8.155787467956543, 'learning_rate': 5.24706825699108e-07, 'epoch': 0.8950586348601784}\n",
      "{'loss': 2.3541, 'grad_norm': 4.492824554443359, 'learning_rate': 5.196952991881328e-07, 'epoch': 0.8960609401623735}\n",
      "{'loss': 2.3734, 'grad_norm': 7.966909885406494, 'learning_rate': 5.146837726771575e-07, 'epoch': 0.8970632454645685}\n",
      "{'loss': 2.4559, 'grad_norm': 1.7908663749694824, 'learning_rate': 5.096722461661822e-07, 'epoch': 0.8980655507667635}\n",
      "{'loss': 2.4708, 'grad_norm': 6.18623685836792, 'learning_rate': 5.04660719655207e-07, 'epoch': 0.8990678560689586}\n",
      "{'loss': 1.8481, 'grad_norm': 7.934018135070801, 'learning_rate': 4.996491931442318e-07, 'epoch': 0.9000701613711537}\n",
      "{'loss': 1.8465, 'grad_norm': 13.27673625946045, 'learning_rate': 4.946376666332566e-07, 'epoch': 0.9010724666733487}\n",
      "{'loss': 2.2587, 'grad_norm': 12.551748275756836, 'learning_rate': 4.896261401222813e-07, 'epoch': 0.9020747719755438}\n",
      "{'loss': 1.4486, 'grad_norm': 5.040186405181885, 'learning_rate': 4.846146136113061e-07, 'epoch': 0.9030770772777388}\n",
      "{'loss': 2.1745, 'grad_norm': 6.236794948577881, 'learning_rate': 4.796030871003307e-07, 'epoch': 0.9040793825799338}\n",
      "{'loss': 0.91, 'grad_norm': 7.932641506195068, 'learning_rate': 4.745915605893556e-07, 'epoch': 0.905081687882129}\n",
      "{'loss': 2.0195, 'grad_norm': 2.572331666946411, 'learning_rate': 4.695800340783803e-07, 'epoch': 0.906083993184324}\n",
      "{'loss': 2.1084, 'grad_norm': 9.550430297851562, 'learning_rate': 4.645685075674051e-07, 'epoch': 0.907086298486519}\n",
      "{'loss': 1.5349, 'grad_norm': 5.081351280212402, 'learning_rate': 4.595569810564298e-07, 'epoch': 0.908088603788714}\n",
      "{'loss': 2.1545, 'grad_norm': 3.5916168689727783, 'learning_rate': 4.5454545454545457e-07, 'epoch': 0.9090909090909091}\n",
      "{'loss': 2.0427, 'grad_norm': 15.442309379577637, 'learning_rate': 4.495339280344793e-07, 'epoch': 0.9100932143931041}\n",
      "{'loss': 2.0997, 'grad_norm': 2.7724640369415283, 'learning_rate': 4.445224015235041e-07, 'epoch': 0.9110955196952992}\n",
      "{'loss': 2.0159, 'grad_norm': 5.627285003662109, 'learning_rate': 4.3951087501252883e-07, 'epoch': 0.9120978249974943}\n",
      "{'loss': 2.0518, 'grad_norm': 11.83828067779541, 'learning_rate': 4.344993485015536e-07, 'epoch': 0.9131001302996893}\n",
      "{'loss': 1.3285, 'grad_norm': 11.787035942077637, 'learning_rate': 4.2948782199057835e-07, 'epoch': 0.9141024356018843}\n",
      "{'loss': 2.8373, 'grad_norm': 7.328183650970459, 'learning_rate': 4.2447629547960314e-07, 'epoch': 0.9151047409040793}\n",
      "{'loss': 1.3451, 'grad_norm': 13.338629722595215, 'learning_rate': 4.1946476896862787e-07, 'epoch': 0.9161070462062745}\n",
      "{'loss': 2.563, 'grad_norm': 7.707284450531006, 'learning_rate': 4.1445324245765266e-07, 'epoch': 0.9171093515084695}\n",
      "{'loss': 2.0954, 'grad_norm': 2.906435966491699, 'learning_rate': 4.0944171594667734e-07, 'epoch': 0.9181116568106645}\n",
      "{'loss': 1.7748, 'grad_norm': 7.494561195373535, 'learning_rate': 4.044301894357022e-07, 'epoch': 0.9191139621128596}\n",
      "{'loss': 1.8064, 'grad_norm': 4.159941673278809, 'learning_rate': 3.9941866292472686e-07, 'epoch': 0.9201162674150546}\n",
      "{'loss': 2.4774, 'grad_norm': 6.512914657592773, 'learning_rate': 3.9440713641375165e-07, 'epoch': 0.9211185727172497}\n",
      "{'loss': 1.7893, 'grad_norm': 27.644126892089844, 'learning_rate': 3.893956099027764e-07, 'epoch': 0.9221208780194448}\n",
      "{'loss': 1.3549, 'grad_norm': 6.116163730621338, 'learning_rate': 3.8438408339180117e-07, 'epoch': 0.9231231833216398}\n",
      "{'loss': 2.5431, 'grad_norm': 7.462431907653809, 'learning_rate': 3.793725568808259e-07, 'epoch': 0.9241254886238348}\n",
      "{'loss': 2.5427, 'grad_norm': 11.176526069641113, 'learning_rate': 3.743610303698507e-07, 'epoch': 0.9251277939260298}\n",
      "{'loss': 2.0201, 'grad_norm': 5.8979668617248535, 'learning_rate': 3.693495038588754e-07, 'epoch': 0.9261300992282249}\n",
      "{'loss': 2.2195, 'grad_norm': 9.699442863464355, 'learning_rate': 3.643379773479002e-07, 'epoch': 0.92713240453042}\n",
      "{'loss': 1.817, 'grad_norm': 10.84890365600586, 'learning_rate': 3.5932645083692495e-07, 'epoch': 0.928134709832615}\n",
      "{'loss': 1.7115, 'grad_norm': 6.782705307006836, 'learning_rate': 3.5431492432594974e-07, 'epoch': 0.9291370151348101}\n",
      "{'loss': 3.2592, 'grad_norm': 7.107883453369141, 'learning_rate': 3.493033978149744e-07, 'epoch': 0.9301393204370051}\n",
      "{'loss': 2.6762, 'grad_norm': 7.013634204864502, 'learning_rate': 3.442918713039992e-07, 'epoch': 0.9311416257392001}\n",
      "{'loss': 1.8079, 'grad_norm': 29.85329246520996, 'learning_rate': 3.3928034479302394e-07, 'epoch': 0.9321439310413953}\n",
      "{'loss': 1.1326, 'grad_norm': 3.650084972381592, 'learning_rate': 3.342688182820487e-07, 'epoch': 0.9331462363435903}\n",
      "{'loss': 1.9475, 'grad_norm': 17.370319366455078, 'learning_rate': 3.2925729177107346e-07, 'epoch': 0.9341485416457853}\n",
      "{'loss': 1.8151, 'grad_norm': 3.025916576385498, 'learning_rate': 3.2424576526009825e-07, 'epoch': 0.9351508469479803}\n",
      "{'loss': 2.3994, 'grad_norm': 4.938182353973389, 'learning_rate': 3.1923423874912303e-07, 'epoch': 0.9361531522501754}\n",
      "{'loss': 2.3178, 'grad_norm': 0.0, 'learning_rate': 3.1422271223814777e-07, 'epoch': 0.9371554575523704}\n",
      "{'loss': 2.2392, 'grad_norm': 5.221969127655029, 'learning_rate': 3.092111857271725e-07, 'epoch': 0.9381577628545655}\n",
      "{'loss': 1.1781, 'grad_norm': 5.7297797203063965, 'learning_rate': 3.041996592161973e-07, 'epoch': 0.9391600681567606}\n",
      "{'loss': 2.1753, 'grad_norm': 6.800915241241455, 'learning_rate': 2.99188132705222e-07, 'epoch': 0.9401623734589556}\n",
      "{'loss': 1.6636, 'grad_norm': 9.230074882507324, 'learning_rate': 2.941766061942468e-07, 'epoch': 0.9411646787611506}\n",
      "{'loss': 1.7541, 'grad_norm': 4.461042881011963, 'learning_rate': 2.8916507968327155e-07, 'epoch': 0.9421669840633456}\n",
      "{'loss': 1.4815, 'grad_norm': 5.720327854156494, 'learning_rate': 2.841535531722963e-07, 'epoch': 0.9431692893655408}\n",
      "{'loss': 1.1468, 'grad_norm': 7.023102760314941, 'learning_rate': 2.7914202666132107e-07, 'epoch': 0.9441715946677358}\n",
      "{'loss': 1.7433, 'grad_norm': 7.445577621459961, 'learning_rate': 2.741305001503458e-07, 'epoch': 0.9451738999699308}\n",
      "{'loss': 1.2114, 'grad_norm': 10.537786483764648, 'learning_rate': 2.691189736393706e-07, 'epoch': 0.9461762052721259}\n",
      "{'loss': 1.4878, 'grad_norm': 5.521598815917969, 'learning_rate': 2.641074471283953e-07, 'epoch': 0.9471785105743209}\n",
      "{'loss': 2.1273, 'grad_norm': 10.03600788116455, 'learning_rate': 2.5909592061742006e-07, 'epoch': 0.948180815876516}\n",
      "{'loss': 1.6728, 'grad_norm': 3.7936151027679443, 'learning_rate': 2.5408439410644484e-07, 'epoch': 0.9491831211787111}\n",
      "{'loss': 1.9216, 'grad_norm': 29.299335479736328, 'learning_rate': 2.490728675954696e-07, 'epoch': 0.9501854264809061}\n",
      "{'loss': 2.6075, 'grad_norm': 8.653430938720703, 'learning_rate': 2.4406134108449437e-07, 'epoch': 0.9511877317831011}\n",
      "{'loss': 1.9366, 'grad_norm': 5.693832874298096, 'learning_rate': 2.390498145735191e-07, 'epoch': 0.9521900370852961}\n",
      "{'loss': 1.9864, 'grad_norm': 4.907839298248291, 'learning_rate': 2.3403828806254386e-07, 'epoch': 0.9531923423874912}\n",
      "{'loss': 1.6478, 'grad_norm': 4.818789482116699, 'learning_rate': 2.2902676155156862e-07, 'epoch': 0.9541946476896863}\n",
      "{'loss': 1.8384, 'grad_norm': 3.156863212585449, 'learning_rate': 2.2401523504059338e-07, 'epoch': 0.9551969529918813}\n",
      "{'loss': 2.4744, 'grad_norm': 5.526182651519775, 'learning_rate': 2.1900370852961812e-07, 'epoch': 0.9561992582940764}\n",
      "{'loss': 1.6159, 'grad_norm': 4.580270767211914, 'learning_rate': 2.1399218201864288e-07, 'epoch': 0.9572015635962714}\n",
      "{'loss': 2.1761, 'grad_norm': 7.064618110656738, 'learning_rate': 2.0898065550766764e-07, 'epoch': 0.9582038688984664}\n",
      "{'loss': 2.2007, 'grad_norm': 11.564249992370605, 'learning_rate': 2.039691289966924e-07, 'epoch': 0.9592061742006616}\n",
      "{'loss': 2.172, 'grad_norm': 5.123139381408691, 'learning_rate': 1.9895760248571716e-07, 'epoch': 0.9602084795028566}\n",
      "{'loss': 2.0274, 'grad_norm': 8.20943546295166, 'learning_rate': 1.9394607597474192e-07, 'epoch': 0.9612107848050516}\n",
      "{'loss': 1.828, 'grad_norm': 4.5088934898376465, 'learning_rate': 1.8893454946376665e-07, 'epoch': 0.9622130901072466}\n",
      "{'loss': 1.6679, 'grad_norm': 12.639400482177734, 'learning_rate': 1.8392302295279142e-07, 'epoch': 0.9632153954094417}\n",
      "{'loss': 1.9264, 'grad_norm': 7.159470081329346, 'learning_rate': 1.7891149644181618e-07, 'epoch': 0.9642177007116368}\n",
      "{'loss': 2.6137, 'grad_norm': 8.462642669677734, 'learning_rate': 1.7389996993084094e-07, 'epoch': 0.9652200060138318}\n",
      "{'loss': 2.2491, 'grad_norm': 8.824132919311523, 'learning_rate': 1.688884434198657e-07, 'epoch': 0.9662223113160269}\n",
      "{'loss': 1.463, 'grad_norm': 6.580870151519775, 'learning_rate': 1.6387691690889046e-07, 'epoch': 0.9672246166182219}\n",
      "{'loss': 2.0512, 'grad_norm': 7.405857086181641, 'learning_rate': 1.588653903979152e-07, 'epoch': 0.9682269219204169}\n",
      "{'loss': 1.5208, 'grad_norm': 1.089238166809082, 'learning_rate': 1.5385386388693998e-07, 'epoch': 0.969229227222612}\n",
      "{'loss': 3.5427, 'grad_norm': 8.516305923461914, 'learning_rate': 1.4884233737596474e-07, 'epoch': 0.9702315325248071}\n",
      "{'loss': 1.1402, 'grad_norm': 4.6187214851379395, 'learning_rate': 1.4383081086498947e-07, 'epoch': 0.9712338378270021}\n",
      "{'loss': 1.9684, 'grad_norm': 8.55916690826416, 'learning_rate': 1.3881928435401424e-07, 'epoch': 0.9722361431291972}\n",
      "{'loss': 2.0141, 'grad_norm': 7.908573150634766, 'learning_rate': 1.33807757843039e-07, 'epoch': 0.9732384484313922}\n",
      "{'loss': 1.4042, 'grad_norm': 3.6866040229797363, 'learning_rate': 1.2879623133206376e-07, 'epoch': 0.9742407537335872}\n",
      "{'loss': 1.8779, 'grad_norm': 7.928564071655273, 'learning_rate': 1.2378470482108852e-07, 'epoch': 0.9752430590357823}\n",
      "{'loss': 2.1969, 'grad_norm': 7.173897743225098, 'learning_rate': 1.1877317831011327e-07, 'epoch': 0.9762453643379774}\n",
      "{'loss': 1.8485, 'grad_norm': 7.528523921966553, 'learning_rate': 1.1376165179913803e-07, 'epoch': 0.9772476696401724}\n",
      "{'loss': 1.8433, 'grad_norm': 0.0, 'learning_rate': 1.0875012528816277e-07, 'epoch': 0.9782499749423674}\n",
      "{'loss': 2.2438, 'grad_norm': 9.639676094055176, 'learning_rate': 1.0373859877718753e-07, 'epoch': 0.9792522802445625}\n",
      "{'loss': 1.5889, 'grad_norm': 4.990735054016113, 'learning_rate': 9.87270722662123e-08, 'epoch': 0.9802545855467576}\n",
      "{'loss': 2.3035, 'grad_norm': 6.165881633758545, 'learning_rate': 9.371554575523704e-08, 'epoch': 0.9812568908489526}\n",
      "{'loss': 2.132, 'grad_norm': 25.85968017578125, 'learning_rate': 8.87040192442618e-08, 'epoch': 0.9822591961511477}\n",
      "{'loss': 1.4436, 'grad_norm': 8.904168128967285, 'learning_rate': 8.369249273328656e-08, 'epoch': 0.9832615014533427}\n",
      "{'loss': 2.038, 'grad_norm': 6.860404014587402, 'learning_rate': 7.868096622231131e-08, 'epoch': 0.9842638067555377}\n",
      "{'loss': 2.0487, 'grad_norm': 2.3042795658111572, 'learning_rate': 7.366943971133609e-08, 'epoch': 0.9852661120577327}\n",
      "{'loss': 1.303, 'grad_norm': 0.4336842894554138, 'learning_rate': 6.865791320036083e-08, 'epoch': 0.9862684173599279}\n",
      "{'loss': 1.8543, 'grad_norm': 7.300917625427246, 'learning_rate': 6.36463866893856e-08, 'epoch': 0.9872707226621229}\n",
      "{'loss': 0.8772, 'grad_norm': 0.0, 'learning_rate': 5.863486017841035e-08, 'epoch': 0.9882730279643179}\n",
      "{'loss': 2.8855, 'grad_norm': 5.87714147567749, 'learning_rate': 5.36233336674351e-08, 'epoch': 0.989275333266513}\n",
      "{'loss': 1.269, 'grad_norm': 15.854966163635254, 'learning_rate': 4.861180715645986e-08, 'epoch': 0.990277638568708}\n",
      "{'loss': 1.6656, 'grad_norm': 4.220335483551025, 'learning_rate': 4.360028064548462e-08, 'epoch': 0.9912799438709031}\n",
      "{'loss': 1.1989, 'grad_norm': 2.3277747631073, 'learning_rate': 3.858875413450937e-08, 'epoch': 0.9922822491730982}\n",
      "{'loss': 1.9225, 'grad_norm': 6.698521614074707, 'learning_rate': 3.357722762353413e-08, 'epoch': 0.9932845544752932}\n",
      "{'loss': 1.6245, 'grad_norm': 9.469996452331543, 'learning_rate': 2.856570111255889e-08, 'epoch': 0.9942868597774882}\n",
      "{'loss': 2.4264, 'grad_norm': 8.562389373779297, 'learning_rate': 2.3554174601583647e-08, 'epoch': 0.9952891650796832}\n",
      "{'loss': 1.7713, 'grad_norm': 7.754574775695801, 'learning_rate': 1.85426480906084e-08, 'epoch': 0.9962914703818784}\n",
      "{'loss': 1.9882, 'grad_norm': 7.951426982879639, 'learning_rate': 1.3531121579633159e-08, 'epoch': 0.9972937756840734}\n",
      "{'loss': 2.2507, 'grad_norm': 5.148945331573486, 'learning_rate': 8.519595068657914e-09, 'epoch': 0.9982960809862684}\n",
      "{'loss': 1.7627, 'grad_norm': 3.360380172729492, 'learning_rate': 3.5080685576826705e-09, 'epoch': 0.9992983862884635}\n",
      "{'eval_loss': nan, 'eval_runtime': 156.6881, 'eval_samples_per_second': 15.866, 'eval_steps_per_second': 15.866, 'epoch': 1.0}\n",
      "{'train_runtime': 4500.7302, 'train_samples_per_second': 4.434, 'train_steps_per_second': 2.217, 'train_loss': 2.384026352002122, 'epoch': 1.0}\n",
      "[COMPLETE] Elapsed: 4500.97s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7fe30dda9d10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train the GPT-2 Medium model with the quest data\n",
    "gpt2_medium_trainer: Trainer = gpt2_medium_model.tokenize_and_train(quest_set)\n",
    "gpt2_medium_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddd11881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOWNLOAD] gpt2-large (openai-community/gpt2-large)\n",
      "[LoRAINFO] trainable params: 5,898,240 || all params: 426,033,920 || trainable%: 1.3845\n",
      "[COMPLETE] \"gpt2-large\" ready in 62.60s.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuestGenLLM(tokenizer=GPT2TokenizerFast(name_or_path='openai-community/gpt2-large', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}\n",
       "), model=PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 1280)\n",
       "        (wpe): Embedding(1024, 1280)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-35): 36 x GPT2Block(\n",
       "            (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=1280, out_features=3840, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3840, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1280, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1280, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       "    )\n",
       "  )\n",
       "), model_key='gpt2-large', model_id='openai-community/gpt2-large', fp16_available=True, device='cuda:0', dtype='float32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the GPT-2 Large model\n",
    "gpt2_large_model: QuestGenLLM = QuestGenLLM.from_pretrained(\n",
    "    model_key=\"gpt2-large\", model_id=MODEL_IDENTIFIERS[\"gpt2-large\"]\n",
    ")\n",
    "gpt2_large_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22c8625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOKENIZE] gpt2-large (openai-community/gpt2-large)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b953f3d700634c3191a73fef61e98e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19954 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8de2a28faad4a96a9e05d8bf2c8ae8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMPLETE] Elapsed: 1.42s\n",
      "\n",
      "[FINETUNE] gpt2-large (openai-community/gpt2-large)\n",
      "{'loss': 4.2989, 'grad_norm': 1.9841364622116089, 'learning_rate': 4.994988473489026e-06, 'epoch': 0.0010023053021950487}\n",
      "{'loss': 4.3669, 'grad_norm': 3.23563814163208, 'learning_rate': 4.98997694697805e-06, 'epoch': 0.0020046106043900974}\n",
      "{'loss': 4.5519, 'grad_norm': 4.506359100341797, 'learning_rate': 4.984965420467074e-06, 'epoch': 0.0030069159065851457}\n",
      "{'loss': 4.5961, 'grad_norm': 2.799888849258423, 'learning_rate': 4.9799538939560996e-06, 'epoch': 0.004009221208780195}\n",
      "{'loss': 4.4529, 'grad_norm': 3.559256076812744, 'learning_rate': 4.974942367445124e-06, 'epoch': 0.005011526510975243}\n",
      "{'loss': 4.1272, 'grad_norm': 5.287730693817139, 'learning_rate': 4.969930840934149e-06, 'epoch': 0.006013831813170291}\n",
      "{'loss': 4.5184, 'grad_norm': 2.398099660873413, 'learning_rate': 4.9649193144231735e-06, 'epoch': 0.00701613711536534}\n",
      "{'loss': 4.2055, 'grad_norm': 2.139139413833618, 'learning_rate': 4.959907787912199e-06, 'epoch': 0.00801844241756039}\n",
      "{'loss': 3.9287, 'grad_norm': 2.0721242427825928, 'learning_rate': 4.954896261401223e-06, 'epoch': 0.009020747719755437}\n",
      "{'loss': 4.094, 'grad_norm': 1.0123366117477417, 'learning_rate': 4.949884734890248e-06, 'epoch': 0.010023053021950485}\n",
      "{'loss': 4.1571, 'grad_norm': 7.537519931793213, 'learning_rate': 4.944873208379273e-06, 'epoch': 0.011025358324145534}\n",
      "{'loss': 4.2245, 'grad_norm': 1.4046872854232788, 'learning_rate': 4.939861681868298e-06, 'epoch': 0.012027663626340583}\n",
      "{'loss': 4.6717, 'grad_norm': 4.469829559326172, 'learning_rate': 4.934850155357322e-06, 'epoch': 0.013029968928535631}\n",
      "{'loss': 3.9721, 'grad_norm': 1.8822368383407593, 'learning_rate': 4.929838628846347e-06, 'epoch': 0.01403227423073068}\n",
      "{'loss': 4.6957, 'grad_norm': 2.8035309314727783, 'learning_rate': 4.924827102335372e-06, 'epoch': 0.015034579532925729}\n",
      "{'loss': 4.0409, 'grad_norm': 2.0125739574432373, 'learning_rate': 4.919815575824396e-06, 'epoch': 0.01603688483512078}\n",
      "{'loss': 4.076, 'grad_norm': 3.0368432998657227, 'learning_rate': 4.914804049313421e-06, 'epoch': 0.017039190137315828}\n",
      "{'loss': 3.8998, 'grad_norm': 7.347426414489746, 'learning_rate': 4.909792522802447e-06, 'epoch': 0.018041495439510873}\n",
      "{'loss': 4.354, 'grad_norm': 3.162818431854248, 'learning_rate': 4.904780996291471e-06, 'epoch': 0.019043800741705922}\n",
      "{'loss': 3.9069, 'grad_norm': 2.115812063217163, 'learning_rate': 4.899769469780495e-06, 'epoch': 0.02004610604390097}\n",
      "{'loss': 4.0555, 'grad_norm': 2.8690927028656006, 'learning_rate': 4.8947579432695205e-06, 'epoch': 0.02104841134609602}\n",
      "{'loss': 3.4939, 'grad_norm': 1.566918134689331, 'learning_rate': 4.889746416758545e-06, 'epoch': 0.022050716648291068}\n",
      "{'loss': 4.6033, 'grad_norm': 4.494696617126465, 'learning_rate': 4.88473489024757e-06, 'epoch': 0.023053021950486117}\n",
      "{'loss': 3.2597, 'grad_norm': 2.0903568267822266, 'learning_rate': 4.8797233637365945e-06, 'epoch': 0.024055327252681166}\n",
      "{'loss': 3.3957, 'grad_norm': 1.9004337787628174, 'learning_rate': 4.874711837225619e-06, 'epoch': 0.025057632554876214}\n",
      "{'loss': 3.9269, 'grad_norm': 2.8720273971557617, 'learning_rate': 4.869700310714644e-06, 'epoch': 0.026059937857071263}\n",
      "{'loss': 3.9518, 'grad_norm': 2.251734972000122, 'learning_rate': 4.864688784203669e-06, 'epoch': 0.02706224315926631}\n",
      "{'loss': 3.7201, 'grad_norm': 3.489057779312134, 'learning_rate': 4.859677257692694e-06, 'epoch': 0.02806454846146136}\n",
      "{'loss': 3.6266, 'grad_norm': 2.092348575592041, 'learning_rate': 4.854665731181719e-06, 'epoch': 0.02906685376365641}\n",
      "{'loss': 3.4118, 'grad_norm': 5.9634690284729, 'learning_rate': 4.849654204670743e-06, 'epoch': 0.030069159065851458}\n",
      "{'loss': 3.8388, 'grad_norm': 1.8123537302017212, 'learning_rate': 4.8446426781597675e-06, 'epoch': 0.031071464368046506}\n",
      "{'loss': 3.5014, 'grad_norm': 3.6085708141326904, 'learning_rate': 4.839631151648793e-06, 'epoch': 0.03207376967024156}\n",
      "{'loss': 3.1322, 'grad_norm': 2.088026762008667, 'learning_rate': 4.834619625137817e-06, 'epoch': 0.03307607497243661}\n",
      "{'loss': 3.8111, 'grad_norm': 8.469640731811523, 'learning_rate': 4.829608098626842e-06, 'epoch': 0.034078380274631656}\n",
      "{'loss': 3.6455, 'grad_norm': 5.100505828857422, 'learning_rate': 4.824596572115867e-06, 'epoch': 0.035080685576826705}\n",
      "{'loss': 3.7218, 'grad_norm': 6.358315467834473, 'learning_rate': 4.819585045604892e-06, 'epoch': 0.03608299087902175}\n",
      "{'loss': 3.6723, 'grad_norm': 1.649733304977417, 'learning_rate': 4.814573519093916e-06, 'epoch': 0.037085296181216795}\n",
      "{'loss': 3.5063, 'grad_norm': 4.663021087646484, 'learning_rate': 4.8095619925829415e-06, 'epoch': 0.038087601483411844}\n",
      "{'loss': 3.8134, 'grad_norm': 3.479320764541626, 'learning_rate': 4.804550466071966e-06, 'epoch': 0.03908990678560689}\n",
      "{'loss': 3.6064, 'grad_norm': 5.78873872756958, 'learning_rate': 4.799538939560991e-06, 'epoch': 0.04009221208780194}\n",
      "{'loss': 3.1664, 'grad_norm': 2.6514086723327637, 'learning_rate': 4.794527413050015e-06, 'epoch': 0.04109451738999699}\n",
      "{'loss': 3.3912, 'grad_norm': 2.7189762592315674, 'learning_rate': 4.78951588653904e-06, 'epoch': 0.04209682269219204}\n",
      "{'loss': 3.1093, 'grad_norm': 6.401658535003662, 'learning_rate': 4.784504360028065e-06, 'epoch': 0.04309912799438709}\n",
      "{'loss': 3.4759, 'grad_norm': 7.172564506530762, 'learning_rate': 4.77949283351709e-06, 'epoch': 0.044101433296582136}\n",
      "{'loss': 3.6653, 'grad_norm': 2.003049612045288, 'learning_rate': 4.7744813070061146e-06, 'epoch': 0.045103738598777185}\n",
      "{'loss': 3.9092, 'grad_norm': 9.385778427124023, 'learning_rate': 4.769469780495139e-06, 'epoch': 0.046106043900972234}\n",
      "{'loss': 3.4698, 'grad_norm': 7.601522445678711, 'learning_rate': 4.764458253984164e-06, 'epoch': 0.04710834920316728}\n",
      "{'loss': 2.8409, 'grad_norm': 3.569227695465088, 'learning_rate': 4.7594467274731885e-06, 'epoch': 0.04811065450536233}\n",
      "{'loss': 3.2976, 'grad_norm': 8.613914489746094, 'learning_rate': 4.754435200962214e-06, 'epoch': 0.04911295980755738}\n",
      "{'loss': 2.9372, 'grad_norm': 5.471620559692383, 'learning_rate': 4.749423674451238e-06, 'epoch': 0.05011526510975243}\n",
      "{'loss': 3.1761, 'grad_norm': 2.1852667331695557, 'learning_rate': 4.7444121479402624e-06, 'epoch': 0.05111757041194748}\n",
      "{'loss': 3.1187, 'grad_norm': 3.9308578968048096, 'learning_rate': 4.739400621429288e-06, 'epoch': 0.052119875714142526}\n",
      "{'loss': 3.0576, 'grad_norm': 9.270962715148926, 'learning_rate': 4.734389094918313e-06, 'epoch': 0.053122181016337575}\n",
      "{'loss': 2.9771, 'grad_norm': 5.0394110679626465, 'learning_rate': 4.729377568407337e-06, 'epoch': 0.05412448631853262}\n",
      "{'loss': 2.1013, 'grad_norm': 2.9140264987945557, 'learning_rate': 4.7243660418963624e-06, 'epoch': 0.05512679162072767}\n",
      "{'loss': 2.9424, 'grad_norm': 3.4213707447052, 'learning_rate': 4.719354515385387e-06, 'epoch': 0.05612909692292272}\n",
      "{'loss': 2.7425, 'grad_norm': 3.8164381980895996, 'learning_rate': 4.714342988874411e-06, 'epoch': 0.05713140222511777}\n",
      "{'loss': 3.3761, 'grad_norm': 9.04179859161377, 'learning_rate': 4.709331462363436e-06, 'epoch': 0.05813370752731282}\n",
      "{'loss': 3.4389, 'grad_norm': 7.244897842407227, 'learning_rate': 4.704319935852461e-06, 'epoch': 0.05913601282950787}\n",
      "{'loss': 3.2057, 'grad_norm': 11.163703918457031, 'learning_rate': 4.699308409341486e-06, 'epoch': 0.060138318131702916}\n",
      "{'loss': 2.8341, 'grad_norm': 5.098126411437988, 'learning_rate': 4.694296882830511e-06, 'epoch': 0.061140623433897964}\n",
      "{'loss': 2.5807, 'grad_norm': 3.7806148529052734, 'learning_rate': 4.689285356319535e-06, 'epoch': 0.06214292873609301}\n",
      "{'loss': 3.2992, 'grad_norm': 2.496420383453369, 'learning_rate': 4.68427382980856e-06, 'epoch': 0.06314523403828806}\n",
      "{'loss': 2.5732, 'grad_norm': 14.422563552856445, 'learning_rate': 4.679262303297585e-06, 'epoch': 0.06414753934048312}\n",
      "{'loss': 3.0874, 'grad_norm': 7.8292670249938965, 'learning_rate': 4.6742507767866095e-06, 'epoch': 0.06514984464267816}\n",
      "{'loss': 2.526, 'grad_norm': 5.222034454345703, 'learning_rate': 4.669239250275635e-06, 'epoch': 0.06615214994487321}\n",
      "{'loss': 2.5926, 'grad_norm': 5.097641468048096, 'learning_rate': 4.664227723764659e-06, 'epoch': 0.06715445524706826}\n",
      "{'loss': 2.0829, 'grad_norm': 5.077376842498779, 'learning_rate': 4.659216197253683e-06, 'epoch': 0.06815676054926331}\n",
      "{'loss': 2.6901, 'grad_norm': 2.946423292160034, 'learning_rate': 4.654204670742709e-06, 'epoch': 0.06915906585145835}\n",
      "{'loss': 2.9715, 'grad_norm': 30.11772346496582, 'learning_rate': 4.649193144231734e-06, 'epoch': 0.07016137115365341}\n",
      "{'loss': 2.8271, 'grad_norm': 3.3276474475860596, 'learning_rate': 4.644181617720758e-06, 'epoch': 0.07116367645584845}\n",
      "{'loss': 2.5724, 'grad_norm': 4.245900630950928, 'learning_rate': 4.639170091209783e-06, 'epoch': 0.0721659817580435}\n",
      "{'loss': 2.5214, 'grad_norm': 5.773539066314697, 'learning_rate': 4.634158564698808e-06, 'epoch': 0.07316828706023855}\n",
      "{'loss': 2.9877, 'grad_norm': 23.49077796936035, 'learning_rate': 4.629147038187832e-06, 'epoch': 0.07417059236243359}\n",
      "{'loss': 3.454, 'grad_norm': 16.20810317993164, 'learning_rate': 4.624135511676857e-06, 'epoch': 0.07517289766462865}\n",
      "{'loss': 2.5186, 'grad_norm': 3.2451419830322266, 'learning_rate': 4.619123985165882e-06, 'epoch': 0.07617520296682369}\n",
      "{'loss': 3.2197, 'grad_norm': 8.436819076538086, 'learning_rate': 4.614112458654907e-06, 'epoch': 0.07717750826901874}\n",
      "{'loss': 2.2628, 'grad_norm': 3.755207061767578, 'learning_rate': 4.609100932143931e-06, 'epoch': 0.07817981357121379}\n",
      "{'loss': 2.7056, 'grad_norm': 26.813230514526367, 'learning_rate': 4.604089405632956e-06, 'epoch': 0.07918211887340884}\n",
      "{'loss': 2.4385, 'grad_norm': 3.9018094539642334, 'learning_rate': 4.599077879121981e-06, 'epoch': 0.08018442417560388}\n",
      "{'loss': 2.4224, 'grad_norm': 4.976461887359619, 'learning_rate': 4.594066352611006e-06, 'epoch': 0.08118672947779894}\n",
      "{'loss': 3.3597, 'grad_norm': 5.703209400177002, 'learning_rate': 4.58905482610003e-06, 'epoch': 0.08218903477999398}\n",
      "{'loss': 2.5371, 'grad_norm': 5.819577217102051, 'learning_rate': 4.584043299589056e-06, 'epoch': 0.08319134008218904}\n",
      "{'loss': 2.0682, 'grad_norm': 9.115372657775879, 'learning_rate': 4.57903177307808e-06, 'epoch': 0.08419364538438408}\n",
      "{'loss': 1.7919, 'grad_norm': 6.846425533294678, 'learning_rate': 4.574020246567104e-06, 'epoch': 0.08519595068657913}\n",
      "{'loss': 2.7421, 'grad_norm': 7.284067630767822, 'learning_rate': 4.5690087200561296e-06, 'epoch': 0.08619825598877418}\n",
      "{'loss': 2.5443, 'grad_norm': 5.1638054847717285, 'learning_rate': 4.563997193545155e-06, 'epoch': 0.08720056129096923}\n",
      "{'loss': 2.696, 'grad_norm': 13.410841941833496, 'learning_rate': 4.558985667034179e-06, 'epoch': 0.08820286659316427}\n",
      "{'loss': 2.7937, 'grad_norm': 5.571617603302002, 'learning_rate': 4.5539741405232035e-06, 'epoch': 0.08920517189535933}\n",
      "{'loss': 3.0117, 'grad_norm': 9.158546447753906, 'learning_rate': 4.548962614012229e-06, 'epoch': 0.09020747719755437}\n",
      "{'loss': 2.6304, 'grad_norm': 5.947723865509033, 'learning_rate': 4.543951087501253e-06, 'epoch': 0.09120978249974943}\n",
      "{'loss': 2.7012, 'grad_norm': 9.66827392578125, 'learning_rate': 4.538939560990278e-06, 'epoch': 0.09221208780194447}\n",
      "{'loss': 2.9635, 'grad_norm': 6.05729341506958, 'learning_rate': 4.533928034479303e-06, 'epoch': 0.09321439310413952}\n",
      "{'loss': 2.5295, 'grad_norm': 17.87990379333496, 'learning_rate': 4.528916507968327e-06, 'epoch': 0.09421669840633456}\n",
      "{'loss': 3.2012, 'grad_norm': 8.51833438873291, 'learning_rate': 4.523904981457352e-06, 'epoch': 0.09521900370852962}\n",
      "{'loss': 2.8243, 'grad_norm': 2.6451122760772705, 'learning_rate': 4.518893454946377e-06, 'epoch': 0.09622130901072466}\n",
      "{'loss': 2.9639, 'grad_norm': 6.834874153137207, 'learning_rate': 4.513881928435402e-06, 'epoch': 0.09722361431291972}\n",
      "{'loss': 2.6061, 'grad_norm': 4.671425819396973, 'learning_rate': 4.508870401924427e-06, 'epoch': 0.09822591961511476}\n",
      "{'loss': 3.4452, 'grad_norm': 5.174430847167969, 'learning_rate': 4.503858875413451e-06, 'epoch': 0.09922822491730982}\n",
      "{'loss': 2.7674, 'grad_norm': 11.341160774230957, 'learning_rate': 4.498847348902476e-06, 'epoch': 0.10023053021950486}\n",
      "{'loss': 2.7189, 'grad_norm': 0.0, 'learning_rate': 4.493835822391501e-06, 'epoch': 0.10123283552169991}\n",
      "{'loss': 2.6249, 'grad_norm': 6.756346702575684, 'learning_rate': 4.488824295880525e-06, 'epoch': 0.10223514082389495}\n",
      "{'loss': 2.8847, 'grad_norm': 6.440170764923096, 'learning_rate': 4.4838127693695505e-06, 'epoch': 0.10323744612609001}\n",
      "{'loss': 3.2951, 'grad_norm': 13.461365699768066, 'learning_rate': 4.478801242858576e-06, 'epoch': 0.10423975142828505}\n",
      "{'loss': 2.4025, 'grad_norm': 3.8835017681121826, 'learning_rate': 4.473789716347599e-06, 'epoch': 0.10524205673048011}\n",
      "{'loss': 2.02, 'grad_norm': 6.1983771324157715, 'learning_rate': 4.4687781898366245e-06, 'epoch': 0.10624436203267515}\n",
      "{'loss': 2.0016, 'grad_norm': 6.916881084442139, 'learning_rate': 4.46376666332565e-06, 'epoch': 0.1072466673348702}\n",
      "{'loss': 2.7186, 'grad_norm': 7.813257217407227, 'learning_rate': 4.458755136814674e-06, 'epoch': 0.10824897263706525}\n",
      "{'loss': 1.686, 'grad_norm': 10.494271278381348, 'learning_rate': 4.453743610303699e-06, 'epoch': 0.1092512779392603}\n",
      "{'loss': 3.6469, 'grad_norm': 4.862451076507568, 'learning_rate': 4.448732083792724e-06, 'epoch': 0.11025358324145534}\n",
      "{'loss': 3.0234, 'grad_norm': 4.725953102111816, 'learning_rate': 4.443720557281748e-06, 'epoch': 0.1112558885436504}\n",
      "{'loss': 2.3378, 'grad_norm': 5.1181440353393555, 'learning_rate': 4.438709030770773e-06, 'epoch': 0.11225819384584544}\n",
      "{'loss': 2.1307, 'grad_norm': 9.686202049255371, 'learning_rate': 4.4336975042597976e-06, 'epoch': 0.1132604991480405}\n",
      "{'loss': 2.0818, 'grad_norm': 5.431640148162842, 'learning_rate': 4.428685977748823e-06, 'epoch': 0.11426280445023554}\n",
      "{'loss': 2.7638, 'grad_norm': 0.0, 'learning_rate': 4.423674451237848e-06, 'epoch': 0.1152651097524306}\n",
      "{'loss': 2.4194, 'grad_norm': 6.1203813552856445, 'learning_rate': 4.418662924726872e-06, 'epoch': 0.11626741505462564}\n",
      "{'loss': 2.5911, 'grad_norm': 8.562774658203125, 'learning_rate': 4.413651398215897e-06, 'epoch': 0.11726972035682069}\n",
      "{'loss': 2.2607, 'grad_norm': 6.608663082122803, 'learning_rate': 4.408639871704922e-06, 'epoch': 0.11827202565901573}\n",
      "{'loss': 2.7217, 'grad_norm': 7.088428974151611, 'learning_rate': 4.403628345193946e-06, 'epoch': 0.11927433096121079}\n",
      "{'loss': 2.1004, 'grad_norm': 9.45617961883545, 'learning_rate': 4.3986168186829715e-06, 'epoch': 0.12027663626340583}\n",
      "{'loss': 2.5357, 'grad_norm': 4.039320945739746, 'learning_rate': 4.393605292171996e-06, 'epoch': 0.12127894156560089}\n",
      "{'loss': 1.6546, 'grad_norm': 7.389503479003906, 'learning_rate': 4.38859376566102e-06, 'epoch': 0.12228124686779593}\n",
      "{'loss': 1.9614, 'grad_norm': 5.090658187866211, 'learning_rate': 4.3835822391500454e-06, 'epoch': 0.12328355216999098}\n",
      "{'loss': 2.3222, 'grad_norm': 11.782073974609375, 'learning_rate': 4.378570712639071e-06, 'epoch': 0.12428585747218603}\n",
      "{'loss': 1.8878, 'grad_norm': 6.410547733306885, 'learning_rate': 4.373559186128095e-06, 'epoch': 0.12528816277438107}\n",
      "{'loss': 2.499, 'grad_norm': 6.133979797363281, 'learning_rate': 4.368547659617119e-06, 'epoch': 0.12629046807657612}\n",
      "{'loss': 2.8269, 'grad_norm': 5.497385025024414, 'learning_rate': 4.3635361331061446e-06, 'epoch': 0.12729277337877118}\n",
      "{'loss': 2.1002, 'grad_norm': 6.734853744506836, 'learning_rate': 4.358524606595169e-06, 'epoch': 0.12829507868096623}\n",
      "{'loss': 2.1926, 'grad_norm': 4.4578962326049805, 'learning_rate': 4.353513080084194e-06, 'epoch': 0.12929738398316126}\n",
      "{'loss': 1.6946, 'grad_norm': 3.7907869815826416, 'learning_rate': 4.3485015535732185e-06, 'epoch': 0.13029968928535632}\n",
      "{'loss': 2.0204, 'grad_norm': 3.645705461502075, 'learning_rate': 4.343490027062244e-06, 'epoch': 0.13130199458755137}\n",
      "{'loss': 2.2752, 'grad_norm': 5.435298442840576, 'learning_rate': 4.338478500551268e-06, 'epoch': 0.13230429988974643}\n",
      "{'loss': 2.0171, 'grad_norm': 5.121659278869629, 'learning_rate': 4.333466974040293e-06, 'epoch': 0.13330660519194146}\n",
      "{'loss': 1.8058, 'grad_norm': 5.716175079345703, 'learning_rate': 4.328455447529318e-06, 'epoch': 0.1343089104941365}\n",
      "{'loss': 2.3643, 'grad_norm': 12.928966522216797, 'learning_rate': 4.323443921018343e-06, 'epoch': 0.13531121579633157}\n",
      "{'loss': 2.9108, 'grad_norm': 7.012472152709961, 'learning_rate': 4.318432394507367e-06, 'epoch': 0.13631352109852662}\n",
      "{'loss': 2.5027, 'grad_norm': 11.538740158081055, 'learning_rate': 4.313420867996392e-06, 'epoch': 0.13731582640072165}\n",
      "{'loss': 2.3541, 'grad_norm': 8.271907806396484, 'learning_rate': 4.308409341485417e-06, 'epoch': 0.1383181317029167}\n",
      "{'loss': 2.2809, 'grad_norm': 6.151761531829834, 'learning_rate': 4.303397814974441e-06, 'epoch': 0.13932043700511176}\n",
      "{'loss': 2.2228, 'grad_norm': 4.58900260925293, 'learning_rate': 4.298386288463466e-06, 'epoch': 0.14032274230730682}\n",
      "{'loss': 2.9638, 'grad_norm': 7.429559230804443, 'learning_rate': 4.293374761952492e-06, 'epoch': 0.14132504760950185}\n",
      "{'loss': 2.6414, 'grad_norm': 7.038646697998047, 'learning_rate': 4.288363235441516e-06, 'epoch': 0.1423273529116969}\n",
      "{'loss': 2.2227, 'grad_norm': 7.160321235656738, 'learning_rate': 4.28335170893054e-06, 'epoch': 0.14332965821389196}\n",
      "{'loss': 2.3784, 'grad_norm': 16.31102180480957, 'learning_rate': 4.2783401824195655e-06, 'epoch': 0.144331963516087}\n",
      "{'loss': 2.6899, 'grad_norm': 7.467768669128418, 'learning_rate': 4.27332865590859e-06, 'epoch': 0.14533426881828204}\n",
      "{'loss': 2.1001, 'grad_norm': 6.606025218963623, 'learning_rate': 4.268317129397615e-06, 'epoch': 0.1463365741204771}\n",
      "{'loss': 2.1557, 'grad_norm': 6.272572994232178, 'learning_rate': 4.2633056028866395e-06, 'epoch': 0.14733887942267215}\n",
      "{'loss': 2.3436, 'grad_norm': 8.179474830627441, 'learning_rate': 4.258294076375664e-06, 'epoch': 0.14834118472486718}\n",
      "{'loss': 2.1161, 'grad_norm': 6.34255838394165, 'learning_rate': 4.253282549864689e-06, 'epoch': 0.14934349002706224}\n",
      "{'loss': 2.246, 'grad_norm': 10.143345832824707, 'learning_rate': 4.248271023353714e-06, 'epoch': 0.1503457953292573}\n",
      "{'loss': 2.2051, 'grad_norm': 11.73130989074707, 'learning_rate': 4.243259496842739e-06, 'epoch': 0.15134810063145235}\n",
      "{'loss': 2.1371, 'grad_norm': 7.160685062408447, 'learning_rate': 4.238247970331764e-06, 'epoch': 0.15235040593364738}\n",
      "{'loss': 2.2235, 'grad_norm': 5.848840236663818, 'learning_rate': 4.233236443820788e-06, 'epoch': 0.15335271123584243}\n",
      "{'loss': 2.5409, 'grad_norm': 5.207876205444336, 'learning_rate': 4.2282249173098126e-06, 'epoch': 0.1543550165380375}\n",
      "{'loss': 1.514, 'grad_norm': 8.891117095947266, 'learning_rate': 4.223213390798838e-06, 'epoch': 0.15535732184023254}\n",
      "{'loss': 2.1605, 'grad_norm': 8.50172233581543, 'learning_rate': 4.218201864287862e-06, 'epoch': 0.15635962714242757}\n",
      "{'loss': 2.0875, 'grad_norm': 0.9216154217720032, 'learning_rate': 4.213190337776887e-06, 'epoch': 0.15736193244462263}\n",
      "{'loss': 2.2338, 'grad_norm': 6.346955299377441, 'learning_rate': 4.2081788112659126e-06, 'epoch': 0.15836423774681768}\n",
      "{'loss': 2.2117, 'grad_norm': 1.3213348388671875, 'learning_rate': 4.203167284754937e-06, 'epoch': 0.15936654304901274}\n",
      "{'loss': 2.4764, 'grad_norm': 8.892509460449219, 'learning_rate': 4.198155758243961e-06, 'epoch': 0.16036884835120777}\n",
      "{'loss': 1.8401, 'grad_norm': 6.7392578125, 'learning_rate': 4.1931442317329865e-06, 'epoch': 0.16137115365340282}\n",
      "{'loss': 2.5992, 'grad_norm': 6.817963600158691, 'learning_rate': 4.188132705222011e-06, 'epoch': 0.16237345895559788}\n",
      "{'loss': 2.2285, 'grad_norm': 9.857504844665527, 'learning_rate': 4.183121178711036e-06, 'epoch': 0.16337576425779293}\n",
      "{'loss': 2.7797, 'grad_norm': 5.6460490226745605, 'learning_rate': 4.1781096522000604e-06, 'epoch': 0.16437806955998796}\n",
      "{'loss': 2.0967, 'grad_norm': 4.175471782684326, 'learning_rate': 4.173098125689085e-06, 'epoch': 0.16538037486218302}\n",
      "{'loss': 1.8397, 'grad_norm': 9.48749828338623, 'learning_rate': 4.16808659917811e-06, 'epoch': 0.16638268016437807}\n",
      "{'loss': 1.5996, 'grad_norm': 7.420097351074219, 'learning_rate': 4.163075072667135e-06, 'epoch': 0.16738498546657313}\n",
      "{'loss': 2.4003, 'grad_norm': 3.890158176422119, 'learning_rate': 4.15806354615616e-06, 'epoch': 0.16838729076876816}\n",
      "{'loss': 2.9112, 'grad_norm': 6.19766902923584, 'learning_rate': 4.153052019645184e-06, 'epoch': 0.1693895960709632}\n",
      "{'loss': 2.3928, 'grad_norm': 6.924117088317871, 'learning_rate': 4.148040493134209e-06, 'epoch': 0.17039190137315827}\n",
      "{'loss': 2.3517, 'grad_norm': 6.5557661056518555, 'learning_rate': 4.1430289666232335e-06, 'epoch': 0.17139420667535332}\n",
      "{'loss': 2.2816, 'grad_norm': 43.02334976196289, 'learning_rate': 4.138017440112259e-06, 'epoch': 0.17239651197754835}\n",
      "{'loss': 2.526, 'grad_norm': 7.169643402099609, 'learning_rate': 4.133005913601283e-06, 'epoch': 0.1733988172797434}\n",
      "{'loss': 1.539, 'grad_norm': 8.628604888916016, 'learning_rate': 4.127994387090308e-06, 'epoch': 0.17440112258193846}\n",
      "{'loss': 1.8461, 'grad_norm': 5.9221086502075195, 'learning_rate': 4.122982860579333e-06, 'epoch': 0.17540342788413352}\n",
      "{'loss': 2.3367, 'grad_norm': 5.118366718292236, 'learning_rate': 4.117971334068358e-06, 'epoch': 0.17640573318632854}\n",
      "{'loss': 1.5613, 'grad_norm': 45.091705322265625, 'learning_rate': 4.112959807557382e-06, 'epoch': 0.1774080384885236}\n",
      "{'loss': 2.125, 'grad_norm': 15.947935104370117, 'learning_rate': 4.1079482810464075e-06, 'epoch': 0.17841034379071866}\n",
      "{'loss': 2.0744, 'grad_norm': 12.579804420471191, 'learning_rate': 4.102936754535432e-06, 'epoch': 0.1794126490929137}\n",
      "{'loss': 1.4636, 'grad_norm': 21.908418655395508, 'learning_rate': 4.097925228024456e-06, 'epoch': 0.18041495439510874}\n",
      "{'loss': 1.432, 'grad_norm': 3.155327320098877, 'learning_rate': 4.092913701513481e-06, 'epoch': 0.1814172596973038}\n",
      "{'loss': 2.3196, 'grad_norm': 6.2378997802734375, 'learning_rate': 4.087902175002506e-06, 'epoch': 0.18241956499949885}\n",
      "{'loss': 1.0155, 'grad_norm': 10.207857131958008, 'learning_rate': 4.082890648491531e-06, 'epoch': 0.1834218703016939}\n",
      "{'loss': 2.2095, 'grad_norm': 19.293283462524414, 'learning_rate': 4.077879121980556e-06, 'epoch': 0.18442417560388893}\n",
      "{'loss': 2.3108, 'grad_norm': 22.162179946899414, 'learning_rate': 4.07286759546958e-06, 'epoch': 0.185426480906084}\n",
      "{'loss': 1.9373, 'grad_norm': 9.170520782470703, 'learning_rate': 4.067856068958605e-06, 'epoch': 0.18642878620827905}\n",
      "{'loss': 3.2602, 'grad_norm': 4.01060152053833, 'learning_rate': 4.06284454244763e-06, 'epoch': 0.1874310915104741}\n",
      "{'loss': 2.7404, 'grad_norm': 9.121905326843262, 'learning_rate': 4.0578330159366545e-06, 'epoch': 0.18843339681266913}\n",
      "{'loss': 2.4698, 'grad_norm': 8.180415153503418, 'learning_rate': 4.05282148942568e-06, 'epoch': 0.18943570211486419}\n",
      "{'loss': 2.242, 'grad_norm': 6.236238956451416, 'learning_rate': 4.047809962914704e-06, 'epoch': 0.19043800741705924}\n",
      "{'loss': 2.0831, 'grad_norm': 5.771040439605713, 'learning_rate': 4.042798436403728e-06, 'epoch': 0.1914403127192543}\n",
      "{'loss': 2.4519, 'grad_norm': 8.086640357971191, 'learning_rate': 4.037786909892754e-06, 'epoch': 0.19244261802144932}\n",
      "{'loss': 1.7713, 'grad_norm': 6.994317054748535, 'learning_rate': 4.032775383381779e-06, 'epoch': 0.19344492332364438}\n",
      "{'loss': 2.4876, 'grad_norm': 7.574676036834717, 'learning_rate': 4.027763856870803e-06, 'epoch': 0.19444722862583944}\n",
      "{'loss': 1.3446, 'grad_norm': 7.600924491882324, 'learning_rate': 4.022752330359828e-06, 'epoch': 0.1954495339280345}\n",
      "{'loss': 1.1584, 'grad_norm': 4.079117298126221, 'learning_rate': 4.017740803848853e-06, 'epoch': 0.19645183923022952}\n",
      "{'loss': 2.6819, 'grad_norm': 31.367700576782227, 'learning_rate': 4.012729277337877e-06, 'epoch': 0.19745414453242457}\n",
      "{'loss': 2.6826, 'grad_norm': 20.959964752197266, 'learning_rate': 4.007717750826902e-06, 'epoch': 0.19845644983461963}\n",
      "{'loss': 2.4159, 'grad_norm': 12.88370418548584, 'learning_rate': 4.002706224315927e-06, 'epoch': 0.19945875513681469}\n",
      "{'loss': 1.937, 'grad_norm': 35.42338562011719, 'learning_rate': 3.997694697804952e-06, 'epoch': 0.20046106043900971}\n",
      "{'loss': 2.9026, 'grad_norm': 18.10356903076172, 'learning_rate': 3.992683171293976e-06, 'epoch': 0.20146336574120477}\n",
      "{'loss': 1.7854, 'grad_norm': 10.639485359191895, 'learning_rate': 3.987671644783001e-06, 'epoch': 0.20246567104339983}\n",
      "{'loss': 1.9976, 'grad_norm': 13.634721755981445, 'learning_rate': 3.982660118272026e-06, 'epoch': 0.20346797634559488}\n",
      "{'loss': 2.0072, 'grad_norm': 11.385987281799316, 'learning_rate': 3.977648591761051e-06, 'epoch': 0.2044702816477899}\n",
      "{'loss': 3.0464, 'grad_norm': 14.786307334899902, 'learning_rate': 3.9726370652500754e-06, 'epoch': 0.20547258694998496}\n",
      "{'loss': 1.5227, 'grad_norm': 6.567281246185303, 'learning_rate': 3.967625538739101e-06, 'epoch': 0.20647489225218002}\n",
      "{'loss': 2.5708, 'grad_norm': 4.3054094314575195, 'learning_rate': 3.962614012228125e-06, 'epoch': 0.20747719755437508}\n",
      "{'loss': 2.5169, 'grad_norm': 7.527522563934326, 'learning_rate': 3.957602485717149e-06, 'epoch': 0.2084795028565701}\n",
      "{'loss': 2.3358, 'grad_norm': 8.15131664276123, 'learning_rate': 3.952590959206175e-06, 'epoch': 0.20948180815876516}\n",
      "{'loss': 2.13, 'grad_norm': 4.221696376800537, 'learning_rate': 3.9475794326952e-06, 'epoch': 0.21048411346096021}\n",
      "{'loss': 1.2265, 'grad_norm': 10.617754936218262, 'learning_rate': 3.942567906184224e-06, 'epoch': 0.21148641876315527}\n",
      "{'loss': 1.4994, 'grad_norm': 3.763019323348999, 'learning_rate': 3.9375563796732485e-06, 'epoch': 0.2124887240653503}\n",
      "{'loss': 2.4383, 'grad_norm': 9.457918167114258, 'learning_rate': 3.932544853162274e-06, 'epoch': 0.21349102936754535}\n",
      "{'loss': 2.504, 'grad_norm': 9.797510147094727, 'learning_rate': 3.927533326651298e-06, 'epoch': 0.2144933346697404}\n",
      "{'loss': 1.5697, 'grad_norm': 11.542476654052734, 'learning_rate': 3.922521800140323e-06, 'epoch': 0.21549563997193547}\n",
      "{'loss': 2.3012, 'grad_norm': 11.543109893798828, 'learning_rate': 3.917510273629348e-06, 'epoch': 0.2164979452741305}\n",
      "{'loss': 2.7383, 'grad_norm': 6.123739719390869, 'learning_rate': 3.912498747118373e-06, 'epoch': 0.21750025057632555}\n",
      "{'loss': 1.7335, 'grad_norm': 2.392939805984497, 'learning_rate': 3.907487220607397e-06, 'epoch': 0.2185025558785206}\n",
      "{'loss': 1.7145, 'grad_norm': 0.0, 'learning_rate': 3.902475694096422e-06, 'epoch': 0.21950486118071563}\n",
      "{'loss': 1.9143, 'grad_norm': 4.593181133270264, 'learning_rate': 3.897464167585447e-06, 'epoch': 0.2205071664829107}\n",
      "{'loss': 1.5493, 'grad_norm': 6.616281509399414, 'learning_rate': 3.892452641074472e-06, 'epoch': 0.22150947178510574}\n",
      "{'loss': 1.7114, 'grad_norm': 10.9638032913208, 'learning_rate': 3.887441114563496e-06, 'epoch': 0.2225117770873008}\n",
      "{'loss': 1.7575, 'grad_norm': 0.2506227493286133, 'learning_rate': 3.882429588052521e-06, 'epoch': 0.22351408238949583}\n",
      "{'loss': 1.8449, 'grad_norm': 1.0949121713638306, 'learning_rate': 3.877418061541546e-06, 'epoch': 0.22451638769169088}\n",
      "{'loss': 2.6732, 'grad_norm': 6.260896682739258, 'learning_rate': 3.87240653503057e-06, 'epoch': 0.22551869299388594}\n",
      "{'loss': 2.3404, 'grad_norm': 7.134249210357666, 'learning_rate': 3.8673950085195955e-06, 'epoch': 0.226520998296081}\n",
      "{'loss': 2.7517, 'grad_norm': 6.03281831741333, 'learning_rate': 3.862383482008621e-06, 'epoch': 0.22752330359827602}\n",
      "{'loss': 2.4896, 'grad_norm': 6.696026802062988, 'learning_rate': 3.857371955497644e-06, 'epoch': 0.22852560890047108}\n",
      "{'loss': 1.3697, 'grad_norm': 6.1637349128723145, 'learning_rate': 3.8523604289866695e-06, 'epoch': 0.22952791420266613}\n",
      "{'loss': 1.2423, 'grad_norm': 7.400132656097412, 'learning_rate': 3.847348902475695e-06, 'epoch': 0.2305302195048612}\n",
      "{'loss': 2.1441, 'grad_norm': 4.965241432189941, 'learning_rate': 3.842337375964719e-06, 'epoch': 0.23153252480705622}\n",
      "{'loss': 2.9744, 'grad_norm': 13.140013694763184, 'learning_rate': 3.837325849453744e-06, 'epoch': 0.23253483010925127}\n",
      "{'loss': 2.0457, 'grad_norm': 4.236713409423828, 'learning_rate': 3.832314322942769e-06, 'epoch': 0.23353713541144633}\n",
      "{'loss': 2.1424, 'grad_norm': 7.090481758117676, 'learning_rate': 3.827302796431793e-06, 'epoch': 0.23453944071364138}\n",
      "{'loss': 1.4722, 'grad_norm': 12.039205551147461, 'learning_rate': 3.822291269920818e-06, 'epoch': 0.2355417460158364}\n",
      "{'loss': 1.5885, 'grad_norm': 7.590853691101074, 'learning_rate': 3.8172797434098426e-06, 'epoch': 0.23654405131803147}\n",
      "{'loss': 2.6379, 'grad_norm': 8.789741516113281, 'learning_rate': 3.8122682168988678e-06, 'epoch': 0.23754635662022652}\n",
      "{'loss': 1.2177, 'grad_norm': 14.216689109802246, 'learning_rate': 3.8072566903878926e-06, 'epoch': 0.23854866192242158}\n",
      "{'loss': 1.6424, 'grad_norm': 9.309500694274902, 'learning_rate': 3.802245163876917e-06, 'epoch': 0.2395509672246166}\n",
      "{'loss': 2.5781, 'grad_norm': 24.29414176940918, 'learning_rate': 3.7972336373659417e-06, 'epoch': 0.24055327252681166}\n",
      "{'loss': 1.7303, 'grad_norm': 5.775805950164795, 'learning_rate': 3.792222110854967e-06, 'epoch': 0.24155557782900672}\n",
      "{'loss': 2.5849, 'grad_norm': 20.33447265625, 'learning_rate': 3.7872105843439917e-06, 'epoch': 0.24255788313120177}\n",
      "{'loss': 1.6431, 'grad_norm': 7.823283672332764, 'learning_rate': 3.7821990578330165e-06, 'epoch': 0.2435601884333968}\n",
      "{'loss': 2.0592, 'grad_norm': 5.968287467956543, 'learning_rate': 3.777187531322041e-06, 'epoch': 0.24456249373559186}\n",
      "{'loss': 1.7927, 'grad_norm': 15.641845703125, 'learning_rate': 3.7721760048110657e-06, 'epoch': 0.2455647990377869}\n",
      "{'loss': 1.9757, 'grad_norm': 0.0, 'learning_rate': 3.7671644783000904e-06, 'epoch': 0.24656710433998197}\n",
      "{'loss': 1.8196, 'grad_norm': 8.137105941772461, 'learning_rate': 3.7621529517891152e-06, 'epoch': 0.247569409642177}\n",
      "{'loss': 2.2181, 'grad_norm': 8.291373252868652, 'learning_rate': 3.75714142527814e-06, 'epoch': 0.24857171494437205}\n",
      "{'loss': 1.426, 'grad_norm': 7.927075386047363, 'learning_rate': 3.7521298987671652e-06, 'epoch': 0.2495740202465671}\n",
      "{'loss': 1.782, 'grad_norm': 12.814922332763672, 'learning_rate': 3.747118372256189e-06, 'epoch': 0.25057632554876214}\n",
      "{'loss': 2.4018, 'grad_norm': 6.907339096069336, 'learning_rate': 3.7421068457452144e-06, 'epoch': 0.2515786308509572}\n",
      "{'loss': 1.8901, 'grad_norm': 3.926466703414917, 'learning_rate': 3.737095319234239e-06, 'epoch': 0.25258093615315225}\n",
      "{'loss': 2.2977, 'grad_norm': 6.241365909576416, 'learning_rate': 3.732083792723264e-06, 'epoch': 0.2535832414553473}\n",
      "{'loss': 1.8084, 'grad_norm': 20.980121612548828, 'learning_rate': 3.7270722662122887e-06, 'epoch': 0.25458554675754236}\n",
      "{'loss': 2.6235, 'grad_norm': 1.8311809301376343, 'learning_rate': 3.722060739701313e-06, 'epoch': 0.2555878520597374}\n",
      "{'loss': 1.3605, 'grad_norm': 3.472391128540039, 'learning_rate': 3.717049213190338e-06, 'epoch': 0.25659015736193247}\n",
      "{'loss': 1.93, 'grad_norm': 10.973196983337402, 'learning_rate': 3.7120376866793627e-06, 'epoch': 0.2575924626641275}\n",
      "{'loss': 1.2137, 'grad_norm': 1.592420220375061, 'learning_rate': 3.707026160168388e-06, 'epoch': 0.2585947679663225}\n",
      "{'loss': 2.4264, 'grad_norm': 44.91559600830078, 'learning_rate': 3.7020146336574127e-06, 'epoch': 0.2595970732685176}\n",
      "{'loss': 2.274, 'grad_norm': 9.506258964538574, 'learning_rate': 3.697003107146437e-06, 'epoch': 0.26059937857071264}\n",
      "{'loss': 1.6296, 'grad_norm': 8.60470962524414, 'learning_rate': 3.691991580635462e-06, 'epoch': 0.26160168387290766}\n",
      "{'loss': 1.8844, 'grad_norm': 8.672391891479492, 'learning_rate': 3.6869800541244866e-06, 'epoch': 0.26260398917510275}\n",
      "{'loss': 1.172, 'grad_norm': 5.906167984008789, 'learning_rate': 3.6819685276135114e-06, 'epoch': 0.2636062944772978}\n",
      "{'loss': 1.7234, 'grad_norm': 7.916903972625732, 'learning_rate': 3.676957001102536e-06, 'epoch': 0.26460859977949286}\n",
      "{'loss': 2.4709, 'grad_norm': 5.251152038574219, 'learning_rate': 3.671945474591561e-06, 'epoch': 0.2656109050816879}\n",
      "{'loss': 1.9035, 'grad_norm': 3.34904408454895, 'learning_rate': 3.6669339480805853e-06, 'epoch': 0.2666132103838829}\n",
      "{'loss': 1.7974, 'grad_norm': 9.902445793151855, 'learning_rate': 3.66192242156961e-06, 'epoch': 0.267615515686078}\n",
      "{'loss': 1.4914, 'grad_norm': 4.4063401222229, 'learning_rate': 3.6569108950586353e-06, 'epoch': 0.268617820988273}\n",
      "{'loss': 1.7147, 'grad_norm': 10.180156707763672, 'learning_rate': 3.65189936854766e-06, 'epoch': 0.26962012629046805}\n",
      "{'loss': 1.8318, 'grad_norm': 18.540586471557617, 'learning_rate': 3.646887842036685e-06, 'epoch': 0.27062243159266314}\n",
      "{'loss': 2.1684, 'grad_norm': 7.515080451965332, 'learning_rate': 3.6418763155257093e-06, 'epoch': 0.27162473689485817}\n",
      "{'loss': 1.737, 'grad_norm': 14.823322296142578, 'learning_rate': 3.636864789014734e-06, 'epoch': 0.27262704219705325}\n",
      "{'loss': 1.4353, 'grad_norm': 10.462237358093262, 'learning_rate': 3.631853262503759e-06, 'epoch': 0.2736293474992483}\n",
      "{'loss': 1.3901, 'grad_norm': 1.8774069547653198, 'learning_rate': 3.6268417359927836e-06, 'epoch': 0.2746316528014433}\n",
      "{'loss': 1.8768, 'grad_norm': 3.1463239192962646, 'learning_rate': 3.6218302094818084e-06, 'epoch': 0.2756339581036384}\n",
      "{'loss': 1.2232, 'grad_norm': 7.472096920013428, 'learning_rate': 3.616818682970833e-06, 'epoch': 0.2766362634058334}\n",
      "{'loss': 1.0367, 'grad_norm': 5.808094024658203, 'learning_rate': 3.611807156459858e-06, 'epoch': 0.27763856870802844}\n",
      "{'loss': 1.2713, 'grad_norm': 9.741880416870117, 'learning_rate': 3.6067956299488828e-06, 'epoch': 0.2786408740102235}\n",
      "{'loss': 1.551, 'grad_norm': 7.412246227264404, 'learning_rate': 3.6017841034379076e-06, 'epoch': 0.27964317931241855}\n",
      "{'loss': 1.9738, 'grad_norm': 5.2405686378479, 'learning_rate': 3.5967725769269324e-06, 'epoch': 0.28064548461461364}\n",
      "{'loss': 2.0531, 'grad_norm': 20.996126174926758, 'learning_rate': 3.591761050415957e-06, 'epoch': 0.28164778991680867}\n",
      "{'loss': 1.6019, 'grad_norm': 3.8711609840393066, 'learning_rate': 3.5867495239049815e-06, 'epoch': 0.2826500952190037}\n",
      "{'loss': 2.1029, 'grad_norm': 5.8804497718811035, 'learning_rate': 3.5817379973940063e-06, 'epoch': 0.2836524005211988}\n",
      "{'loss': 2.2835, 'grad_norm': 10.503222465515137, 'learning_rate': 3.576726470883031e-06, 'epoch': 0.2846547058233938}\n",
      "{'loss': 1.7335, 'grad_norm': 1.9759938716888428, 'learning_rate': 3.5717149443720563e-06, 'epoch': 0.28565701112558883}\n",
      "{'loss': 2.7933, 'grad_norm': 5.640563488006592, 'learning_rate': 3.566703417861081e-06, 'epoch': 0.2866593164277839}\n",
      "{'loss': 1.9239, 'grad_norm': 8.072359085083008, 'learning_rate': 3.5616918913501054e-06, 'epoch': 0.28766162172997894}\n",
      "{'loss': 2.4627, 'grad_norm': 8.023059844970703, 'learning_rate': 3.5566803648391302e-06, 'epoch': 0.288663927032174}\n",
      "{'loss': 1.5057, 'grad_norm': 7.164151191711426, 'learning_rate': 3.551668838328155e-06, 'epoch': 0.28966623233436906}\n",
      "{'loss': 2.7423, 'grad_norm': 7.015140056610107, 'learning_rate': 3.54665731181718e-06, 'epoch': 0.2906685376365641}\n",
      "{'loss': 2.816, 'grad_norm': 0.0, 'learning_rate': 3.5416457853062046e-06, 'epoch': 0.29167084293875917}\n",
      "{'loss': 1.9745, 'grad_norm': 12.278977394104004, 'learning_rate': 3.5366342587952294e-06, 'epoch': 0.2926731482409542}\n",
      "{'loss': 1.8854, 'grad_norm': 5.218825340270996, 'learning_rate': 3.5316227322842537e-06, 'epoch': 0.2936754535431492}\n",
      "{'loss': 0.9725, 'grad_norm': 2.5097830295562744, 'learning_rate': 3.526611205773279e-06, 'epoch': 0.2946777588453443}\n",
      "{'loss': 1.8764, 'grad_norm': 8.828644752502441, 'learning_rate': 3.5215996792623037e-06, 'epoch': 0.29568006414753933}\n",
      "{'loss': 1.4949, 'grad_norm': 3.2656478881835938, 'learning_rate': 3.5165881527513285e-06, 'epoch': 0.29668236944973436}\n",
      "{'loss': 1.8178, 'grad_norm': 3.7712881565093994, 'learning_rate': 3.5115766262403533e-06, 'epoch': 0.29768467475192945}\n",
      "{'loss': 2.3464, 'grad_norm': 9.69976806640625, 'learning_rate': 3.5065650997293777e-06, 'epoch': 0.2986869800541245}\n",
      "{'loss': 1.9255, 'grad_norm': 5.1397929191589355, 'learning_rate': 3.5015535732184025e-06, 'epoch': 0.29968928535631956}\n",
      "{'loss': 1.7744, 'grad_norm': 9.385766983032227, 'learning_rate': 3.4965420467074273e-06, 'epoch': 0.3006915906585146}\n",
      "{'loss': 1.9987, 'grad_norm': 0.5649473667144775, 'learning_rate': 3.491530520196452e-06, 'epoch': 0.3016938959607096}\n",
      "{'loss': 2.2712, 'grad_norm': 5.194311618804932, 'learning_rate': 3.4865189936854773e-06, 'epoch': 0.3026962012629047}\n",
      "{'loss': 1.3605, 'grad_norm': 11.607471466064453, 'learning_rate': 3.481507467174501e-06, 'epoch': 0.3036985065650997}\n",
      "{'loss': 1.0719, 'grad_norm': 5.468879699707031, 'learning_rate': 3.4764959406635264e-06, 'epoch': 0.30470081186729475}\n",
      "{'loss': 1.837, 'grad_norm': 5.372107028961182, 'learning_rate': 3.471484414152551e-06, 'epoch': 0.30570311716948984}\n",
      "{'loss': 1.3859, 'grad_norm': 0.5089457631111145, 'learning_rate': 3.466472887641576e-06, 'epoch': 0.30670542247168486}\n",
      "{'loss': 1.9242, 'grad_norm': 11.060689926147461, 'learning_rate': 3.4614613611306008e-06, 'epoch': 0.30770772777387995}\n",
      "{'loss': 1.4274, 'grad_norm': 7.262386798858643, 'learning_rate': 3.4564498346196256e-06, 'epoch': 0.308710033076075}\n",
      "{'loss': 1.5252, 'grad_norm': 0.47741952538490295, 'learning_rate': 3.45143830810865e-06, 'epoch': 0.30971233837827}\n",
      "{'loss': 1.8627, 'grad_norm': 5.907329559326172, 'learning_rate': 3.4464267815976747e-06, 'epoch': 0.3107146436804651}\n",
      "{'loss': 1.3872, 'grad_norm': 4.024412155151367, 'learning_rate': 3.4414152550867e-06, 'epoch': 0.3117169489826601}\n",
      "{'loss': 2.0944, 'grad_norm': 7.851265907287598, 'learning_rate': 3.4364037285757247e-06, 'epoch': 0.31271925428485514}\n",
      "{'loss': 1.6609, 'grad_norm': 8.81368637084961, 'learning_rate': 3.4313922020647495e-06, 'epoch': 0.3137215595870502}\n",
      "{'loss': 1.1981, 'grad_norm': 9.148292541503906, 'learning_rate': 3.426380675553774e-06, 'epoch': 0.31472386488924525}\n",
      "{'loss': 1.1387, 'grad_norm': 3.391444206237793, 'learning_rate': 3.4213691490427986e-06, 'epoch': 0.31572617019144034}\n",
      "{'loss': 1.1611, 'grad_norm': 0.4374065399169922, 'learning_rate': 3.4163576225318234e-06, 'epoch': 0.31672847549363536}\n",
      "{'loss': 1.9591, 'grad_norm': 11.830954551696777, 'learning_rate': 3.4113460960208482e-06, 'epoch': 0.3177307807958304}\n",
      "{'loss': 1.6431, 'grad_norm': 3.9344191551208496, 'learning_rate': 3.406334569509873e-06, 'epoch': 0.3187330860980255}\n",
      "{'loss': 0.8911, 'grad_norm': 7.595620632171631, 'learning_rate': 3.4013230429988974e-06, 'epoch': 0.3197353914002205}\n",
      "{'loss': 2.1199, 'grad_norm': 7.8945536613464355, 'learning_rate': 3.396311516487922e-06, 'epoch': 0.32073769670241553}\n",
      "{'loss': 1.7749, 'grad_norm': 18.22151756286621, 'learning_rate': 3.3912999899769474e-06, 'epoch': 0.3217400020046106}\n",
      "{'loss': 1.9941, 'grad_norm': 40.18135070800781, 'learning_rate': 3.386288463465972e-06, 'epoch': 0.32274230730680564}\n",
      "{'loss': 1.99, 'grad_norm': 14.707453727722168, 'learning_rate': 3.381276936954997e-06, 'epoch': 0.3237446126090007}\n",
      "{'loss': 2.1553, 'grad_norm': 7.614401340484619, 'learning_rate': 3.3762654104440217e-06, 'epoch': 0.32474691791119575}\n",
      "{'loss': 1.8654, 'grad_norm': 9.623476028442383, 'learning_rate': 3.371253883933046e-06, 'epoch': 0.3257492232133908}\n",
      "{'loss': 2.3159, 'grad_norm': 10.96023941040039, 'learning_rate': 3.366242357422071e-06, 'epoch': 0.32675152851558587}\n",
      "{'loss': 1.3271, 'grad_norm': 14.221332550048828, 'learning_rate': 3.3612308309110957e-06, 'epoch': 0.3277538338177809}\n",
      "{'loss': 2.7302, 'grad_norm': 8.212087631225586, 'learning_rate': 3.356219304400121e-06, 'epoch': 0.3287561391199759}\n",
      "{'loss': 1.7403, 'grad_norm': 8.171420097351074, 'learning_rate': 3.3512077778891457e-06, 'epoch': 0.329758444422171}\n",
      "{'loss': 1.3922, 'grad_norm': 13.125238418579102, 'learning_rate': 3.34619625137817e-06, 'epoch': 0.33076074972436603}\n",
      "{'loss': 0.7264, 'grad_norm': 8.685338020324707, 'learning_rate': 3.341184724867195e-06, 'epoch': 0.3317630550265611}\n",
      "{'loss': 1.4325, 'grad_norm': 8.814292907714844, 'learning_rate': 3.3361731983562196e-06, 'epoch': 0.33276536032875614}\n",
      "{'loss': 1.6094, 'grad_norm': 2.66540789604187, 'learning_rate': 3.3311616718452444e-06, 'epoch': 0.33376766563095117}\n",
      "{'loss': 1.7853, 'grad_norm': 18.917997360229492, 'learning_rate': 3.326150145334269e-06, 'epoch': 0.33476997093314625}\n",
      "{'loss': 1.3469, 'grad_norm': 5.407016754150391, 'learning_rate': 3.3211386188232935e-06, 'epoch': 0.3357722762353413}\n",
      "{'loss': 1.5949, 'grad_norm': 8.541409492492676, 'learning_rate': 3.3161270923123183e-06, 'epoch': 0.3367745815375363}\n",
      "{'loss': 2.2476, 'grad_norm': 7.609997749328613, 'learning_rate': 3.311115565801343e-06, 'epoch': 0.3377768868397314}\n",
      "{'loss': 2.409, 'grad_norm': 2.743882656097412, 'learning_rate': 3.3061040392903683e-06, 'epoch': 0.3387791921419264}\n",
      "{'loss': 1.5394, 'grad_norm': 3.703434944152832, 'learning_rate': 3.301092512779393e-06, 'epoch': 0.3397814974441215}\n",
      "{'loss': 1.0707, 'grad_norm': 11.642237663269043, 'learning_rate': 3.296080986268418e-06, 'epoch': 0.34078380274631653}\n",
      "{'loss': 1.3162, 'grad_norm': 13.86644458770752, 'learning_rate': 3.2910694597574423e-06, 'epoch': 0.34178610804851156}\n",
      "{'loss': 2.2272, 'grad_norm': 16.479341506958008, 'learning_rate': 3.286057933246467e-06, 'epoch': 0.34278841335070664}\n",
      "{'loss': 1.8958, 'grad_norm': 13.129204750061035, 'learning_rate': 3.281046406735492e-06, 'epoch': 0.3437907186529017}\n",
      "{'loss': 1.5723, 'grad_norm': 8.980609893798828, 'learning_rate': 3.2760348802245166e-06, 'epoch': 0.3447930239550967}\n",
      "{'loss': 2.1487, 'grad_norm': 16.75845718383789, 'learning_rate': 3.271023353713542e-06, 'epoch': 0.3457953292572918}\n",
      "{'loss': 0.973, 'grad_norm': 19.17546272277832, 'learning_rate': 3.2660118272025658e-06, 'epoch': 0.3467976345594868}\n",
      "{'loss': 1.393, 'grad_norm': 4.403226375579834, 'learning_rate': 3.261000300691591e-06, 'epoch': 0.3477999398616819}\n",
      "{'loss': 1.4266, 'grad_norm': 7.107981204986572, 'learning_rate': 3.2559887741806158e-06, 'epoch': 0.3488022451638769}\n",
      "{'loss': 0.4507, 'grad_norm': 0.1232927069067955, 'learning_rate': 3.2509772476696406e-06, 'epoch': 0.34980455046607195}\n",
      "{'loss': 1.2916, 'grad_norm': 7.3975934982299805, 'learning_rate': 3.2459657211586653e-06, 'epoch': 0.35080685576826703}\n",
      "{'loss': 1.031, 'grad_norm': 9.664630889892578, 'learning_rate': 3.2409541946476897e-06, 'epoch': 0.35180916107046206}\n",
      "{'loss': 1.5826, 'grad_norm': 6.9479079246521, 'learning_rate': 3.2359426681367145e-06, 'epoch': 0.3528114663726571}\n",
      "{'loss': 1.6691, 'grad_norm': 3.7074668407440186, 'learning_rate': 3.2309311416257393e-06, 'epoch': 0.3538137716748522}\n",
      "{'loss': 1.7404, 'grad_norm': 11.926316261291504, 'learning_rate': 3.225919615114764e-06, 'epoch': 0.3548160769770472}\n",
      "{'loss': 2.1333, 'grad_norm': 6.98488187789917, 'learning_rate': 3.2209080886037893e-06, 'epoch': 0.3558183822792423}\n",
      "{'loss': 2.5445, 'grad_norm': 6.746371269226074, 'learning_rate': 3.215896562092814e-06, 'epoch': 0.3568206875814373}\n",
      "{'loss': 1.4839, 'grad_norm': 7.909026622772217, 'learning_rate': 3.2108850355818384e-06, 'epoch': 0.35782299288363234}\n",
      "{'loss': 1.2499, 'grad_norm': 0.2502442002296448, 'learning_rate': 3.2058735090708632e-06, 'epoch': 0.3588252981858274}\n",
      "{'loss': 1.2824, 'grad_norm': 15.446074485778809, 'learning_rate': 3.200861982559888e-06, 'epoch': 0.35982760348802245}\n",
      "{'loss': 1.2253, 'grad_norm': 13.528642654418945, 'learning_rate': 3.195850456048913e-06, 'epoch': 0.3608299087902175}\n",
      "{'loss': 1.0789, 'grad_norm': 3.410714626312256, 'learning_rate': 3.1908389295379376e-06, 'epoch': 0.36183221409241256}\n",
      "{'loss': 1.9833, 'grad_norm': 7.327469825744629, 'learning_rate': 3.185827403026962e-06, 'epoch': 0.3628345193946076}\n",
      "{'loss': 1.057, 'grad_norm': 8.36470890045166, 'learning_rate': 3.1808158765159867e-06, 'epoch': 0.3638368246968026}\n",
      "{'loss': 1.6752, 'grad_norm': 6.642719745635986, 'learning_rate': 3.175804350005012e-06, 'epoch': 0.3648391299989977}\n",
      "{'loss': 1.9847, 'grad_norm': 4.102529048919678, 'learning_rate': 3.1707928234940367e-06, 'epoch': 0.36584143530119273}\n",
      "{'loss': 1.0149, 'grad_norm': 0.0, 'learning_rate': 3.1657812969830615e-06, 'epoch': 0.3668437406033878}\n",
      "{'loss': 1.1316, 'grad_norm': 11.554162979125977, 'learning_rate': 3.1607697704720863e-06, 'epoch': 0.36784604590558284}\n",
      "{'loss': 1.7507, 'grad_norm': 7.474846363067627, 'learning_rate': 3.1557582439611107e-06, 'epoch': 0.36884835120777787}\n",
      "{'loss': 1.9755, 'grad_norm': 9.82513427734375, 'learning_rate': 3.1507467174501355e-06, 'epoch': 0.36985065650997295}\n",
      "{'loss': 1.5599, 'grad_norm': 17.72060775756836, 'learning_rate': 3.1457351909391602e-06, 'epoch': 0.370852961812168}\n",
      "{'loss': 2.0888, 'grad_norm': 1.9912419319152832, 'learning_rate': 3.140723664428185e-06, 'epoch': 0.371855267114363}\n",
      "{'loss': 1.5436, 'grad_norm': 16.855138778686523, 'learning_rate': 3.1357121379172102e-06, 'epoch': 0.3728575724165581}\n",
      "{'loss': 1.8188, 'grad_norm': 12.604799270629883, 'learning_rate': 3.130700611406234e-06, 'epoch': 0.3738598777187531}\n",
      "{'loss': 1.9923, 'grad_norm': 10.111553192138672, 'learning_rate': 3.1256890848952594e-06, 'epoch': 0.3748621830209482}\n",
      "{'loss': 1.7576, 'grad_norm': 37.483421325683594, 'learning_rate': 3.120677558384284e-06, 'epoch': 0.37586448832314323}\n",
      "{'loss': 1.6879, 'grad_norm': 7.005846977233887, 'learning_rate': 3.115666031873309e-06, 'epoch': 0.37686679362533826}\n",
      "{'loss': 1.9913, 'grad_norm': 2.7854411602020264, 'learning_rate': 3.1106545053623338e-06, 'epoch': 0.37786909892753334}\n",
      "{'loss': 1.2804, 'grad_norm': 12.98696231842041, 'learning_rate': 3.105642978851358e-06, 'epoch': 0.37887140422972837}\n",
      "{'loss': 2.3759, 'grad_norm': 9.64670181274414, 'learning_rate': 3.100631452340383e-06, 'epoch': 0.3798737095319234}\n",
      "{'loss': 1.9825, 'grad_norm': 8.01128101348877, 'learning_rate': 3.0956199258294077e-06, 'epoch': 0.3808760148341185}\n",
      "{'loss': 0.8195, 'grad_norm': 6.665098667144775, 'learning_rate': 3.090608399318433e-06, 'epoch': 0.3818783201363135}\n",
      "{'loss': 1.2047, 'grad_norm': 33.79963302612305, 'learning_rate': 3.0855968728074577e-06, 'epoch': 0.3828806254385086}\n",
      "{'loss': 1.2526, 'grad_norm': 5.167933464050293, 'learning_rate': 3.0805853462964825e-06, 'epoch': 0.3838829307407036}\n",
      "{'loss': 1.6401, 'grad_norm': 3.2829489707946777, 'learning_rate': 3.075573819785507e-06, 'epoch': 0.38488523604289865}\n",
      "{'loss': 1.6602, 'grad_norm': 7.724255084991455, 'learning_rate': 3.0705622932745316e-06, 'epoch': 0.38588754134509373}\n",
      "{'loss': 1.7803, 'grad_norm': 1.6460480690002441, 'learning_rate': 3.0655507667635564e-06, 'epoch': 0.38688984664728876}\n",
      "{'loss': 1.3285, 'grad_norm': 9.196954727172852, 'learning_rate': 3.060539240252581e-06, 'epoch': 0.3878921519494838}\n",
      "{'loss': 1.7481, 'grad_norm': 8.161189079284668, 'learning_rate': 3.055527713741606e-06, 'epoch': 0.38889445725167887}\n",
      "{'loss': 1.6266, 'grad_norm': 8.262350082397461, 'learning_rate': 3.0505161872306304e-06, 'epoch': 0.3898967625538739}\n",
      "{'loss': 2.61, 'grad_norm': 1.7534637451171875, 'learning_rate': 3.045504660719655e-06, 'epoch': 0.390899067856069}\n",
      "{'loss': 1.5732, 'grad_norm': 6.530284404754639, 'learning_rate': 3.0404931342086804e-06, 'epoch': 0.391901373158264}\n",
      "{'loss': 1.949, 'grad_norm': 8.534830093383789, 'learning_rate': 3.035481607697705e-06, 'epoch': 0.39290367846045904}\n",
      "{'loss': 2.0987, 'grad_norm': 0.7286245822906494, 'learning_rate': 3.03047008118673e-06, 'epoch': 0.3939059837626541}\n",
      "{'loss': 0.892, 'grad_norm': 7.766035079956055, 'learning_rate': 3.0254585546757543e-06, 'epoch': 0.39490828906484915}\n",
      "{'loss': 0.9755, 'grad_norm': 39.33848190307617, 'learning_rate': 3.020447028164779e-06, 'epoch': 0.3959105943670442}\n",
      "{'loss': 1.3213, 'grad_norm': 8.221570014953613, 'learning_rate': 3.015435501653804e-06, 'epoch': 0.39691289966923926}\n",
      "{'loss': 1.2187, 'grad_norm': 3.732058525085449, 'learning_rate': 3.0104239751428287e-06, 'epoch': 0.3979152049714343}\n",
      "{'loss': 1.4049, 'grad_norm': 7.931021213531494, 'learning_rate': 3.005412448631854e-06, 'epoch': 0.39891751027362937}\n",
      "{'loss': 2.1568, 'grad_norm': 10.240095138549805, 'learning_rate': 3.0004009221208787e-06, 'epoch': 0.3999198155758244}\n",
      "{'loss': 1.3232, 'grad_norm': 9.408164978027344, 'learning_rate': 2.995389395609903e-06, 'epoch': 0.40092212087801943}\n",
      "{'loss': 1.2591, 'grad_norm': 47.053123474121094, 'learning_rate': 2.990377869098928e-06, 'epoch': 0.4019244261802145}\n",
      "{'loss': 1.4736, 'grad_norm': 1.6335729360580444, 'learning_rate': 2.9853663425879526e-06, 'epoch': 0.40292673148240954}\n",
      "{'loss': 1.7513, 'grad_norm': 9.853909492492676, 'learning_rate': 2.9803548160769774e-06, 'epoch': 0.40392903678460457}\n",
      "{'loss': 1.8512, 'grad_norm': 0.7957574725151062, 'learning_rate': 2.975343289566002e-06, 'epoch': 0.40493134208679965}\n",
      "{'loss': 1.3234, 'grad_norm': 9.755047798156738, 'learning_rate': 2.9703317630550265e-06, 'epoch': 0.4059336473889947}\n",
      "{'loss': 2.0453, 'grad_norm': 57.047523498535156, 'learning_rate': 2.9653202365440513e-06, 'epoch': 0.40693595269118976}\n",
      "{'loss': 1.4795, 'grad_norm': 11.33423900604248, 'learning_rate': 2.960308710033076e-06, 'epoch': 0.4079382579933848}\n",
      "{'loss': 1.4865, 'grad_norm': 6.607468605041504, 'learning_rate': 2.9552971835221013e-06, 'epoch': 0.4089405632955798}\n",
      "{'loss': 1.7052, 'grad_norm': 16.620759963989258, 'learning_rate': 2.950285657011126e-06, 'epoch': 0.4099428685977749}\n",
      "{'loss': 1.6338, 'grad_norm': 3.411951780319214, 'learning_rate': 2.9452741305001505e-06, 'epoch': 0.41094517389996993}\n",
      "{'loss': 2.2442, 'grad_norm': 19.996896743774414, 'learning_rate': 2.9402626039891753e-06, 'epoch': 0.41194747920216496}\n",
      "{'loss': 2.0758, 'grad_norm': 12.530281066894531, 'learning_rate': 2.9352510774782e-06, 'epoch': 0.41294978450436004}\n",
      "{'loss': 2.2476, 'grad_norm': 12.90124225616455, 'learning_rate': 2.930239550967225e-06, 'epoch': 0.41395208980655507}\n",
      "{'loss': 1.598, 'grad_norm': 15.535016059875488, 'learning_rate': 2.9252280244562496e-06, 'epoch': 0.41495439510875015}\n",
      "{'loss': 1.8642, 'grad_norm': 27.161970138549805, 'learning_rate': 2.920216497945275e-06, 'epoch': 0.4159567004109452}\n",
      "{'loss': 1.8042, 'grad_norm': 11.796119689941406, 'learning_rate': 2.9152049714342988e-06, 'epoch': 0.4169590057131402}\n",
      "{'loss': 1.1444, 'grad_norm': 4.496089935302734, 'learning_rate': 2.910193444923324e-06, 'epoch': 0.4179613110153353}\n",
      "{'loss': 1.6301, 'grad_norm': 0.0, 'learning_rate': 2.9051819184123488e-06, 'epoch': 0.4189636163175303}\n",
      "{'loss': 1.97, 'grad_norm': 7.639516353607178, 'learning_rate': 2.9001703919013735e-06, 'epoch': 0.41996592161972535}\n",
      "{'loss': 1.3668, 'grad_norm': 3.088253974914551, 'learning_rate': 2.8951588653903983e-06, 'epoch': 0.42096822692192043}\n",
      "{'loss': 1.952, 'grad_norm': 7.686131000518799, 'learning_rate': 2.8901473388794227e-06, 'epoch': 0.42197053222411546}\n",
      "{'loss': 1.8341, 'grad_norm': 9.889138221740723, 'learning_rate': 2.8851358123684475e-06, 'epoch': 0.42297283752631054}\n",
      "{'loss': 1.7466, 'grad_norm': 24.167360305786133, 'learning_rate': 2.8801242858574723e-06, 'epoch': 0.42397514282850557}\n",
      "{'loss': 1.5257, 'grad_norm': 25.689502716064453, 'learning_rate': 2.875112759346497e-06, 'epoch': 0.4249774481307006}\n",
      "{'loss': 1.637, 'grad_norm': 4.5862932205200195, 'learning_rate': 2.8701012328355223e-06, 'epoch': 0.4259797534328957}\n",
      "{'loss': 1.6415, 'grad_norm': 14.838136672973633, 'learning_rate': 2.8650897063245462e-06, 'epoch': 0.4269820587350907}\n",
      "{'loss': 2.5204, 'grad_norm': 17.021408081054688, 'learning_rate': 2.8600781798135714e-06, 'epoch': 0.42798436403728574}\n",
      "{'loss': 1.5526, 'grad_norm': 6.600634574890137, 'learning_rate': 2.855066653302596e-06, 'epoch': 0.4289866693394808}\n",
      "{'loss': 1.3339, 'grad_norm': 6.2417426109313965, 'learning_rate': 2.850055126791621e-06, 'epoch': 0.42998897464167585}\n",
      "{'loss': 1.191, 'grad_norm': 1.5564428567886353, 'learning_rate': 2.8450436002806458e-06, 'epoch': 0.43099127994387093}\n",
      "{'loss': 2.4659, 'grad_norm': 7.832552909851074, 'learning_rate': 2.8400320737696706e-06, 'epoch': 0.43199358524606596}\n",
      "{'loss': 1.3621, 'grad_norm': 19.529577255249023, 'learning_rate': 2.835020547258695e-06, 'epoch': 0.432995890548261}\n",
      "{'loss': 1.2798, 'grad_norm': 14.69758415222168, 'learning_rate': 2.8300090207477197e-06, 'epoch': 0.43399819585045607}\n",
      "{'loss': 2.0743, 'grad_norm': 7.747799396514893, 'learning_rate': 2.824997494236745e-06, 'epoch': 0.4350005011526511}\n",
      "{'loss': 2.0735, 'grad_norm': 17.901840209960938, 'learning_rate': 2.8199859677257697e-06, 'epoch': 0.4360028064548461}\n",
      "{'loss': 2.2859, 'grad_norm': 11.789016723632812, 'learning_rate': 2.8149744412147945e-06, 'epoch': 0.4370051117570412}\n",
      "{'loss': 2.4412, 'grad_norm': 13.704914093017578, 'learning_rate': 2.809962914703819e-06, 'epoch': 0.43800741705923624}\n",
      "{'loss': 1.6033, 'grad_norm': 13.369224548339844, 'learning_rate': 2.8049513881928437e-06, 'epoch': 0.43900972236143126}\n",
      "{'loss': 1.5242, 'grad_norm': 6.163711071014404, 'learning_rate': 2.7999398616818684e-06, 'epoch': 0.44001202766362635}\n",
      "{'loss': 1.8656, 'grad_norm': 5.700070858001709, 'learning_rate': 2.7949283351708932e-06, 'epoch': 0.4410143329658214}\n",
      "{'loss': 1.4813, 'grad_norm': 7.875725746154785, 'learning_rate': 2.789916808659918e-06, 'epoch': 0.44201663826801646}\n",
      "{'loss': 2.2928, 'grad_norm': 10.576711654663086, 'learning_rate': 2.7849052821489432e-06, 'epoch': 0.4430189435702115}\n",
      "{'loss': 2.1638, 'grad_norm': 10.335260391235352, 'learning_rate': 2.779893755637967e-06, 'epoch': 0.4440212488724065}\n",
      "{'loss': 1.0497, 'grad_norm': 4.418088436126709, 'learning_rate': 2.7748822291269924e-06, 'epoch': 0.4450235541746016}\n",
      "{'loss': 1.8472, 'grad_norm': 8.669349670410156, 'learning_rate': 2.769870702616017e-06, 'epoch': 0.4460258594767966}\n",
      "{'loss': 1.5051, 'grad_norm': 5.2120137214660645, 'learning_rate': 2.764859176105042e-06, 'epoch': 0.44702816477899165}\n",
      "{'loss': 1.6853, 'grad_norm': 4.951160430908203, 'learning_rate': 2.7598476495940667e-06, 'epoch': 0.44803047008118674}\n",
      "{'loss': 1.2901, 'grad_norm': 9.027165412902832, 'learning_rate': 2.754836123083091e-06, 'epoch': 0.44903277538338177}\n",
      "{'loss': 1.322, 'grad_norm': 4.592994213104248, 'learning_rate': 2.749824596572116e-06, 'epoch': 0.45003508068557685}\n",
      "{'loss': 1.8571, 'grad_norm': 8.792885780334473, 'learning_rate': 2.7448130700611407e-06, 'epoch': 0.4510373859877719}\n",
      "{'loss': 1.2484, 'grad_norm': 6.8391547203063965, 'learning_rate': 2.739801543550166e-06, 'epoch': 0.4520396912899669}\n",
      "{'loss': 1.6042, 'grad_norm': 5.250680446624756, 'learning_rate': 2.7347900170391907e-06, 'epoch': 0.453041996592162}\n",
      "{'loss': 1.1984, 'grad_norm': 6.313566207885742, 'learning_rate': 2.729778490528215e-06, 'epoch': 0.454044301894357}\n",
      "{'loss': 0.7026, 'grad_norm': 6.656607627868652, 'learning_rate': 2.72476696401724e-06, 'epoch': 0.45504660719655204}\n",
      "{'loss': 1.5012, 'grad_norm': 6.102799415588379, 'learning_rate': 2.7197554375062646e-06, 'epoch': 0.4560489124987471}\n",
      "{'loss': 0.7126, 'grad_norm': 0.6613636016845703, 'learning_rate': 2.7147439109952894e-06, 'epoch': 0.45705121780094216}\n",
      "{'loss': 1.2609, 'grad_norm': 7.1339592933654785, 'learning_rate': 2.709732384484314e-06, 'epoch': 0.45805352310313724}\n",
      "{'loss': 1.6049, 'grad_norm': 5.628255844116211, 'learning_rate': 2.704720857973339e-06, 'epoch': 0.45905582840533227}\n",
      "{'loss': 1.6632, 'grad_norm': 30.36144256591797, 'learning_rate': 2.6997093314623633e-06, 'epoch': 0.4600581337075273}\n",
      "{'loss': 1.7935, 'grad_norm': 10.268171310424805, 'learning_rate': 2.694697804951388e-06, 'epoch': 0.4610604390097224}\n",
      "{'loss': 2.286, 'grad_norm': 9.826542854309082, 'learning_rate': 2.6896862784404133e-06, 'epoch': 0.4620627443119174}\n",
      "{'loss': 2.0507, 'grad_norm': 4.775933742523193, 'learning_rate': 2.684674751929438e-06, 'epoch': 0.46306504961411243}\n",
      "{'loss': 2.0331, 'grad_norm': 15.547306060791016, 'learning_rate': 2.679663225418463e-06, 'epoch': 0.4640673549163075}\n",
      "{'loss': 1.5527, 'grad_norm': 24.313692092895508, 'learning_rate': 2.6746516989074873e-06, 'epoch': 0.46506966021850255}\n",
      "{'loss': 1.8112, 'grad_norm': 8.572981834411621, 'learning_rate': 2.669640172396512e-06, 'epoch': 0.46607196552069763}\n",
      "{'loss': 2.0031, 'grad_norm': 7.29034948348999, 'learning_rate': 2.664628645885537e-06, 'epoch': 0.46707427082289266}\n",
      "{'loss': 1.552, 'grad_norm': 0.0, 'learning_rate': 2.6596171193745616e-06, 'epoch': 0.4680765761250877}\n",
      "{'loss': 1.6343, 'grad_norm': 8.117766380310059, 'learning_rate': 2.654605592863587e-06, 'epoch': 0.46907888142728277}\n",
      "{'loss': 0.8505, 'grad_norm': 0.1909792125225067, 'learning_rate': 2.649594066352611e-06, 'epoch': 0.4700811867294778}\n",
      "{'loss': 2.0066, 'grad_norm': 10.804023742675781, 'learning_rate': 2.644582539841636e-06, 'epoch': 0.4710834920316728}\n",
      "{'loss': 2.1845, 'grad_norm': 0.0, 'learning_rate': 2.639571013330661e-06, 'epoch': 0.4720857973338679}\n",
      "{'loss': 2.205, 'grad_norm': 13.78184986114502, 'learning_rate': 2.6345594868196856e-06, 'epoch': 0.47308810263606293}\n",
      "{'loss': 0.7804, 'grad_norm': 13.258602142333984, 'learning_rate': 2.6295479603087104e-06, 'epoch': 0.474090407938258}\n",
      "{'loss': 1.8743, 'grad_norm': 12.047530174255371, 'learning_rate': 2.624536433797735e-06, 'epoch': 0.47509271324045305}\n",
      "{'loss': 0.7583, 'grad_norm': 11.061129570007324, 'learning_rate': 2.6195249072867595e-06, 'epoch': 0.4760950185426481}\n",
      "{'loss': 1.4355, 'grad_norm': 9.431151390075684, 'learning_rate': 2.6145133807757843e-06, 'epoch': 0.47709732384484316}\n",
      "{'loss': 1.5137, 'grad_norm': 14.524452209472656, 'learning_rate': 2.609501854264809e-06, 'epoch': 0.4780996291470382}\n",
      "{'loss': 1.1111, 'grad_norm': 6.949922561645508, 'learning_rate': 2.6044903277538343e-06, 'epoch': 0.4791019344492332}\n",
      "{'loss': 1.6509, 'grad_norm': 6.807340145111084, 'learning_rate': 2.599478801242859e-06, 'epoch': 0.4801042397514283}\n",
      "{'loss': 1.1287, 'grad_norm': 8.010376930236816, 'learning_rate': 2.5944672747318835e-06, 'epoch': 0.4811065450536233}\n",
      "{'loss': 1.6489, 'grad_norm': 5.063529014587402, 'learning_rate': 2.5894557482209082e-06, 'epoch': 0.4821088503558184}\n",
      "{'loss': 0.7546, 'grad_norm': 10.14991283416748, 'learning_rate': 2.584444221709933e-06, 'epoch': 0.48311115565801344}\n",
      "{'loss': 2.4877, 'grad_norm': 0.6122000217437744, 'learning_rate': 2.579432695198958e-06, 'epoch': 0.48411346096020846}\n",
      "{'loss': 1.6298, 'grad_norm': 9.590374946594238, 'learning_rate': 2.5744211686879826e-06, 'epoch': 0.48511576626240355}\n",
      "{'loss': 0.9752, 'grad_norm': 17.17610740661621, 'learning_rate': 2.569409642177007e-06, 'epoch': 0.4861180715645986}\n",
      "{'loss': 2.2827, 'grad_norm': 8.837117195129395, 'learning_rate': 2.5643981156660318e-06, 'epoch': 0.4871203768667936}\n",
      "{'loss': 1.7378, 'grad_norm': 4.012534141540527, 'learning_rate': 2.559386589155057e-06, 'epoch': 0.4881226821689887}\n",
      "{'loss': 1.454, 'grad_norm': 6.113384246826172, 'learning_rate': 2.5543750626440818e-06, 'epoch': 0.4891249874711837}\n",
      "{'loss': 2.1609, 'grad_norm': 5.505107879638672, 'learning_rate': 2.5493635361331065e-06, 'epoch': 0.4901272927733788}\n",
      "{'loss': 2.1535, 'grad_norm': 10.072300910949707, 'learning_rate': 2.5443520096221313e-06, 'epoch': 0.4911295980755738}\n",
      "{'loss': 1.8122, 'grad_norm': 8.936695098876953, 'learning_rate': 2.5393404831111557e-06, 'epoch': 0.49213190337776885}\n",
      "{'loss': 1.522, 'grad_norm': 5.922140598297119, 'learning_rate': 2.5343289566001805e-06, 'epoch': 0.49313420867996394}\n",
      "{'loss': 1.2379, 'grad_norm': 10.410959243774414, 'learning_rate': 2.5293174300892053e-06, 'epoch': 0.49413651398215896}\n",
      "{'loss': 2.5916, 'grad_norm': 0.0, 'learning_rate': 2.52430590357823e-06, 'epoch': 0.495138819284354}\n",
      "{'loss': 2.3477, 'grad_norm': 19.517208099365234, 'learning_rate': 2.5192943770672553e-06, 'epoch': 0.4961411245865491}\n",
      "{'loss': 1.1067, 'grad_norm': 15.055156707763672, 'learning_rate': 2.514282850556279e-06, 'epoch': 0.4971434298887441}\n",
      "{'loss': 1.5642, 'grad_norm': 7.693513870239258, 'learning_rate': 2.5092713240453044e-06, 'epoch': 0.4981457351909392}\n",
      "{'loss': 0.6335, 'grad_norm': 1.5477434396743774, 'learning_rate': 2.504259797534329e-06, 'epoch': 0.4991480404931342}\n",
      "{'loss': 1.239, 'grad_norm': 0.37392953038215637, 'learning_rate': 2.499248271023354e-06, 'epoch': 0.5001503457953292}\n",
      "{'loss': 1.9456, 'grad_norm': 5.289161205291748, 'learning_rate': 2.4942367445123788e-06, 'epoch': 0.5011526510975243}\n",
      "{'loss': 0.8091, 'grad_norm': 8.338144302368164, 'learning_rate': 2.4892252180014036e-06, 'epoch': 0.5021549563997194}\n",
      "{'loss': 1.8391, 'grad_norm': 23.289207458496094, 'learning_rate': 2.4842136914904283e-06, 'epoch': 0.5031572617019144}\n",
      "{'loss': 1.6614, 'grad_norm': 7.89202356338501, 'learning_rate': 2.4792021649794527e-06, 'epoch': 0.5041595670041095}\n",
      "{'loss': 1.9889, 'grad_norm': 13.290825843811035, 'learning_rate': 2.474190638468478e-06, 'epoch': 0.5051618723063045}\n",
      "{'loss': 1.6716, 'grad_norm': 0.3871161639690399, 'learning_rate': 2.4691791119575027e-06, 'epoch': 0.5061641776084995}\n",
      "{'loss': 2.201, 'grad_norm': 12.698552131652832, 'learning_rate': 2.464167585446527e-06, 'epoch': 0.5071664829106945}\n",
      "{'loss': 1.8162, 'grad_norm': 9.550243377685547, 'learning_rate': 2.459156058935552e-06, 'epoch': 0.5081687882128897}\n",
      "{'loss': 1.6045, 'grad_norm': 9.83203125, 'learning_rate': 2.4541445324245766e-06, 'epoch': 0.5091710935150847}\n",
      "{'loss': 1.2163, 'grad_norm': 0.3538095951080322, 'learning_rate': 2.4491330059136014e-06, 'epoch': 0.5101733988172797}\n",
      "{'loss': 1.3625, 'grad_norm': 8.3744535446167, 'learning_rate': 2.4441214794026262e-06, 'epoch': 0.5111757041194748}\n",
      "{'loss': 2.6561, 'grad_norm': 6.4272332191467285, 'learning_rate': 2.439109952891651e-06, 'epoch': 0.5121780094216698}\n",
      "{'loss': 1.0782, 'grad_norm': 0.40627115964889526, 'learning_rate': 2.434098426380676e-06, 'epoch': 0.5131803147238649}\n",
      "{'loss': 1.3412, 'grad_norm': 9.779104232788086, 'learning_rate': 2.4290868998697006e-06, 'epoch': 0.51418262002606}\n",
      "{'loss': 1.0603, 'grad_norm': 11.654369354248047, 'learning_rate': 2.4240753733587254e-06, 'epoch': 0.515184925328255}\n",
      "{'loss': 1.8848, 'grad_norm': 5.820672988891602, 'learning_rate': 2.41906384684775e-06, 'epoch': 0.51618723063045}\n",
      "{'loss': 1.0915, 'grad_norm': 8.171821594238281, 'learning_rate': 2.4140523203367745e-06, 'epoch': 0.517189535932645}\n",
      "{'loss': 2.5107, 'grad_norm': 7.942185401916504, 'learning_rate': 2.4090407938257997e-06, 'epoch': 0.5181918412348401}\n",
      "{'loss': 1.5519, 'grad_norm': 5.638369083404541, 'learning_rate': 2.4040292673148245e-06, 'epoch': 0.5191941465370352}\n",
      "{'loss': 1.0997, 'grad_norm': 0.09007705003023148, 'learning_rate': 2.399017740803849e-06, 'epoch': 0.5201964518392302}\n",
      "{'loss': 1.6587, 'grad_norm': 6.4012861251831055, 'learning_rate': 2.3940062142928737e-06, 'epoch': 0.5211987571414253}\n",
      "{'loss': 1.1955, 'grad_norm': 10.869268417358398, 'learning_rate': 2.388994687781899e-06, 'epoch': 0.5222010624436203}\n",
      "{'loss': 1.6835, 'grad_norm': 19.480012893676758, 'learning_rate': 2.3839831612709232e-06, 'epoch': 0.5232033677458153}\n",
      "{'loss': 1.2226, 'grad_norm': 70.2323989868164, 'learning_rate': 2.378971634759948e-06, 'epoch': 0.5242056730480105}\n",
      "{'loss': 1.8242, 'grad_norm': 18.83466148376465, 'learning_rate': 2.373960108248973e-06, 'epoch': 0.5252079783502055}\n",
      "{'loss': 1.4591, 'grad_norm': 4.00622034072876, 'learning_rate': 2.3689485817379976e-06, 'epoch': 0.5262102836524005}\n",
      "{'loss': 1.6875, 'grad_norm': 1.0155165195465088, 'learning_rate': 2.3639370552270224e-06, 'epoch': 0.5272125889545956}\n",
      "{'loss': 1.4147, 'grad_norm': 7.435431480407715, 'learning_rate': 2.358925528716047e-06, 'epoch': 0.5282148942567906}\n",
      "{'loss': 1.6405, 'grad_norm': 18.959749221801758, 'learning_rate': 2.353914002205072e-06, 'epoch': 0.5292171995589857}\n",
      "{'loss': 1.1326, 'grad_norm': 9.635009765625, 'learning_rate': 2.3489024756940968e-06, 'epoch': 0.5302195048611807}\n",
      "{'loss': 1.3029, 'grad_norm': 17.808345794677734, 'learning_rate': 2.343890949183121e-06, 'epoch': 0.5312218101633758}\n",
      "{'loss': 1.924, 'grad_norm': 7.968717575073242, 'learning_rate': 2.3388794226721463e-06, 'epoch': 0.5322241154655708}\n",
      "{'loss': 1.0344, 'grad_norm': 3.728144884109497, 'learning_rate': 2.3338678961611707e-06, 'epoch': 0.5332264207677658}\n",
      "{'loss': 2.4464, 'grad_norm': 15.164972305297852, 'learning_rate': 2.3288563696501955e-06, 'epoch': 0.5342287260699609}\n",
      "{'loss': 1.5261, 'grad_norm': 5.389977931976318, 'learning_rate': 2.3238448431392207e-06, 'epoch': 0.535231031372156}\n",
      "{'loss': 2.0842, 'grad_norm': 12.234175682067871, 'learning_rate': 2.318833316628245e-06, 'epoch': 0.536233336674351}\n",
      "{'loss': 1.3581, 'grad_norm': 13.890986442565918, 'learning_rate': 2.31382179011727e-06, 'epoch': 0.537235641976546}\n",
      "{'loss': 1.5049, 'grad_norm': 19.408824920654297, 'learning_rate': 2.3088102636062946e-06, 'epoch': 0.5382379472787411}\n",
      "{'loss': 2.4446, 'grad_norm': 7.458432197570801, 'learning_rate': 2.3037987370953194e-06, 'epoch': 0.5392402525809361}\n",
      "{'loss': 2.1918, 'grad_norm': 6.925503730773926, 'learning_rate': 2.298787210584344e-06, 'epoch': 0.5402425578831312}\n",
      "{'loss': 2.1814, 'grad_norm': 11.7604398727417, 'learning_rate': 2.293775684073369e-06, 'epoch': 0.5412448631853263}\n",
      "{'loss': 1.8681, 'grad_norm': 19.466440200805664, 'learning_rate': 2.2887641575623938e-06, 'epoch': 0.5422471684875213}\n",
      "{'loss': 1.4925, 'grad_norm': 9.667399406433105, 'learning_rate': 2.2837526310514186e-06, 'epoch': 0.5432494737897163}\n",
      "{'loss': 2.2958, 'grad_norm': 19.75899887084961, 'learning_rate': 2.278741104540443e-06, 'epoch': 0.5442517790919114}\n",
      "{'loss': 1.4859, 'grad_norm': 8.997065544128418, 'learning_rate': 2.273729578029468e-06, 'epoch': 0.5452540843941065}\n",
      "{'loss': 2.4787, 'grad_norm': 9.489380836486816, 'learning_rate': 2.268718051518493e-06, 'epoch': 0.5462563896963015}\n",
      "{'loss': 1.7439, 'grad_norm': 9.124305725097656, 'learning_rate': 2.2637065250075173e-06, 'epoch': 0.5472586949984966}\n",
      "{'loss': 2.5779, 'grad_norm': 5.05840539932251, 'learning_rate': 2.258694998496542e-06, 'epoch': 0.5482610003006916}\n",
      "{'loss': 1.8475, 'grad_norm': 11.533970832824707, 'learning_rate': 2.253683471985567e-06, 'epoch': 0.5492633056028866}\n",
      "{'loss': 1.936, 'grad_norm': 7.62290096282959, 'learning_rate': 2.2486719454745917e-06, 'epoch': 0.5502656109050816}\n",
      "{'loss': 1.76, 'grad_norm': 13.758661270141602, 'learning_rate': 2.2436604189636164e-06, 'epoch': 0.5512679162072768}\n",
      "{'loss': 2.5517, 'grad_norm': 0.6568005681037903, 'learning_rate': 2.2386488924526412e-06, 'epoch': 0.5522702215094718}\n",
      "{'loss': 1.9353, 'grad_norm': 38.8248291015625, 'learning_rate': 2.233637365941666e-06, 'epoch': 0.5532725268116668}\n",
      "{'loss': 0.9247, 'grad_norm': 21.959081649780273, 'learning_rate': 2.228625839430691e-06, 'epoch': 0.5542748321138619}\n",
      "{'loss': 1.7787, 'grad_norm': 9.451567649841309, 'learning_rate': 2.2236143129197156e-06, 'epoch': 0.5552771374160569}\n",
      "{'loss': 1.4889, 'grad_norm': 9.841268539428711, 'learning_rate': 2.2186027864087404e-06, 'epoch': 0.556279442718252}\n",
      "{'loss': 1.7766, 'grad_norm': 8.23192310333252, 'learning_rate': 2.2135912598977647e-06, 'epoch': 0.557281748020447}\n",
      "{'loss': 1.6542, 'grad_norm': 24.207117080688477, 'learning_rate': 2.20857973338679e-06, 'epoch': 0.5582840533226421}\n",
      "{'loss': 1.4615, 'grad_norm': 7.92793607711792, 'learning_rate': 2.2035682068758147e-06, 'epoch': 0.5592863586248371}\n",
      "{'loss': 1.1396, 'grad_norm': 42.28360366821289, 'learning_rate': 2.198556680364839e-06, 'epoch': 0.5602886639270321}\n",
      "{'loss': 1.6453, 'grad_norm': 5.714633941650391, 'learning_rate': 2.193545153853864e-06, 'epoch': 0.5612909692292273}\n",
      "{'loss': 0.1952, 'grad_norm': 3.5257890224456787, 'learning_rate': 2.188533627342889e-06, 'epoch': 0.5622932745314223}\n",
      "{'loss': 0.9744, 'grad_norm': 11.458455085754395, 'learning_rate': 2.1835221008319135e-06, 'epoch': 0.5632955798336173}\n",
      "{'loss': 1.1883, 'grad_norm': 0.6615472435951233, 'learning_rate': 2.1785105743209383e-06, 'epoch': 0.5642978851358124}\n",
      "{'loss': 2.1958, 'grad_norm': 9.504082679748535, 'learning_rate': 2.173499047809963e-06, 'epoch': 0.5653001904380074}\n",
      "{'loss': 1.9152, 'grad_norm': 26.874855041503906, 'learning_rate': 2.168487521298988e-06, 'epoch': 0.5663024957402024}\n",
      "{'loss': 1.5645, 'grad_norm': 8.215973854064941, 'learning_rate': 2.1634759947880126e-06, 'epoch': 0.5673048010423976}\n",
      "{'loss': 1.6289, 'grad_norm': 12.887492179870605, 'learning_rate': 2.1584644682770374e-06, 'epoch': 0.5683071063445926}\n",
      "{'loss': 2.235, 'grad_norm': 5.407214164733887, 'learning_rate': 2.153452941766062e-06, 'epoch': 0.5693094116467876}\n",
      "{'loss': 1.6272, 'grad_norm': 10.192254066467285, 'learning_rate': 2.148441415255087e-06, 'epoch': 0.5703117169489826}\n",
      "{'loss': 1.6235, 'grad_norm': 13.28023624420166, 'learning_rate': 2.1434298887441118e-06, 'epoch': 0.5713140222511777}\n",
      "{'loss': 2.1784, 'grad_norm': 5.495586395263672, 'learning_rate': 2.1384183622331365e-06, 'epoch': 0.5723163275533728}\n",
      "{'loss': 1.4349, 'grad_norm': 23.08467674255371, 'learning_rate': 2.133406835722161e-06, 'epoch': 0.5733186328555678}\n",
      "{'loss': 1.3231, 'grad_norm': 6.215418815612793, 'learning_rate': 2.1283953092111857e-06, 'epoch': 0.5743209381577629}\n",
      "{'loss': 2.2726, 'grad_norm': 9.143715858459473, 'learning_rate': 2.123383782700211e-06, 'epoch': 0.5753232434599579}\n",
      "{'loss': 1.7648, 'grad_norm': 2.145514965057373, 'learning_rate': 2.1183722561892353e-06, 'epoch': 0.5763255487621529}\n",
      "{'loss': 1.5455, 'grad_norm': 15.04769229888916, 'learning_rate': 2.11336072967826e-06, 'epoch': 0.577327854064348}\n",
      "{'loss': 1.8771, 'grad_norm': 11.051538467407227, 'learning_rate': 2.108349203167285e-06, 'epoch': 0.5783301593665431}\n",
      "{'loss': 1.6737, 'grad_norm': 0.30609455704689026, 'learning_rate': 2.1033376766563096e-06, 'epoch': 0.5793324646687381}\n",
      "{'loss': 1.313, 'grad_norm': 14.392990112304688, 'learning_rate': 2.0983261501453344e-06, 'epoch': 0.5803347699709331}\n",
      "{'loss': 0.7743, 'grad_norm': 5.796448707580566, 'learning_rate': 2.093314623634359e-06, 'epoch': 0.5813370752731282}\n",
      "{'loss': 1.3298, 'grad_norm': 7.078169345855713, 'learning_rate': 2.088303097123384e-06, 'epoch': 0.5823393805753232}\n",
      "{'loss': 1.5536, 'grad_norm': 8.25320816040039, 'learning_rate': 2.0832915706124088e-06, 'epoch': 0.5833416858775183}\n",
      "{'loss': 1.5631, 'grad_norm': 0.0, 'learning_rate': 2.078280044101433e-06, 'epoch': 0.5843439911797134}\n",
      "{'loss': 1.7493, 'grad_norm': 13.829070091247559, 'learning_rate': 2.0732685175904584e-06, 'epoch': 0.5853462964819084}\n",
      "{'loss': 1.7747, 'grad_norm': 8.903553009033203, 'learning_rate': 2.068256991079483e-06, 'epoch': 0.5863486017841034}\n",
      "{'loss': 1.1072, 'grad_norm': 14.573490142822266, 'learning_rate': 2.0632454645685075e-06, 'epoch': 0.5873509070862984}\n",
      "{'loss': 0.6943, 'grad_norm': 4.228479385375977, 'learning_rate': 2.0582339380575327e-06, 'epoch': 0.5883532123884936}\n",
      "{'loss': 2.1019, 'grad_norm': 0.0, 'learning_rate': 2.0532224115465575e-06, 'epoch': 0.5893555176906886}\n",
      "{'loss': 0.5641, 'grad_norm': 11.996871948242188, 'learning_rate': 2.048210885035582e-06, 'epoch': 0.5903578229928836}\n",
      "{'loss': 2.4106, 'grad_norm': 11.438694953918457, 'learning_rate': 2.0431993585246067e-06, 'epoch': 0.5913601282950787}\n",
      "{'loss': 1.4305, 'grad_norm': 3.5625529289245605, 'learning_rate': 2.0381878320136314e-06, 'epoch': 0.5923624335972737}\n",
      "{'loss': 2.9934, 'grad_norm': 6.1491498947143555, 'learning_rate': 2.0331763055026562e-06, 'epoch': 0.5933647388994687}\n",
      "{'loss': 1.4854, 'grad_norm': 23.660953521728516, 'learning_rate': 2.028164778991681e-06, 'epoch': 0.5943670442016639}\n",
      "{'loss': 2.4886, 'grad_norm': 0.0, 'learning_rate': 2.023153252480706e-06, 'epoch': 0.5953693495038589}\n",
      "{'loss': 2.2711, 'grad_norm': 6.026662826538086, 'learning_rate': 2.0181417259697306e-06, 'epoch': 0.5963716548060539}\n",
      "{'loss': 1.9809, 'grad_norm': 12.67465877532959, 'learning_rate': 2.0131301994587554e-06, 'epoch': 0.597373960108249}\n",
      "{'loss': 1.9635, 'grad_norm': 6.695747375488281, 'learning_rate': 2.00811867294778e-06, 'epoch': 0.598376265410444}\n",
      "{'loss': 1.0879, 'grad_norm': 12.530413627624512, 'learning_rate': 2.003107146436805e-06, 'epoch': 0.5993785707126391}\n",
      "{'loss': 1.0279, 'grad_norm': 8.487597465515137, 'learning_rate': 1.9980956199258293e-06, 'epoch': 0.6003808760148341}\n",
      "{'loss': 1.3246, 'grad_norm': 10.539460182189941, 'learning_rate': 1.993084093414854e-06, 'epoch': 0.6013831813170292}\n",
      "{'loss': 2.218, 'grad_norm': 8.927806854248047, 'learning_rate': 1.9880725669038793e-06, 'epoch': 0.6023854866192242}\n",
      "{'loss': 1.4392, 'grad_norm': 6.837822437286377, 'learning_rate': 1.9830610403929037e-06, 'epoch': 0.6033877919214192}\n",
      "{'loss': 1.1726, 'grad_norm': 8.0733003616333, 'learning_rate': 1.9780495138819285e-06, 'epoch': 0.6043900972236144}\n",
      "{'loss': 2.254, 'grad_norm': 7.913094997406006, 'learning_rate': 1.9730379873709537e-06, 'epoch': 0.6053924025258094}\n",
      "{'loss': 1.5958, 'grad_norm': 6.594144344329834, 'learning_rate': 1.968026460859978e-06, 'epoch': 0.6063947078280044}\n",
      "{'loss': 1.1114, 'grad_norm': 11.615572929382324, 'learning_rate': 1.963014934349003e-06, 'epoch': 0.6073970131301994}\n",
      "{'loss': 2.2267, 'grad_norm': 15.152657508850098, 'learning_rate': 1.9580034078380276e-06, 'epoch': 0.6083993184323945}\n",
      "{'loss': 1.3558, 'grad_norm': 11.40017318725586, 'learning_rate': 1.9529918813270524e-06, 'epoch': 0.6094016237345895}\n",
      "{'loss': 1.1432, 'grad_norm': 0.31571531295776367, 'learning_rate': 1.947980354816077e-06, 'epoch': 0.6104039290367846}\n",
      "{'loss': 1.3935, 'grad_norm': 12.502853393554688, 'learning_rate': 1.942968828305102e-06, 'epoch': 0.6114062343389797}\n",
      "{'loss': 1.5644, 'grad_norm': 5.443321704864502, 'learning_rate': 1.9379573017941268e-06, 'epoch': 0.6124085396411747}\n",
      "{'loss': 2.3143, 'grad_norm': 9.558370590209961, 'learning_rate': 1.9329457752831516e-06, 'epoch': 0.6134108449433697}\n",
      "{'loss': 1.4205, 'grad_norm': 39.91435241699219, 'learning_rate': 1.927934248772176e-06, 'epoch': 0.6144131502455648}\n",
      "{'loss': 3.121, 'grad_norm': 8.800508499145508, 'learning_rate': 1.922922722261201e-06, 'epoch': 0.6154154555477599}\n",
      "{'loss': 2.1326, 'grad_norm': 13.436230659484863, 'learning_rate': 1.9179111957502255e-06, 'epoch': 0.6164177608499549}\n",
      "{'loss': 2.5434, 'grad_norm': 9.289447784423828, 'learning_rate': 1.9128996692392503e-06, 'epoch': 0.61742006615215}\n",
      "{'loss': 1.3446, 'grad_norm': 9.48996639251709, 'learning_rate': 1.907888142728275e-06, 'epoch': 0.618422371454345}\n",
      "{'loss': 1.4703, 'grad_norm': 6.798765659332275, 'learning_rate': 1.9028766162172999e-06, 'epoch': 0.61942467675654}\n",
      "{'loss': 1.7229, 'grad_norm': 9.12393856048584, 'learning_rate': 1.8978650897063246e-06, 'epoch': 0.6204269820587351}\n",
      "{'loss': 2.5023, 'grad_norm': 8.954760551452637, 'learning_rate': 1.8928535631953496e-06, 'epoch': 0.6214292873609302}\n",
      "{'loss': 1.112, 'grad_norm': 8.503823280334473, 'learning_rate': 1.8878420366843742e-06, 'epoch': 0.6224315926631252}\n",
      "{'loss': 2.1405, 'grad_norm': 0.31210649013519287, 'learning_rate': 1.882830510173399e-06, 'epoch': 0.6234338979653202}\n",
      "{'loss': 1.7343, 'grad_norm': 7.185203552246094, 'learning_rate': 1.8778189836624236e-06, 'epoch': 0.6244362032675153}\n",
      "{'loss': 1.6815, 'grad_norm': 11.244592666625977, 'learning_rate': 1.8728074571514484e-06, 'epoch': 0.6254385085697103}\n",
      "{'loss': 1.9285, 'grad_norm': 5.0618743896484375, 'learning_rate': 1.8677959306404734e-06, 'epoch': 0.6264408138719054}\n",
      "{'loss': 1.6874, 'grad_norm': 11.66254711151123, 'learning_rate': 1.862784404129498e-06, 'epoch': 0.6274431191741004}\n",
      "{'loss': 1.9753, 'grad_norm': 0.19362246990203857, 'learning_rate': 1.8577728776185227e-06, 'epoch': 0.6284454244762955}\n",
      "{'loss': 1.4203, 'grad_norm': 9.468663215637207, 'learning_rate': 1.8527613511075477e-06, 'epoch': 0.6294477297784905}\n",
      "{'loss': 1.4996, 'grad_norm': 5.409953594207764, 'learning_rate': 1.8477498245965723e-06, 'epoch': 0.6304500350806855}\n",
      "{'loss': 0.9511, 'grad_norm': 0.19054727256298065, 'learning_rate': 1.842738298085597e-06, 'epoch': 0.6314523403828807}\n",
      "{'loss': 0.9649, 'grad_norm': 0.37514254450798035, 'learning_rate': 1.8377267715746217e-06, 'epoch': 0.6324546456850757}\n",
      "{'loss': 2.3815, 'grad_norm': 7.814285755157471, 'learning_rate': 1.8327152450636465e-06, 'epoch': 0.6334569509872707}\n",
      "{'loss': 1.304, 'grad_norm': 4.367955684661865, 'learning_rate': 1.8277037185526715e-06, 'epoch': 0.6344592562894658}\n",
      "{'loss': 0.9856, 'grad_norm': 6.958570957183838, 'learning_rate': 1.822692192041696e-06, 'epoch': 0.6354615615916608}\n",
      "{'loss': 1.4332, 'grad_norm': 15.064279556274414, 'learning_rate': 1.8176806655307208e-06, 'epoch': 0.6364638668938559}\n",
      "{'loss': 1.8522, 'grad_norm': 2.3376216888427734, 'learning_rate': 1.8126691390197456e-06, 'epoch': 0.637466172196051}\n",
      "{'loss': 1.2392, 'grad_norm': 6.412542343139648, 'learning_rate': 1.8076576125087702e-06, 'epoch': 0.638468477498246}\n",
      "{'loss': 2.2151, 'grad_norm': 16.41694450378418, 'learning_rate': 1.8026460859977952e-06, 'epoch': 0.639470782800441}\n",
      "{'loss': 1.6801, 'grad_norm': 23.207366943359375, 'learning_rate': 1.7976345594868198e-06, 'epoch': 0.640473088102636}\n",
      "{'loss': 1.5429, 'grad_norm': 0.5371838808059692, 'learning_rate': 1.7926230329758445e-06, 'epoch': 0.6414753934048311}\n",
      "{'loss': 1.6693, 'grad_norm': 11.701186180114746, 'learning_rate': 1.7876115064648693e-06, 'epoch': 0.6424776987070262}\n",
      "{'loss': 1.3543, 'grad_norm': 6.281982421875, 'learning_rate': 1.782599979953894e-06, 'epoch': 0.6434800040092212}\n",
      "{'loss': 1.1788, 'grad_norm': 16.74698829650879, 'learning_rate': 1.777588453442919e-06, 'epoch': 0.6444823093114163}\n",
      "{'loss': 1.5258, 'grad_norm': 1.6815372705459595, 'learning_rate': 1.7725769269319437e-06, 'epoch': 0.6454846146136113}\n",
      "{'loss': 1.5964, 'grad_norm': 16.793262481689453, 'learning_rate': 1.7675654004209683e-06, 'epoch': 0.6464869199158063}\n",
      "{'loss': 2.349, 'grad_norm': 18.633567810058594, 'learning_rate': 1.7625538739099933e-06, 'epoch': 0.6474892252180015}\n",
      "{'loss': 1.0918, 'grad_norm': 7.240424156188965, 'learning_rate': 1.757542347399018e-06, 'epoch': 0.6484915305201965}\n",
      "{'loss': 1.6367, 'grad_norm': 13.524219512939453, 'learning_rate': 1.7525308208880426e-06, 'epoch': 0.6494938358223915}\n",
      "{'loss': 1.0719, 'grad_norm': 0.0, 'learning_rate': 1.7475192943770674e-06, 'epoch': 0.6504961411245865}\n",
      "{'loss': 1.3778, 'grad_norm': 7.406090259552002, 'learning_rate': 1.742507767866092e-06, 'epoch': 0.6514984464267816}\n",
      "{'loss': 1.7892, 'grad_norm': 14.974556922912598, 'learning_rate': 1.737496241355117e-06, 'epoch': 0.6525007517289766}\n",
      "{'loss': 0.9672, 'grad_norm': 1.9607243537902832, 'learning_rate': 1.7324847148441418e-06, 'epoch': 0.6535030570311717}\n",
      "{'loss': 1.9115, 'grad_norm': 10.069190979003906, 'learning_rate': 1.7274731883331663e-06, 'epoch': 0.6545053623333668}\n",
      "{'loss': 2.175, 'grad_norm': 7.8887410163879395, 'learning_rate': 1.7224616618221911e-06, 'epoch': 0.6555076676355618}\n",
      "{'loss': 1.6631, 'grad_norm': 0.37543031573295593, 'learning_rate': 1.7174501353112161e-06, 'epoch': 0.6565099729377568}\n",
      "{'loss': 1.6813, 'grad_norm': 5.928485870361328, 'learning_rate': 1.7124386088002407e-06, 'epoch': 0.6575122782399518}\n",
      "{'loss': 1.6827, 'grad_norm': 15.796547889709473, 'learning_rate': 1.7074270822892655e-06, 'epoch': 0.658514583542147}\n",
      "{'loss': 2.2397, 'grad_norm': 11.859315872192383, 'learning_rate': 1.70241555577829e-06, 'epoch': 0.659516888844342}\n",
      "{'loss': 1.078, 'grad_norm': 14.389016151428223, 'learning_rate': 1.6974040292673149e-06, 'epoch': 0.660519194146537}\n",
      "{'loss': 2.418, 'grad_norm': 7.159725666046143, 'learning_rate': 1.6923925027563399e-06, 'epoch': 0.6615214994487321}\n",
      "{'loss': 1.4855, 'grad_norm': 0.7829493880271912, 'learning_rate': 1.6873809762453644e-06, 'epoch': 0.6625238047509271}\n",
      "{'loss': 1.2229, 'grad_norm': 3.85012149810791, 'learning_rate': 1.6823694497343892e-06, 'epoch': 0.6635261100531222}\n",
      "{'loss': 1.8517, 'grad_norm': 0.5769632458686829, 'learning_rate': 1.6773579232234142e-06, 'epoch': 0.6645284153553173}\n",
      "{'loss': 2.0537, 'grad_norm': 4.975471019744873, 'learning_rate': 1.6723463967124388e-06, 'epoch': 0.6655307206575123}\n",
      "{'loss': 1.5467, 'grad_norm': 9.364919662475586, 'learning_rate': 1.6673348702014636e-06, 'epoch': 0.6665330259597073}\n",
      "{'loss': 1.1118, 'grad_norm': 4.901036262512207, 'learning_rate': 1.6623233436904882e-06, 'epoch': 0.6675353312619023}\n",
      "{'loss': 0.8452, 'grad_norm': 10.96274185180664, 'learning_rate': 1.657311817179513e-06, 'epoch': 0.6685376365640974}\n",
      "{'loss': 1.8818, 'grad_norm': 5.920585632324219, 'learning_rate': 1.652300290668538e-06, 'epoch': 0.6695399418662925}\n",
      "{'loss': 1.7727, 'grad_norm': 4.686038970947266, 'learning_rate': 1.6472887641575625e-06, 'epoch': 0.6705422471684875}\n",
      "{'loss': 0.9497, 'grad_norm': 1.1604787111282349, 'learning_rate': 1.6422772376465873e-06, 'epoch': 0.6715445524706826}\n",
      "{'loss': 1.1908, 'grad_norm': 4.1299285888671875, 'learning_rate': 1.637265711135612e-06, 'epoch': 0.6725468577728776}\n",
      "{'loss': 1.5532, 'grad_norm': 7.8306355476379395, 'learning_rate': 1.6322541846246367e-06, 'epoch': 0.6735491630750726}\n",
      "{'loss': 0.7499, 'grad_norm': 0.37374788522720337, 'learning_rate': 1.6272426581136617e-06, 'epoch': 0.6745514683772678}\n",
      "{'loss': 2.0696, 'grad_norm': 1.172178030014038, 'learning_rate': 1.6222311316026862e-06, 'epoch': 0.6755537736794628}\n",
      "{'loss': 1.9062, 'grad_norm': 8.214463233947754, 'learning_rate': 1.617219605091711e-06, 'epoch': 0.6765560789816578}\n",
      "{'loss': 2.732, 'grad_norm': 9.981046676635742, 'learning_rate': 1.6122080785807358e-06, 'epoch': 0.6775583842838528}\n",
      "{'loss': 1.7156, 'grad_norm': 15.675050735473633, 'learning_rate': 1.6071965520697604e-06, 'epoch': 0.6785606895860479}\n",
      "{'loss': 1.3851, 'grad_norm': 15.934246063232422, 'learning_rate': 1.6021850255587854e-06, 'epoch': 0.679562994888243}\n",
      "{'loss': 1.1391, 'grad_norm': 0.13949178159236908, 'learning_rate': 1.5971734990478102e-06, 'epoch': 0.680565300190438}\n",
      "{'loss': 1.8322, 'grad_norm': 9.396578788757324, 'learning_rate': 1.5921619725368348e-06, 'epoch': 0.6815676054926331}\n",
      "{'loss': 1.8391, 'grad_norm': 7.6461286544799805, 'learning_rate': 1.5871504460258598e-06, 'epoch': 0.6825699107948281}\n",
      "{'loss': 1.5205, 'grad_norm': 16.857833862304688, 'learning_rate': 1.5821389195148843e-06, 'epoch': 0.6835722160970231}\n",
      "{'loss': 1.7589, 'grad_norm': 15.147238731384277, 'learning_rate': 1.5771273930039091e-06, 'epoch': 0.6845745213992181}\n",
      "{'loss': 1.795, 'grad_norm': 52.897830963134766, 'learning_rate': 1.572115866492934e-06, 'epoch': 0.6855768267014133}\n",
      "{'loss': 0.8405, 'grad_norm': 13.623485565185547, 'learning_rate': 1.5671043399819585e-06, 'epoch': 0.6865791320036083}\n",
      "{'loss': 0.923, 'grad_norm': 27.264299392700195, 'learning_rate': 1.5620928134709835e-06, 'epoch': 0.6875814373058033}\n",
      "{'loss': 1.7913, 'grad_norm': 10.603385925292969, 'learning_rate': 1.5570812869600083e-06, 'epoch': 0.6885837426079984}\n",
      "{'loss': 1.7519, 'grad_norm': 4.941251277923584, 'learning_rate': 1.5520697604490328e-06, 'epoch': 0.6895860479101934}\n",
      "{'loss': 1.3841, 'grad_norm': 10.086052894592285, 'learning_rate': 1.5470582339380576e-06, 'epoch': 0.6905883532123885}\n",
      "{'loss': 2.5397, 'grad_norm': 8.740017890930176, 'learning_rate': 1.5420467074270822e-06, 'epoch': 0.6915906585145836}\n",
      "{'loss': 1.7643, 'grad_norm': 17.447782516479492, 'learning_rate': 1.5370351809161072e-06, 'epoch': 0.6925929638167786}\n",
      "{'loss': 1.0697, 'grad_norm': 4.009900093078613, 'learning_rate': 1.532023654405132e-06, 'epoch': 0.6935952691189736}\n",
      "{'loss': 1.7787, 'grad_norm': 4.642971992492676, 'learning_rate': 1.5270121278941566e-06, 'epoch': 0.6945975744211687}\n",
      "{'loss': 1.5978, 'grad_norm': 6.0330047607421875, 'learning_rate': 1.5220006013831814e-06, 'epoch': 0.6955998797233638}\n",
      "{'loss': 1.262, 'grad_norm': 45.73270034790039, 'learning_rate': 1.5169890748722064e-06, 'epoch': 0.6966021850255588}\n",
      "{'loss': 1.6746, 'grad_norm': 5.396696090698242, 'learning_rate': 1.511977548361231e-06, 'epoch': 0.6976044903277538}\n",
      "{'loss': 1.9934, 'grad_norm': 5.368892669677734, 'learning_rate': 1.5069660218502557e-06, 'epoch': 0.6986067956299489}\n",
      "{'loss': 1.8196, 'grad_norm': 10.368029594421387, 'learning_rate': 1.5019544953392803e-06, 'epoch': 0.6996091009321439}\n",
      "{'loss': 2.1294, 'grad_norm': 6.026545524597168, 'learning_rate': 1.4969429688283053e-06, 'epoch': 0.7006114062343389}\n",
      "{'loss': 1.7443, 'grad_norm': 9.713492393493652, 'learning_rate': 1.49193144231733e-06, 'epoch': 0.7016137115365341}\n",
      "{'loss': 0.9639, 'grad_norm': 17.374784469604492, 'learning_rate': 1.4869199158063547e-06, 'epoch': 0.7026160168387291}\n",
      "{'loss': 1.5563, 'grad_norm': 10.831379890441895, 'learning_rate': 1.4819083892953794e-06, 'epoch': 0.7036183221409241}\n",
      "{'loss': 1.4554, 'grad_norm': 0.09683195501565933, 'learning_rate': 1.4768968627844044e-06, 'epoch': 0.7046206274431192}\n",
      "{'loss': 1.4787, 'grad_norm': 8.198031425476074, 'learning_rate': 1.471885336273429e-06, 'epoch': 0.7056229327453142}\n",
      "{'loss': 1.0068, 'grad_norm': 14.47769832611084, 'learning_rate': 1.4668738097624538e-06, 'epoch': 0.7066252380475093}\n",
      "{'loss': 1.341, 'grad_norm': 0.06650245189666748, 'learning_rate': 1.4618622832514784e-06, 'epoch': 0.7076275433497043}\n",
      "{'loss': 2.5174, 'grad_norm': 5.1135735511779785, 'learning_rate': 1.4568507567405032e-06, 'epoch': 0.7086298486518994}\n",
      "{'loss': 2.5996, 'grad_norm': 15.180644989013672, 'learning_rate': 1.4518392302295282e-06, 'epoch': 0.7096321539540944}\n",
      "{'loss': 1.3184, 'grad_norm': 45.87098693847656, 'learning_rate': 1.4468277037185527e-06, 'epoch': 0.7106344592562894}\n",
      "{'loss': 1.853, 'grad_norm': 24.57501220703125, 'learning_rate': 1.4418161772075775e-06, 'epoch': 0.7116367645584846}\n",
      "{'loss': 1.7304, 'grad_norm': 12.484476089477539, 'learning_rate': 1.4368046506966023e-06, 'epoch': 0.7126390698606796}\n",
      "{'loss': 1.0582, 'grad_norm': 6.504582405090332, 'learning_rate': 1.4317931241856269e-06, 'epoch': 0.7136413751628746}\n",
      "{'loss': 1.3454, 'grad_norm': 1.318453073501587, 'learning_rate': 1.4267815976746519e-06, 'epoch': 0.7146436804650697}\n",
      "{'loss': 1.7276, 'grad_norm': 3.938875198364258, 'learning_rate': 1.4217700711636765e-06, 'epoch': 0.7156459857672647}\n",
      "{'loss': 1.6197, 'grad_norm': 5.856935501098633, 'learning_rate': 1.4167585446527012e-06, 'epoch': 0.7166482910694597}\n",
      "{'loss': 2.4019, 'grad_norm': 10.495994567871094, 'learning_rate': 1.4117470181417262e-06, 'epoch': 0.7176505963716548}\n",
      "{'loss': 2.1101, 'grad_norm': 7.378170013427734, 'learning_rate': 1.4067354916307508e-06, 'epoch': 0.7186529016738499}\n",
      "{'loss': 1.2218, 'grad_norm': 7.825658321380615, 'learning_rate': 1.4017239651197756e-06, 'epoch': 0.7196552069760449}\n",
      "{'loss': 0.8184, 'grad_norm': 0.27413979172706604, 'learning_rate': 1.3967124386088004e-06, 'epoch': 0.7206575122782399}\n",
      "{'loss': 1.6304, 'grad_norm': 4.804845333099365, 'learning_rate': 1.391700912097825e-06, 'epoch': 0.721659817580435}\n",
      "{'loss': 1.9537, 'grad_norm': 11.091320037841797, 'learning_rate': 1.38668938558685e-06, 'epoch': 0.7226621228826301}\n",
      "{'loss': 2.2513, 'grad_norm': 0.0, 'learning_rate': 1.3816778590758748e-06, 'epoch': 0.7236644281848251}\n",
      "{'loss': 2.2209, 'grad_norm': 0.03774283453822136, 'learning_rate': 1.3766663325648993e-06, 'epoch': 0.7246667334870202}\n",
      "{'loss': 0.6145, 'grad_norm': 2.3140859603881836, 'learning_rate': 1.3716548060539241e-06, 'epoch': 0.7256690387892152}\n",
      "{'loss': 2.5017, 'grad_norm': 4.4515485763549805, 'learning_rate': 1.3666432795429487e-06, 'epoch': 0.7266713440914102}\n",
      "{'loss': 1.4842, 'grad_norm': 8.170663833618164, 'learning_rate': 1.3616317530319737e-06, 'epoch': 0.7276736493936052}\n",
      "{'loss': 2.2818, 'grad_norm': 17.160036087036133, 'learning_rate': 1.3566202265209985e-06, 'epoch': 0.7286759546958004}\n",
      "{'loss': 2.5441, 'grad_norm': 12.1909761428833, 'learning_rate': 1.351608700010023e-06, 'epoch': 0.7296782599979954}\n",
      "{'loss': 0.867, 'grad_norm': 0.20477980375289917, 'learning_rate': 1.3465971734990478e-06, 'epoch': 0.7306805653001904}\n",
      "{'loss': 2.1531, 'grad_norm': 0.32747799158096313, 'learning_rate': 1.3415856469880728e-06, 'epoch': 0.7316828706023855}\n",
      "{'loss': 1.8684, 'grad_norm': 22.504362106323242, 'learning_rate': 1.3365741204770974e-06, 'epoch': 0.7326851759045805}\n",
      "{'loss': 1.0629, 'grad_norm': 3.229766845703125, 'learning_rate': 1.3315625939661222e-06, 'epoch': 0.7336874812067756}\n",
      "{'loss': 1.5705, 'grad_norm': 12.626665115356445, 'learning_rate': 1.3265510674551468e-06, 'epoch': 0.7346897865089707}\n",
      "{'loss': 1.4891, 'grad_norm': 9.07966136932373, 'learning_rate': 1.3215395409441718e-06, 'epoch': 0.7356920918111657}\n",
      "{'loss': 0.5665, 'grad_norm': 4.8344316482543945, 'learning_rate': 1.3165280144331966e-06, 'epoch': 0.7366943971133607}\n",
      "{'loss': 1.6299, 'grad_norm': 8.587691307067871, 'learning_rate': 1.3115164879222211e-06, 'epoch': 0.7376967024155557}\n",
      "{'loss': 1.5776, 'grad_norm': 1.3529707193374634, 'learning_rate': 1.306504961411246e-06, 'epoch': 0.7386990077177509}\n",
      "{'loss': 2.4107, 'grad_norm': 5.960797309875488, 'learning_rate': 1.301493434900271e-06, 'epoch': 0.7397013130199459}\n",
      "{'loss': 1.1591, 'grad_norm': 6.865314483642578, 'learning_rate': 1.2964819083892955e-06, 'epoch': 0.7407036183221409}\n",
      "{'loss': 1.9947, 'grad_norm': 7.256227016448975, 'learning_rate': 1.2914703818783203e-06, 'epoch': 0.741705923624336}\n",
      "{'loss': 1.8355, 'grad_norm': 13.014250755310059, 'learning_rate': 1.2864588553673449e-06, 'epoch': 0.742708228926531}\n",
      "{'loss': 1.6804, 'grad_norm': 22.453857421875, 'learning_rate': 1.2814473288563697e-06, 'epoch': 0.743710534228726}\n",
      "{'loss': 2.3335, 'grad_norm': 7.208860874176025, 'learning_rate': 1.2764358023453947e-06, 'epoch': 0.7447128395309212}\n",
      "{'loss': 1.7043, 'grad_norm': 17.694625854492188, 'learning_rate': 1.2714242758344192e-06, 'epoch': 0.7457151448331162}\n",
      "{'loss': 1.1339, 'grad_norm': 6.2546305656433105, 'learning_rate': 1.266412749323444e-06, 'epoch': 0.7467174501353112}\n",
      "{'loss': 1.6238, 'grad_norm': 11.767287254333496, 'learning_rate': 1.2614012228124688e-06, 'epoch': 0.7477197554375062}\n",
      "{'loss': 1.8341, 'grad_norm': 23.002532958984375, 'learning_rate': 1.2563896963014936e-06, 'epoch': 0.7487220607397013}\n",
      "{'loss': 2.8449, 'grad_norm': 25.983642578125, 'learning_rate': 1.2513781697905184e-06, 'epoch': 0.7497243660418964}\n",
      "{'loss': 1.7171, 'grad_norm': 4.0385966300964355, 'learning_rate': 1.2463666432795432e-06, 'epoch': 0.7507266713440914}\n",
      "{'loss': 1.1277, 'grad_norm': 8.073091506958008, 'learning_rate': 1.2413551167685677e-06, 'epoch': 0.7517289766462865}\n",
      "{'loss': 1.4868, 'grad_norm': 6.794077396392822, 'learning_rate': 1.2363435902575925e-06, 'epoch': 0.7527312819484815}\n",
      "{'loss': 1.2484, 'grad_norm': 7.482551574707031, 'learning_rate': 1.2313320637466173e-06, 'epoch': 0.7537335872506765}\n",
      "{'loss': 1.6881, 'grad_norm': 10.29743480682373, 'learning_rate': 1.226320537235642e-06, 'epoch': 0.7547358925528717}\n",
      "{'loss': 1.732, 'grad_norm': 11.0491304397583, 'learning_rate': 1.2213090107246669e-06, 'epoch': 0.7557381978550667}\n",
      "{'loss': 1.5804, 'grad_norm': 9.06612777709961, 'learning_rate': 1.2162974842136915e-06, 'epoch': 0.7567405031572617}\n",
      "{'loss': 1.676, 'grad_norm': 6.632029056549072, 'learning_rate': 1.2112859577027165e-06, 'epoch': 0.7577428084594567}\n",
      "{'loss': 1.6366, 'grad_norm': 7.996475696563721, 'learning_rate': 1.206274431191741e-06, 'epoch': 0.7587451137616518}\n",
      "{'loss': 1.9261, 'grad_norm': 14.856531143188477, 'learning_rate': 1.2012629046807658e-06, 'epoch': 0.7597474190638468}\n",
      "{'loss': 0.6163, 'grad_norm': 26.387849807739258, 'learning_rate': 1.1962513781697906e-06, 'epoch': 0.7607497243660419}\n",
      "{'loss': 1.4722, 'grad_norm': 9.42580509185791, 'learning_rate': 1.1912398516588154e-06, 'epoch': 0.761752029668237}\n",
      "{'loss': 2.2845, 'grad_norm': 6.5489420890808105, 'learning_rate': 1.1862283251478402e-06, 'epoch': 0.762754334970432}\n",
      "{'loss': 2.2708, 'grad_norm': 15.243486404418945, 'learning_rate': 1.1812167986368648e-06, 'epoch': 0.763756640272627}\n",
      "{'loss': 1.5962, 'grad_norm': 4.634021282196045, 'learning_rate': 1.1762052721258896e-06, 'epoch': 0.764758945574822}\n",
      "{'loss': 0.606, 'grad_norm': 1.6319864988327026, 'learning_rate': 1.1711937456149143e-06, 'epoch': 0.7657612508770172}\n",
      "{'loss': 1.7272, 'grad_norm': 3.0075600147247314, 'learning_rate': 1.1661822191039391e-06, 'epoch': 0.7667635561792122}\n",
      "{'loss': 1.6234, 'grad_norm': 13.600800514221191, 'learning_rate': 1.161170692592964e-06, 'epoch': 0.7677658614814072}\n",
      "{'loss': 2.8685, 'grad_norm': 0.0, 'learning_rate': 1.1561591660819887e-06, 'epoch': 0.7687681667836023}\n",
      "{'loss': 1.6951, 'grad_norm': 13.599241256713867, 'learning_rate': 1.1511476395710135e-06, 'epoch': 0.7697704720857973}\n",
      "{'loss': 1.4084, 'grad_norm': 17.11103630065918, 'learning_rate': 1.1461361130600383e-06, 'epoch': 0.7707727773879924}\n",
      "{'loss': 1.6867, 'grad_norm': 6.8351898193359375, 'learning_rate': 1.1411245865490629e-06, 'epoch': 0.7717750826901875}\n",
      "{'loss': 2.1391, 'grad_norm': 6.146535873413086, 'learning_rate': 1.1361130600380876e-06, 'epoch': 0.7727773879923825}\n",
      "{'loss': 1.3177, 'grad_norm': 12.063677787780762, 'learning_rate': 1.1311015335271124e-06, 'epoch': 0.7737796932945775}\n",
      "{'loss': 0.9431, 'grad_norm': 8.371341705322266, 'learning_rate': 1.1260900070161372e-06, 'epoch': 0.7747819985967725}\n",
      "{'loss': 1.1751, 'grad_norm': 3.5213356018066406, 'learning_rate': 1.121078480505162e-06, 'epoch': 0.7757843038989676}\n",
      "{'loss': 2.4188, 'grad_norm': 9.880227088928223, 'learning_rate': 1.1160669539941866e-06, 'epoch': 0.7767866092011627}\n",
      "{'loss': 2.1094, 'grad_norm': 6.202986240386963, 'learning_rate': 1.1110554274832116e-06, 'epoch': 0.7777889145033577}\n",
      "{'loss': 1.5851, 'grad_norm': 0.25708669424057007, 'learning_rate': 1.1060439009722362e-06, 'epoch': 0.7787912198055528}\n",
      "{'loss': 1.288, 'grad_norm': 19.166400909423828, 'learning_rate': 1.101032374461261e-06, 'epoch': 0.7797935251077478}\n",
      "{'loss': 1.7456, 'grad_norm': 8.301202774047852, 'learning_rate': 1.0960208479502857e-06, 'epoch': 0.7807958304099428}\n",
      "{'loss': 1.2627, 'grad_norm': 5.549359321594238, 'learning_rate': 1.0910093214393105e-06, 'epoch': 0.781798135712138}\n",
      "{'loss': 1.5263, 'grad_norm': 19.497962951660156, 'learning_rate': 1.0859977949283353e-06, 'epoch': 0.782800441014333}\n",
      "{'loss': 0.9342, 'grad_norm': 10.718720436096191, 'learning_rate': 1.08098626841736e-06, 'epoch': 0.783802746316528}\n",
      "{'loss': 0.7406, 'grad_norm': 12.090055465698242, 'learning_rate': 1.0759747419063847e-06, 'epoch': 0.784805051618723}\n",
      "{'loss': 1.4438, 'grad_norm': 2.812293767929077, 'learning_rate': 1.0709632153954097e-06, 'epoch': 0.7858073569209181}\n",
      "{'loss': 1.3004, 'grad_norm': 2.0950779914855957, 'learning_rate': 1.0659516888844342e-06, 'epoch': 0.7868096622231132}\n",
      "{'loss': 2.439, 'grad_norm': 8.196267127990723, 'learning_rate': 1.060940162373459e-06, 'epoch': 0.7878119675253082}\n",
      "{'loss': 1.5665, 'grad_norm': 0.2747188210487366, 'learning_rate': 1.0559286358624838e-06, 'epoch': 0.7888142728275033}\n",
      "{'loss': 1.4302, 'grad_norm': 0.17375454306602478, 'learning_rate': 1.0509171093515086e-06, 'epoch': 0.7898165781296983}\n",
      "{'loss': 1.4513, 'grad_norm': 9.773406982421875, 'learning_rate': 1.0459055828405334e-06, 'epoch': 0.7908188834318933}\n",
      "{'loss': 1.4648, 'grad_norm': 6.363827705383301, 'learning_rate': 1.040894056329558e-06, 'epoch': 0.7918211887340884}\n",
      "{'loss': 1.3064, 'grad_norm': 9.530735969543457, 'learning_rate': 1.035882529818583e-06, 'epoch': 0.7928234940362835}\n",
      "{'loss': 1.4202, 'grad_norm': 15.233932495117188, 'learning_rate': 1.0308710033076075e-06, 'epoch': 0.7938257993384785}\n",
      "{'loss': 0.9027, 'grad_norm': 13.37772274017334, 'learning_rate': 1.0258594767966323e-06, 'epoch': 0.7948281046406735}\n",
      "{'loss': 0.684, 'grad_norm': 7.713386058807373, 'learning_rate': 1.0208479502856571e-06, 'epoch': 0.7958304099428686}\n",
      "{'loss': 1.456, 'grad_norm': 9.774720191955566, 'learning_rate': 1.015836423774682e-06, 'epoch': 0.7968327152450636}\n",
      "{'loss': 1.739, 'grad_norm': 8.776811599731445, 'learning_rate': 1.0108248972637067e-06, 'epoch': 0.7978350205472587}\n",
      "{'loss': 2.2818, 'grad_norm': 7.211462497711182, 'learning_rate': 1.0058133707527313e-06, 'epoch': 0.7988373258494538}\n",
      "{'loss': 1.4099, 'grad_norm': 29.747676849365234, 'learning_rate': 1.000801844241756e-06, 'epoch': 0.7998396311516488}\n",
      "{'loss': 2.1322, 'grad_norm': 10.194474220275879, 'learning_rate': 9.95790317730781e-07, 'epoch': 0.8008419364538438}\n",
      "{'loss': 1.8748, 'grad_norm': 7.697047233581543, 'learning_rate': 9.907787912198056e-07, 'epoch': 0.8018442417560389}\n",
      "{'loss': 0.8062, 'grad_norm': 0.2093266099691391, 'learning_rate': 9.857672647088304e-07, 'epoch': 0.8028465470582339}\n",
      "{'loss': 2.1752, 'grad_norm': 9.464356422424316, 'learning_rate': 9.807557381978552e-07, 'epoch': 0.803848852360429}\n",
      "{'loss': 1.1252, 'grad_norm': 1.975558876991272, 'learning_rate': 9.7574421168688e-07, 'epoch': 0.804851157662624}\n",
      "{'loss': 1.733, 'grad_norm': 7.517721176147461, 'learning_rate': 9.707326851759048e-07, 'epoch': 0.8058534629648191}\n",
      "{'loss': 1.2515, 'grad_norm': 8.085131645202637, 'learning_rate': 9.657211586649293e-07, 'epoch': 0.8068557682670141}\n",
      "{'loss': 1.4389, 'grad_norm': 8.4882173538208, 'learning_rate': 9.607096321539541e-07, 'epoch': 0.8078580735692091}\n",
      "{'loss': 1.6586, 'grad_norm': 0.09131419658660889, 'learning_rate': 9.55698105642979e-07, 'epoch': 0.8088603788714043}\n",
      "{'loss': 2.3464, 'grad_norm': 14.041701316833496, 'learning_rate': 9.506865791320037e-07, 'epoch': 0.8098626841735993}\n",
      "{'loss': 2.1941, 'grad_norm': 4.791313171386719, 'learning_rate': 9.456750526210284e-07, 'epoch': 0.8108649894757943}\n",
      "{'loss': 1.5208, 'grad_norm': 8.643783569335938, 'learning_rate': 9.406635261100532e-07, 'epoch': 0.8118672947779894}\n",
      "{'loss': 1.4765, 'grad_norm': 8.140254974365234, 'learning_rate': 9.35651999599078e-07, 'epoch': 0.8128696000801844}\n",
      "{'loss': 1.4936, 'grad_norm': 20.382190704345703, 'learning_rate': 9.306404730881028e-07, 'epoch': 0.8138719053823795}\n",
      "{'loss': 1.3485, 'grad_norm': 0.0, 'learning_rate': 9.256289465771274e-07, 'epoch': 0.8148742106845746}\n",
      "{'loss': 1.5861, 'grad_norm': 12.699962615966797, 'learning_rate': 9.206174200661522e-07, 'epoch': 0.8158765159867696}\n",
      "{'loss': 1.6938, 'grad_norm': 2.86468505859375, 'learning_rate': 9.15605893555177e-07, 'epoch': 0.8168788212889646}\n",
      "{'loss': 0.5046, 'grad_norm': 1.4714853763580322, 'learning_rate': 9.105943670442018e-07, 'epoch': 0.8178811265911596}\n",
      "{'loss': 1.0052, 'grad_norm': 42.84382247924805, 'learning_rate': 9.055828405332265e-07, 'epoch': 0.8188834318933547}\n",
      "{'loss': 1.563, 'grad_norm': 0.0, 'learning_rate': 9.005713140222512e-07, 'epoch': 0.8198857371955498}\n",
      "{'loss': 1.621, 'grad_norm': 11.54590129852295, 'learning_rate': 8.95559787511276e-07, 'epoch': 0.8208880424977448}\n",
      "{'loss': 2.0375, 'grad_norm': 56.6159782409668, 'learning_rate': 8.905482610003007e-07, 'epoch': 0.8218903477999399}\n",
      "{'loss': 1.8093, 'grad_norm': 12.415772438049316, 'learning_rate': 8.855367344893255e-07, 'epoch': 0.8228926531021349}\n",
      "{'loss': 1.2026, 'grad_norm': 7.1103668212890625, 'learning_rate': 8.805252079783502e-07, 'epoch': 0.8238949584043299}\n",
      "{'loss': 1.97, 'grad_norm': 10.194440841674805, 'learning_rate': 8.755136814673751e-07, 'epoch': 0.824897263706525}\n",
      "{'loss': 0.3513, 'grad_norm': 1.2997255325317383, 'learning_rate': 8.705021549563998e-07, 'epoch': 0.8258995690087201}\n",
      "{'loss': 1.9486, 'grad_norm': 7.308902263641357, 'learning_rate': 8.654906284454246e-07, 'epoch': 0.8269018743109151}\n",
      "{'loss': 1.4413, 'grad_norm': 7.362003803253174, 'learning_rate': 8.604791019344492e-07, 'epoch': 0.8279041796131101}\n",
      "{'loss': 1.8365, 'grad_norm': 0.0, 'learning_rate': 8.554675754234741e-07, 'epoch': 0.8289064849153052}\n",
      "{'loss': 2.1738, 'grad_norm': 12.129035949707031, 'learning_rate': 8.504560489124988e-07, 'epoch': 0.8299087902175003}\n",
      "{'loss': 1.9406, 'grad_norm': 6.644753932952881, 'learning_rate': 8.454445224015236e-07, 'epoch': 0.8309110955196953}\n",
      "{'loss': 1.6165, 'grad_norm': 8.590780258178711, 'learning_rate': 8.404329958905483e-07, 'epoch': 0.8319134008218904}\n",
      "{'loss': 1.7534, 'grad_norm': 15.645862579345703, 'learning_rate': 8.354214693795732e-07, 'epoch': 0.8329157061240854}\n",
      "{'loss': 1.7845, 'grad_norm': 23.6373348236084, 'learning_rate': 8.304099428685979e-07, 'epoch': 0.8339180114262804}\n",
      "{'loss': 2.0351, 'grad_norm': 6.594115734100342, 'learning_rate': 8.253984163576225e-07, 'epoch': 0.8349203167284754}\n",
      "{'loss': 1.7722, 'grad_norm': 7.157094955444336, 'learning_rate': 8.203868898466473e-07, 'epoch': 0.8359226220306706}\n",
      "{'loss': 1.3803, 'grad_norm': 3.7995989322662354, 'learning_rate': 8.153753633356721e-07, 'epoch': 0.8369249273328656}\n",
      "{'loss': 1.6701, 'grad_norm': 7.9196624755859375, 'learning_rate': 8.103638368246969e-07, 'epoch': 0.8379272326350606}\n",
      "{'loss': 1.9011, 'grad_norm': 1.6183665990829468, 'learning_rate': 8.053523103137216e-07, 'epoch': 0.8389295379372557}\n",
      "{'loss': 1.6319, 'grad_norm': 7.036595344543457, 'learning_rate': 8.003407838027464e-07, 'epoch': 0.8399318432394507}\n",
      "{'loss': 1.9364, 'grad_norm': 28.691320419311523, 'learning_rate': 7.953292572917712e-07, 'epoch': 0.8409341485416458}\n",
      "{'loss': 1.8086, 'grad_norm': 4.287138938903809, 'learning_rate': 7.903177307807959e-07, 'epoch': 0.8419364538438409}\n",
      "{'loss': 1.706, 'grad_norm': 21.790653228759766, 'learning_rate': 7.853062042698206e-07, 'epoch': 0.8429387591460359}\n",
      "{'loss': 2.3514, 'grad_norm': 4.304389953613281, 'learning_rate': 7.802946777588453e-07, 'epoch': 0.8439410644482309}\n",
      "{'loss': 1.9571, 'grad_norm': 19.00848388671875, 'learning_rate': 7.752831512478702e-07, 'epoch': 0.8449433697504259}\n",
      "{'loss': 1.5823, 'grad_norm': 3.108785390853882, 'learning_rate': 7.702716247368949e-07, 'epoch': 0.8459456750526211}\n",
      "{'loss': 1.8631, 'grad_norm': 7.844940185546875, 'learning_rate': 7.652600982259197e-07, 'epoch': 0.8469479803548161}\n",
      "{'loss': 1.5079, 'grad_norm': 10.381185531616211, 'learning_rate': 7.602485717149444e-07, 'epoch': 0.8479502856570111}\n",
      "{'loss': 1.2186, 'grad_norm': 9.046645164489746, 'learning_rate': 7.552370452039692e-07, 'epoch': 0.8489525909592062}\n",
      "{'loss': 1.9543, 'grad_norm': 44.106048583984375, 'learning_rate': 7.502255186929939e-07, 'epoch': 0.8499548962614012}\n",
      "{'loss': 1.7061, 'grad_norm': 6.952327728271484, 'learning_rate': 7.452139921820187e-07, 'epoch': 0.8509572015635962}\n",
      "{'loss': 2.3203, 'grad_norm': 20.536264419555664, 'learning_rate': 7.402024656710434e-07, 'epoch': 0.8519595068657914}\n",
      "{'loss': 1.3448, 'grad_norm': 8.426318168640137, 'learning_rate': 7.351909391600683e-07, 'epoch': 0.8529618121679864}\n",
      "{'loss': 1.6599, 'grad_norm': 5.563670635223389, 'learning_rate': 7.30179412649093e-07, 'epoch': 0.8539641174701814}\n",
      "{'loss': 1.5521, 'grad_norm': 13.663217544555664, 'learning_rate': 7.251678861381177e-07, 'epoch': 0.8549664227723764}\n",
      "{'loss': 1.5469, 'grad_norm': 14.852170944213867, 'learning_rate': 7.201563596271424e-07, 'epoch': 0.8559687280745715}\n",
      "{'loss': 2.6464, 'grad_norm': 15.043769836425781, 'learning_rate': 7.151448331161673e-07, 'epoch': 0.8569710333767666}\n",
      "{'loss': 1.823, 'grad_norm': 7.258780479431152, 'learning_rate': 7.10133306605192e-07, 'epoch': 0.8579733386789616}\n",
      "{'loss': 1.3019, 'grad_norm': 14.432290077209473, 'learning_rate': 7.051217800942167e-07, 'epoch': 0.8589756439811567}\n",
      "{'loss': 2.2221, 'grad_norm': 4.254759788513184, 'learning_rate': 7.001102535832415e-07, 'epoch': 0.8599779492833517}\n",
      "{'loss': 1.3975, 'grad_norm': 1.5131365060806274, 'learning_rate': 6.950987270722663e-07, 'epoch': 0.8609802545855467}\n",
      "{'loss': 1.6406, 'grad_norm': 4.289767265319824, 'learning_rate': 6.900872005612911e-07, 'epoch': 0.8619825598877419}\n",
      "{'loss': 1.9382, 'grad_norm': 10.069788932800293, 'learning_rate': 6.850756740503157e-07, 'epoch': 0.8629848651899369}\n",
      "{'loss': 1.3093, 'grad_norm': 7.368234157562256, 'learning_rate': 6.800641475393406e-07, 'epoch': 0.8639871704921319}\n",
      "{'loss': 1.715, 'grad_norm': 6.723838806152344, 'learning_rate': 6.750526210283653e-07, 'epoch': 0.864989475794327}\n",
      "{'loss': 1.7235, 'grad_norm': 6.005229473114014, 'learning_rate': 6.700410945173901e-07, 'epoch': 0.865991781096522}\n",
      "{'loss': 1.9939, 'grad_norm': 12.781131744384766, 'learning_rate': 6.650295680064148e-07, 'epoch': 0.866994086398717}\n",
      "{'loss': 1.9843, 'grad_norm': 6.446231365203857, 'learning_rate': 6.600180414954397e-07, 'epoch': 0.8679963917009121}\n",
      "{'loss': 1.944, 'grad_norm': 23.37078857421875, 'learning_rate': 6.550065149844644e-07, 'epoch': 0.8689986970031072}\n",
      "{'loss': 1.7247, 'grad_norm': 35.24692916870117, 'learning_rate': 6.49994988473489e-07, 'epoch': 0.8700010023053022}\n",
      "{'loss': 2.0045, 'grad_norm': 15.972406387329102, 'learning_rate': 6.449834619625138e-07, 'epoch': 0.8710033076074972}\n",
      "{'loss': 1.4397, 'grad_norm': 6.023092746734619, 'learning_rate': 6.399719354515386e-07, 'epoch': 0.8720056129096923}\n",
      "{'loss': 1.2509, 'grad_norm': 6.290672779083252, 'learning_rate': 6.349604089405634e-07, 'epoch': 0.8730079182118874}\n",
      "{'loss': 1.7861, 'grad_norm': 11.44394588470459, 'learning_rate': 6.299488824295881e-07, 'epoch': 0.8740102235140824}\n",
      "{'loss': 1.5119, 'grad_norm': 3.900897264480591, 'learning_rate': 6.249373559186129e-07, 'epoch': 0.8750125288162774}\n",
      "{'loss': 1.1487, 'grad_norm': 7.233887195587158, 'learning_rate': 6.199258294076377e-07, 'epoch': 0.8760148341184725}\n",
      "{'loss': 2.2999, 'grad_norm': 15.619786262512207, 'learning_rate': 6.149143028966624e-07, 'epoch': 0.8770171394206675}\n",
      "{'loss': 1.8103, 'grad_norm': 13.02651309967041, 'learning_rate': 6.099027763856871e-07, 'epoch': 0.8780194447228625}\n",
      "{'loss': 1.3193, 'grad_norm': 0.9849902391433716, 'learning_rate': 6.048912498747119e-07, 'epoch': 0.8790217500250577}\n",
      "{'loss': 2.2058, 'grad_norm': 5.624277591705322, 'learning_rate': 5.998797233637366e-07, 'epoch': 0.8800240553272527}\n",
      "{'loss': 1.0088, 'grad_norm': 22.964515686035156, 'learning_rate': 5.948681968527614e-07, 'epoch': 0.8810263606294477}\n",
      "{'loss': 1.2177, 'grad_norm': 15.730216026306152, 'learning_rate': 5.898566703417862e-07, 'epoch': 0.8820286659316428}\n",
      "{'loss': 1.0811, 'grad_norm': 13.12257194519043, 'learning_rate': 5.84845143830811e-07, 'epoch': 0.8830309712338378}\n",
      "{'loss': 0.9496, 'grad_norm': 4.640498638153076, 'learning_rate': 5.798336173198356e-07, 'epoch': 0.8840332765360329}\n",
      "{'loss': 2.152, 'grad_norm': 10.031146049499512, 'learning_rate': 5.748220908088604e-07, 'epoch': 0.885035581838228}\n",
      "{'loss': 1.9143, 'grad_norm': 14.667364120483398, 'learning_rate': 5.698105642978852e-07, 'epoch': 0.886037887140423}\n",
      "{'loss': 1.7489, 'grad_norm': 9.037064552307129, 'learning_rate': 5.6479903778691e-07, 'epoch': 0.887040192442618}\n",
      "{'loss': 1.2661, 'grad_norm': 20.23249053955078, 'learning_rate': 5.597875112759347e-07, 'epoch': 0.888042497744813}\n",
      "{'loss': 1.3398, 'grad_norm': 0.2172737419605255, 'learning_rate': 5.547759847649595e-07, 'epoch': 0.8890448030470082}\n",
      "{'loss': 1.8294, 'grad_norm': 10.526522636413574, 'learning_rate': 5.497644582539841e-07, 'epoch': 0.8900471083492032}\n",
      "{'loss': 2.3731, 'grad_norm': 6.0070037841796875, 'learning_rate': 5.44752931743009e-07, 'epoch': 0.8910494136513982}\n",
      "{'loss': 1.373, 'grad_norm': 7.336480140686035, 'learning_rate': 5.397414052320337e-07, 'epoch': 0.8920517189535933}\n",
      "{'loss': 2.1849, 'grad_norm': 7.909914970397949, 'learning_rate': 5.347298787210585e-07, 'epoch': 0.8930540242557883}\n",
      "{'loss': 1.1222, 'grad_norm': 0.19165877997875214, 'learning_rate': 5.297183522100832e-07, 'epoch': 0.8940563295579833}\n",
      "{'loss': 1.5265, 'grad_norm': 5.466807842254639, 'learning_rate': 5.24706825699108e-07, 'epoch': 0.8950586348601784}\n",
      "{'loss': 1.9053, 'grad_norm': 12.826098442077637, 'learning_rate': 5.196952991881328e-07, 'epoch': 0.8960609401623735}\n",
      "{'loss': 1.9893, 'grad_norm': 7.988102436065674, 'learning_rate': 5.146837726771575e-07, 'epoch': 0.8970632454645685}\n",
      "{'loss': 1.958, 'grad_norm': 2.5909337997436523, 'learning_rate': 5.096722461661822e-07, 'epoch': 0.8980655507667635}\n",
      "{'loss': 2.1587, 'grad_norm': 6.661502361297607, 'learning_rate': 5.04660719655207e-07, 'epoch': 0.8990678560689586}\n",
      "{'loss': 1.637, 'grad_norm': 16.352651596069336, 'learning_rate': 4.996491931442318e-07, 'epoch': 0.9000701613711537}\n",
      "{'loss': 1.5196, 'grad_norm': 11.709993362426758, 'learning_rate': 4.946376666332566e-07, 'epoch': 0.9010724666733487}\n",
      "{'loss': 2.0942, 'grad_norm': 15.88603687286377, 'learning_rate': 4.896261401222813e-07, 'epoch': 0.9020747719755438}\n",
      "{'loss': 1.2019, 'grad_norm': 6.447446346282959, 'learning_rate': 4.846146136113061e-07, 'epoch': 0.9030770772777388}\n",
      "{'loss': 1.8399, 'grad_norm': 14.729716300964355, 'learning_rate': 4.796030871003307e-07, 'epoch': 0.9040793825799338}\n",
      "{'loss': 0.7348, 'grad_norm': 10.078499794006348, 'learning_rate': 4.745915605893556e-07, 'epoch': 0.905081687882129}\n",
      "{'loss': 1.881, 'grad_norm': 1.2731611728668213, 'learning_rate': 4.695800340783803e-07, 'epoch': 0.906083993184324}\n",
      "{'loss': 1.745, 'grad_norm': 12.376317024230957, 'learning_rate': 4.645685075674051e-07, 'epoch': 0.907086298486519}\n",
      "{'loss': 1.0721, 'grad_norm': 6.1585612297058105, 'learning_rate': 4.595569810564298e-07, 'epoch': 0.908088603788714}\n",
      "{'loss': 1.9028, 'grad_norm': 1.1171021461486816, 'learning_rate': 4.5454545454545457e-07, 'epoch': 0.9090909090909091}\n",
      "{'loss': 1.6672, 'grad_norm': 14.453495979309082, 'learning_rate': 4.495339280344793e-07, 'epoch': 0.9100932143931041}\n",
      "{'loss': 1.841, 'grad_norm': 1.5707528591156006, 'learning_rate': 4.445224015235041e-07, 'epoch': 0.9110955196952992}\n",
      "{'loss': 1.6843, 'grad_norm': 5.637322902679443, 'learning_rate': 4.3951087501252883e-07, 'epoch': 0.9120978249974943}\n",
      "{'loss': 1.6404, 'grad_norm': 10.128314018249512, 'learning_rate': 4.344993485015536e-07, 'epoch': 0.9131001302996893}\n",
      "{'loss': 1.0433, 'grad_norm': 17.539926528930664, 'learning_rate': 4.2948782199057835e-07, 'epoch': 0.9141024356018843}\n",
      "{'loss': 2.2413, 'grad_norm': 10.990882873535156, 'learning_rate': 4.2447629547960314e-07, 'epoch': 0.9151047409040793}\n",
      "{'loss': 1.1781, 'grad_norm': 11.677936553955078, 'learning_rate': 4.1946476896862787e-07, 'epoch': 0.9161070462062745}\n",
      "{'loss': 2.1874, 'grad_norm': 6.542631149291992, 'learning_rate': 4.1445324245765266e-07, 'epoch': 0.9171093515084695}\n",
      "{'loss': 1.8169, 'grad_norm': 0.4151352345943451, 'learning_rate': 4.0944171594667734e-07, 'epoch': 0.9181116568106645}\n",
      "{'loss': 1.4451, 'grad_norm': 8.959517478942871, 'learning_rate': 4.044301894357022e-07, 'epoch': 0.9191139621128596}\n",
      "{'loss': 1.6535, 'grad_norm': 7.052234649658203, 'learning_rate': 3.9941866292472686e-07, 'epoch': 0.9201162674150546}\n",
      "{'loss': 2.1334, 'grad_norm': 5.011598110198975, 'learning_rate': 3.9440713641375165e-07, 'epoch': 0.9211185727172497}\n",
      "{'loss': 1.3655, 'grad_norm': 25.761512756347656, 'learning_rate': 3.893956099027764e-07, 'epoch': 0.9221208780194448}\n",
      "{'loss': 1.1088, 'grad_norm': 8.97764778137207, 'learning_rate': 3.8438408339180117e-07, 'epoch': 0.9231231833216398}\n",
      "{'loss': 2.1466, 'grad_norm': 12.087528228759766, 'learning_rate': 3.793725568808259e-07, 'epoch': 0.9241254886238348}\n",
      "{'loss': 2.4387, 'grad_norm': 13.81939697265625, 'learning_rate': 3.743610303698507e-07, 'epoch': 0.9251277939260298}\n",
      "{'loss': 1.6703, 'grad_norm': 0.04743879288434982, 'learning_rate': 3.693495038588754e-07, 'epoch': 0.9261300992282249}\n",
      "{'loss': 1.9487, 'grad_norm': 12.968791961669922, 'learning_rate': 3.643379773479002e-07, 'epoch': 0.92713240453042}\n",
      "{'loss': 1.4957, 'grad_norm': 8.165886878967285, 'learning_rate': 3.5932645083692495e-07, 'epoch': 0.928134709832615}\n",
      "{'loss': 1.3762, 'grad_norm': 10.400790214538574, 'learning_rate': 3.5431492432594974e-07, 'epoch': 0.9291370151348101}\n",
      "{'loss': 2.8719, 'grad_norm': 10.930950164794922, 'learning_rate': 3.493033978149744e-07, 'epoch': 0.9301393204370051}\n",
      "{'loss': 2.2779, 'grad_norm': 7.007893085479736, 'learning_rate': 3.442918713039992e-07, 'epoch': 0.9311416257392001}\n",
      "{'loss': 1.4833, 'grad_norm': 29.035341262817383, 'learning_rate': 3.3928034479302394e-07, 'epoch': 0.9321439310413953}\n",
      "{'loss': 0.9268, 'grad_norm': 1.5507071018218994, 'learning_rate': 3.342688182820487e-07, 'epoch': 0.9331462363435903}\n",
      "{'loss': 1.6027, 'grad_norm': 5.635502338409424, 'learning_rate': 3.2925729177107346e-07, 'epoch': 0.9341485416457853}\n",
      "{'loss': 1.4988, 'grad_norm': 12.062810897827148, 'learning_rate': 3.2424576526009825e-07, 'epoch': 0.9351508469479803}\n",
      "{'loss': 2.0872, 'grad_norm': 5.401549816131592, 'learning_rate': 3.1923423874912303e-07, 'epoch': 0.9361531522501754}\n",
      "{'loss': 2.0148, 'grad_norm': 0.0, 'learning_rate': 3.1422271223814777e-07, 'epoch': 0.9371554575523704}\n",
      "{'loss': 2.0638, 'grad_norm': 5.957612037658691, 'learning_rate': 3.092111857271725e-07, 'epoch': 0.9381577628545655}\n",
      "{'loss': 0.9259, 'grad_norm': 3.2080819606781006, 'learning_rate': 3.041996592161973e-07, 'epoch': 0.9391600681567606}\n",
      "{'loss': 1.8862, 'grad_norm': 7.509154319763184, 'learning_rate': 2.99188132705222e-07, 'epoch': 0.9401623734589556}\n",
      "{'loss': 1.4121, 'grad_norm': 11.626423835754395, 'learning_rate': 2.941766061942468e-07, 'epoch': 0.9411646787611506}\n",
      "{'loss': 1.5298, 'grad_norm': 4.294783115386963, 'learning_rate': 2.8916507968327155e-07, 'epoch': 0.9421669840633456}\n",
      "{'loss': 1.1747, 'grad_norm': 13.795744895935059, 'learning_rate': 2.841535531722963e-07, 'epoch': 0.9431692893655408}\n",
      "{'loss': 0.8537, 'grad_norm': 8.84902286529541, 'learning_rate': 2.7914202666132107e-07, 'epoch': 0.9441715946677358}\n",
      "{'loss': 1.253, 'grad_norm': 6.441219329833984, 'learning_rate': 2.741305001503458e-07, 'epoch': 0.9451738999699308}\n",
      "{'loss': 0.969, 'grad_norm': 13.618656158447266, 'learning_rate': 2.691189736393706e-07, 'epoch': 0.9461762052721259}\n",
      "{'loss': 1.3495, 'grad_norm': 5.820033073425293, 'learning_rate': 2.641074471283953e-07, 'epoch': 0.9471785105743209}\n",
      "{'loss': 1.8452, 'grad_norm': 13.667736053466797, 'learning_rate': 2.5909592061742006e-07, 'epoch': 0.948180815876516}\n",
      "{'loss': 1.4142, 'grad_norm': 6.325890064239502, 'learning_rate': 2.5408439410644484e-07, 'epoch': 0.9491831211787111}\n",
      "{'loss': 1.735, 'grad_norm': 59.77332305908203, 'learning_rate': 2.490728675954696e-07, 'epoch': 0.9501854264809061}\n",
      "{'loss': 2.199, 'grad_norm': 5.542511940002441, 'learning_rate': 2.4406134108449437e-07, 'epoch': 0.9511877317831011}\n",
      "{'loss': 1.4478, 'grad_norm': 8.363231658935547, 'learning_rate': 2.390498145735191e-07, 'epoch': 0.9521900370852961}\n",
      "{'loss': 1.6422, 'grad_norm': 2.4933078289031982, 'learning_rate': 2.3403828806254386e-07, 'epoch': 0.9531923423874912}\n",
      "{'loss': 1.332, 'grad_norm': 6.4857001304626465, 'learning_rate': 2.2902676155156862e-07, 'epoch': 0.9541946476896863}\n",
      "{'loss': 1.5696, 'grad_norm': 2.2667508125305176, 'learning_rate': 2.2401523504059338e-07, 'epoch': 0.9551969529918813}\n",
      "{'loss': 1.9927, 'grad_norm': 6.09782075881958, 'learning_rate': 2.1900370852961812e-07, 'epoch': 0.9561992582940764}\n",
      "{'loss': 1.4033, 'grad_norm': 4.415017127990723, 'learning_rate': 2.1399218201864288e-07, 'epoch': 0.9572015635962714}\n",
      "{'loss': 1.6597, 'grad_norm': 13.033368110656738, 'learning_rate': 2.0898065550766764e-07, 'epoch': 0.9582038688984664}\n",
      "{'loss': 1.9569, 'grad_norm': 18.589160919189453, 'learning_rate': 2.039691289966924e-07, 'epoch': 0.9592061742006616}\n",
      "{'loss': 1.8128, 'grad_norm': 6.221588611602783, 'learning_rate': 1.9895760248571716e-07, 'epoch': 0.9602084795028566}\n",
      "{'loss': 1.5657, 'grad_norm': 7.598072052001953, 'learning_rate': 1.9394607597474192e-07, 'epoch': 0.9612107848050516}\n",
      "{'loss': 1.5015, 'grad_norm': 17.15127182006836, 'learning_rate': 1.8893454946376665e-07, 'epoch': 0.9622130901072466}\n",
      "{'loss': 1.1953, 'grad_norm': 13.675763130187988, 'learning_rate': 1.8392302295279142e-07, 'epoch': 0.9632153954094417}\n",
      "{'loss': 1.5563, 'grad_norm': 13.290757179260254, 'learning_rate': 1.7891149644181618e-07, 'epoch': 0.9642177007116368}\n",
      "{'loss': 2.1301, 'grad_norm': 7.245720386505127, 'learning_rate': 1.7389996993084094e-07, 'epoch': 0.9652200060138318}\n",
      "{'loss': 1.8639, 'grad_norm': 9.095335960388184, 'learning_rate': 1.688884434198657e-07, 'epoch': 0.9662223113160269}\n",
      "{'loss': 1.1877, 'grad_norm': 6.179208755493164, 'learning_rate': 1.6387691690889046e-07, 'epoch': 0.9672246166182219}\n",
      "{'loss': 1.6023, 'grad_norm': 10.545775413513184, 'learning_rate': 1.588653903979152e-07, 'epoch': 0.9682269219204169}\n",
      "{'loss': 1.3875, 'grad_norm': 0.3054077923297882, 'learning_rate': 1.5385386388693998e-07, 'epoch': 0.969229227222612}\n",
      "{'loss': 3.2302, 'grad_norm': 6.470959186553955, 'learning_rate': 1.4884233737596474e-07, 'epoch': 0.9702315325248071}\n",
      "{'loss': 1.0111, 'grad_norm': 0.4926426112651825, 'learning_rate': 1.4383081086498947e-07, 'epoch': 0.9712338378270021}\n",
      "{'loss': 1.7585, 'grad_norm': 14.45394515991211, 'learning_rate': 1.3881928435401424e-07, 'epoch': 0.9722361431291972}\n",
      "{'loss': 1.6415, 'grad_norm': 7.3378214836120605, 'learning_rate': 1.33807757843039e-07, 'epoch': 0.9732384484313922}\n",
      "{'loss': 1.2127, 'grad_norm': 3.928525447845459, 'learning_rate': 1.2879623133206376e-07, 'epoch': 0.9742407537335872}\n",
      "{'loss': 1.517, 'grad_norm': 8.461592674255371, 'learning_rate': 1.2378470482108852e-07, 'epoch': 0.9752430590357823}\n",
      "{'loss': 1.9879, 'grad_norm': 7.43411922454834, 'learning_rate': 1.1877317831011327e-07, 'epoch': 0.9762453643379774}\n",
      "{'loss': 1.6116, 'grad_norm': 7.419674873352051, 'learning_rate': 1.1376165179913803e-07, 'epoch': 0.9772476696401724}\n",
      "{'loss': 1.5388, 'grad_norm': 0.0, 'learning_rate': 1.0875012528816277e-07, 'epoch': 0.9782499749423674}\n",
      "{'loss': 1.6608, 'grad_norm': 5.047540187835693, 'learning_rate': 1.0373859877718753e-07, 'epoch': 0.9792522802445625}\n",
      "{'loss': 1.324, 'grad_norm': 6.7010297775268555, 'learning_rate': 9.87270722662123e-08, 'epoch': 0.9802545855467576}\n",
      "{'loss': 1.93, 'grad_norm': 6.235803127288818, 'learning_rate': 9.371554575523704e-08, 'epoch': 0.9812568908489526}\n",
      "{'loss': 1.9107, 'grad_norm': 36.28301239013672, 'learning_rate': 8.87040192442618e-08, 'epoch': 0.9822591961511477}\n",
      "{'loss': 1.0929, 'grad_norm': 13.444730758666992, 'learning_rate': 8.369249273328656e-08, 'epoch': 0.9832615014533427}\n",
      "{'loss': 1.8155, 'grad_norm': 9.397313117980957, 'learning_rate': 7.868096622231131e-08, 'epoch': 0.9842638067555377}\n",
      "{'loss': 1.7705, 'grad_norm': 0.3339810371398926, 'learning_rate': 7.366943971133609e-08, 'epoch': 0.9852661120577327}\n",
      "{'loss': 1.0005, 'grad_norm': 0.19036780297756195, 'learning_rate': 6.865791320036083e-08, 'epoch': 0.9862684173599279}\n",
      "{'loss': 1.4295, 'grad_norm': 14.488694190979004, 'learning_rate': 6.36463866893856e-08, 'epoch': 0.9872707226621229}\n",
      "{'loss': 0.7151, 'grad_norm': 0.0, 'learning_rate': 5.863486017841035e-08, 'epoch': 0.9882730279643179}\n",
      "{'loss': 2.4222, 'grad_norm': 6.648532867431641, 'learning_rate': 5.36233336674351e-08, 'epoch': 0.989275333266513}\n",
      "{'loss': 1.0096, 'grad_norm': 25.27293586730957, 'learning_rate': 4.861180715645986e-08, 'epoch': 0.990277638568708}\n",
      "{'loss': 1.4842, 'grad_norm': 4.776939868927002, 'learning_rate': 4.360028064548462e-08, 'epoch': 0.9912799438709031}\n",
      "{'loss': 1.0163, 'grad_norm': 3.3530678749084473, 'learning_rate': 3.858875413450937e-08, 'epoch': 0.9922822491730982}\n",
      "{'loss': 1.6907, 'grad_norm': 7.045074939727783, 'learning_rate': 3.357722762353413e-08, 'epoch': 0.9932845544752932}\n",
      "{'loss': 1.4093, 'grad_norm': 15.099159240722656, 'learning_rate': 2.856570111255889e-08, 'epoch': 0.9942868597774882}\n",
      "{'loss': 1.9619, 'grad_norm': 12.80527400970459, 'learning_rate': 2.3554174601583647e-08, 'epoch': 0.9952891650796832}\n",
      "{'loss': 1.3275, 'grad_norm': 11.554779052734375, 'learning_rate': 1.85426480906084e-08, 'epoch': 0.9962914703818784}\n",
      "{'loss': 1.5948, 'grad_norm': 13.69225788116455, 'learning_rate': 1.3531121579633159e-08, 'epoch': 0.9972937756840734}\n",
      "{'loss': 1.8177, 'grad_norm': 4.764305591583252, 'learning_rate': 8.519595068657914e-09, 'epoch': 0.9982960809862684}\n",
      "{'loss': 1.3658, 'grad_norm': 0.7784380316734314, 'learning_rate': 3.5080685576826705e-09, 'epoch': 0.9992983862884635}\n",
      "{'eval_loss': nan, 'eval_runtime': 310.1578, 'eval_samples_per_second': 8.015, 'eval_steps_per_second': 8.015, 'epoch': 1.0}\n",
      "{'train_runtime': 7925.9959, 'train_samples_per_second': 2.518, 'train_steps_per_second': 1.259, 'train_loss': 1.9008366028435952, 'epoch': 1.0}\n",
      "[COMPLETE] Elapsed: 7926.34s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7fe30c4825d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train the GPT-2 Large model with the quest data\n",
    "gpt2_large_trainer: Trainer = gpt2_large_model.tokenize_and_train(quest_set)\n",
    "gpt2_large_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9bda9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOWNLOAD] llama-3.2-1b-instruct (meta-llama/Llama-3.2-1B-Instruct)\n",
      "[LoRAINFO] trainable params: 5,636,096 || all params: 754,911,232 || trainable%: 0.7466\n",
      "[COMPLETE] \"llama-3.2-1b-instruct\" ready in 52.69s.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuestGenLLM(tokenizer=PreTrainedTokenizerFast(name_or_path='meta-llama/Llama-3.2-1B-Instruct', vocab_size=128000, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128002: AddedToken(\"<|reserved_special_token_0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128003: AddedToken(\"<|reserved_special_token_1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128004: AddedToken(\"<|finetune_right_pad_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128005: AddedToken(\"<|reserved_special_token_2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128008: AddedToken(\"<|eom_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128010: AddedToken(\"<|python_tag|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128011: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128012: AddedToken(\"<|reserved_special_token_4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128013: AddedToken(\"<|reserved_special_token_5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128014: AddedToken(\"<|reserved_special_token_6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128015: AddedToken(\"<|reserved_special_token_7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128016: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128017: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128018: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128019: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128020: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128021: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128022: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128023: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128024: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128025: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128026: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128027: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128028: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128029: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128030: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128031: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128032: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128033: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128034: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128035: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128036: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128037: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128038: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128039: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128040: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128041: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128042: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128043: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128044: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128045: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128046: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128047: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128048: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128049: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128050: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128051: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128052: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128053: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128054: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128055: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128056: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128057: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128058: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128059: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128060: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128061: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128062: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128063: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128064: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128065: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128066: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128067: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128068: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128069: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128070: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128071: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128072: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128073: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128074: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128075: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128076: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128077: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128078: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128079: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128080: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128081: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128082: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128083: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128084: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128085: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128086: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128087: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128088: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128089: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128090: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128091: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128092: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128093: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128094: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128095: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128096: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128097: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128098: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128099: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128100: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128101: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128102: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128103: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128104: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128105: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128106: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128107: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128108: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128109: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128110: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128111: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128112: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128113: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128114: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128115: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128116: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128117: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128118: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128119: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128120: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128121: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128122: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128123: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128124: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128125: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128126: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128127: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128128: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128129: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128130: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128131: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128132: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128133: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128134: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128135: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128136: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128137: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128138: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128139: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128140: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128141: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128142: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128143: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128144: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128145: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128146: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128147: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128148: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128149: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128150: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128151: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128152: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128153: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128154: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128155: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128156: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128157: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128158: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128159: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128160: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128161: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128162: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128163: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128164: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128165: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128166: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128167: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128168: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128169: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128170: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128171: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128172: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128173: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128174: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128175: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128176: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128177: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128178: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128179: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128180: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128181: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128182: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128183: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128184: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128185: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128186: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128187: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128188: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128189: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128190: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128191: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128192: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128193: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128194: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128195: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128196: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128197: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128198: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128199: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128200: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128201: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128202: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128203: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128204: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128205: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128206: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128207: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128208: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128209: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128210: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128211: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128212: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128213: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128214: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128215: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128216: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128217: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128218: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128219: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128220: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128221: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128222: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128223: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128224: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128225: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128226: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128227: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128228: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128229: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128230: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128231: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128232: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128233: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128234: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128235: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128236: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128237: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128238: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128239: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128240: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128241: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128242: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128243: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128244: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128245: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128246: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128247: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128248: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128249: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128250: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128251: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128252: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128253: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128254: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128255: AddedToken(\"<|reserved_special_token_247|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "), model=PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       "), model_key='llama-3.2-1b-instruct', model_id='meta-llama/Llama-3.2-1B-Instruct', fp16_available=True, device='cuda:0', dtype='float32')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the Llama 3.2 model\n",
    "llama32_model: QuestGenLLM = QuestGenLLM.from_pretrained(\n",
    "    model_key=\"llama-3.2-1b-instruct\",\n",
    "    model_id=MODEL_IDENTIFIERS[\"llama-3.2-1b-instruct\"],\n",
    ")\n",
    "llama32_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2e31198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOKENIZE] llama-3.2-1b-instruct (meta-llama/Llama-3.2-1B-Instruct)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c6ffb9e97148e3aecfb9818614dcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19954 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467c26e8b04e42ee9b9e5b8b97b5bc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMPLETE] Elapsed: 1.85s\n",
      "\n",
      "[FINETUNE] llama-3.2-1b-instruct (meta-llama/Llama-3.2-1B-Instruct)\n",
      "{'loss': 5.5898, 'grad_norm': 8.2940673828125, 'learning_rate': 4.994988473489026e-06, 'epoch': 0.0010023053021950487}\n",
      "{'loss': 5.0065, 'grad_norm': 7.0037760734558105, 'learning_rate': 4.98997694697805e-06, 'epoch': 0.0020046106043900974}\n",
      "{'loss': 5.1688, 'grad_norm': 10.214489936828613, 'learning_rate': 4.984965420467074e-06, 'epoch': 0.0030069159065851457}\n",
      "{'loss': 5.8673, 'grad_norm': 5.771705627441406, 'learning_rate': 4.9799538939560996e-06, 'epoch': 0.004009221208780195}\n",
      "{'loss': 5.4176, 'grad_norm': 7.813205242156982, 'learning_rate': 4.974942367445124e-06, 'epoch': 0.005011526510975243}\n",
      "{'loss': 5.3445, 'grad_norm': 6.220595359802246, 'learning_rate': 4.969930840934149e-06, 'epoch': 0.006013831813170291}\n",
      "{'loss': 5.3704, 'grad_norm': 9.442450523376465, 'learning_rate': 4.9649193144231735e-06, 'epoch': 0.00701613711536534}\n",
      "{'loss': 4.9348, 'grad_norm': 7.940437316894531, 'learning_rate': 4.959907787912199e-06, 'epoch': 0.00801844241756039}\n",
      "{'loss': 4.7625, 'grad_norm': 8.118612289428711, 'learning_rate': 4.954896261401223e-06, 'epoch': 0.009020747719755437}\n",
      "{'loss': 4.8434, 'grad_norm': 4.569303035736084, 'learning_rate': 4.949884734890248e-06, 'epoch': 0.010023053021950485}\n",
      "{'loss': 4.8556, 'grad_norm': 18.33374786376953, 'learning_rate': 4.944873208379273e-06, 'epoch': 0.011025358324145534}\n",
      "{'loss': 4.6235, 'grad_norm': 5.772408962249756, 'learning_rate': 4.939861681868298e-06, 'epoch': 0.012027663626340583}\n",
      "{'loss': 4.4471, 'grad_norm': 8.753626823425293, 'learning_rate': 4.934850155357322e-06, 'epoch': 0.013029968928535631}\n",
      "{'loss': 3.7579, 'grad_norm': 5.588968276977539, 'learning_rate': 4.929838628846347e-06, 'epoch': 0.01403227423073068}\n",
      "{'loss': 4.0031, 'grad_norm': 6.664250373840332, 'learning_rate': 4.924827102335372e-06, 'epoch': 0.015034579532925729}\n",
      "{'loss': 4.2142, 'grad_norm': 5.724983215332031, 'learning_rate': 4.919815575824396e-06, 'epoch': 0.01603688483512078}\n",
      "{'loss': 4.5605, 'grad_norm': 6.7080278396606445, 'learning_rate': 4.914804049313421e-06, 'epoch': 0.017039190137315828}\n",
      "{'loss': 4.2886, 'grad_norm': 21.542831420898438, 'learning_rate': 4.909792522802447e-06, 'epoch': 0.018041495439510873}\n",
      "{'loss': 5.0775, 'grad_norm': 6.651169300079346, 'learning_rate': 4.904780996291471e-06, 'epoch': 0.019043800741705922}\n",
      "{'loss': 4.4956, 'grad_norm': 7.50877571105957, 'learning_rate': 4.899769469780495e-06, 'epoch': 0.02004610604390097}\n",
      "{'loss': 4.7926, 'grad_norm': 8.464000701904297, 'learning_rate': 4.8947579432695205e-06, 'epoch': 0.02104841134609602}\n",
      "{'loss': 4.4526, 'grad_norm': 4.907986164093018, 'learning_rate': 4.889746416758545e-06, 'epoch': 0.022050716648291068}\n",
      "{'loss': 4.1082, 'grad_norm': 14.130749702453613, 'learning_rate': 4.88473489024757e-06, 'epoch': 0.023053021950486117}\n",
      "{'loss': 3.7393, 'grad_norm': 5.982326984405518, 'learning_rate': 4.8797233637365945e-06, 'epoch': 0.024055327252681166}\n",
      "{'loss': 4.1618, 'grad_norm': 6.39725399017334, 'learning_rate': 4.874711837225619e-06, 'epoch': 0.025057632554876214}\n",
      "{'loss': 4.1171, 'grad_norm': 6.292623996734619, 'learning_rate': 4.869700310714644e-06, 'epoch': 0.026059937857071263}\n",
      "{'loss': 4.1626, 'grad_norm': 5.582736492156982, 'learning_rate': 4.864688784203669e-06, 'epoch': 0.02706224315926631}\n",
      "{'loss': 3.9153, 'grad_norm': 7.364327907562256, 'learning_rate': 4.859677257692694e-06, 'epoch': 0.02806454846146136}\n",
      "{'loss': 4.2865, 'grad_norm': 7.67042350769043, 'learning_rate': 4.854665731181719e-06, 'epoch': 0.02906685376365641}\n",
      "{'loss': 3.9396, 'grad_norm': 8.207403182983398, 'learning_rate': 4.849654204670743e-06, 'epoch': 0.030069159065851458}\n",
      "{'loss': 4.3941, 'grad_norm': 5.550920486450195, 'learning_rate': 4.8446426781597675e-06, 'epoch': 0.031071464368046506}\n",
      "{'loss': 3.9529, 'grad_norm': 9.579267501831055, 'learning_rate': 4.839631151648793e-06, 'epoch': 0.03207376967024156}\n",
      "{'loss': 3.5745, 'grad_norm': 5.239692211151123, 'learning_rate': 4.834619625137817e-06, 'epoch': 0.03307607497243661}\n",
      "{'loss': 4.1041, 'grad_norm': 14.273138999938965, 'learning_rate': 4.829608098626842e-06, 'epoch': 0.034078380274631656}\n",
      "{'loss': 3.4907, 'grad_norm': 13.351386070251465, 'learning_rate': 4.824596572115867e-06, 'epoch': 0.035080685576826705}\n",
      "{'loss': 4.1571, 'grad_norm': 15.175838470458984, 'learning_rate': 4.819585045604892e-06, 'epoch': 0.03608299087902175}\n",
      "{'loss': 3.9311, 'grad_norm': 4.396181106567383, 'learning_rate': 4.814573519093916e-06, 'epoch': 0.037085296181216795}\n",
      "{'loss': 4.1543, 'grad_norm': 10.316970825195312, 'learning_rate': 4.8095619925829415e-06, 'epoch': 0.038087601483411844}\n",
      "{'loss': 3.3556, 'grad_norm': 9.264504432678223, 'learning_rate': 4.804550466071966e-06, 'epoch': 0.03908990678560689}\n",
      "{'loss': 3.8919, 'grad_norm': 18.596542358398438, 'learning_rate': 4.799538939560991e-06, 'epoch': 0.04009221208780194}\n",
      "{'loss': 3.5852, 'grad_norm': 5.778951168060303, 'learning_rate': 4.794527413050015e-06, 'epoch': 0.04109451738999699}\n",
      "{'loss': 3.3585, 'grad_norm': 7.255405902862549, 'learning_rate': 4.78951588653904e-06, 'epoch': 0.04209682269219204}\n",
      "{'loss': 3.6346, 'grad_norm': 10.819775581359863, 'learning_rate': 4.784504360028065e-06, 'epoch': 0.04309912799438709}\n",
      "{'loss': 3.7395, 'grad_norm': 9.986652374267578, 'learning_rate': 4.77949283351709e-06, 'epoch': 0.044101433296582136}\n",
      "{'loss': 3.8923, 'grad_norm': 5.277294635772705, 'learning_rate': 4.7744813070061146e-06, 'epoch': 0.045103738598777185}\n",
      "{'loss': 3.3846, 'grad_norm': 15.484813690185547, 'learning_rate': 4.769469780495139e-06, 'epoch': 0.046106043900972234}\n",
      "{'loss': 3.7344, 'grad_norm': 10.020224571228027, 'learning_rate': 4.764458253984164e-06, 'epoch': 0.04710834920316728}\n",
      "{'loss': 3.079, 'grad_norm': 10.127737998962402, 'learning_rate': 4.7594467274731885e-06, 'epoch': 0.04811065450536233}\n",
      "{'loss': 3.9045, 'grad_norm': 29.074548721313477, 'learning_rate': 4.754435200962214e-06, 'epoch': 0.04911295980755738}\n",
      "{'loss': 3.3801, 'grad_norm': 8.402978897094727, 'learning_rate': 4.749423674451238e-06, 'epoch': 0.05011526510975243}\n",
      "{'loss': 3.8592, 'grad_norm': 6.384897232055664, 'learning_rate': 4.7444121479402624e-06, 'epoch': 0.05111757041194748}\n",
      "{'loss': 3.4281, 'grad_norm': 8.846301078796387, 'learning_rate': 4.739400621429288e-06, 'epoch': 0.052119875714142526}\n",
      "{'loss': 2.9341, 'grad_norm': 10.786452293395996, 'learning_rate': 4.734389094918313e-06, 'epoch': 0.053122181016337575}\n",
      "{'loss': 3.2448, 'grad_norm': 11.078473091125488, 'learning_rate': 4.729377568407337e-06, 'epoch': 0.05412448631853262}\n",
      "{'loss': 2.9671, 'grad_norm': 9.535806655883789, 'learning_rate': 4.7243660418963624e-06, 'epoch': 0.05512679162072767}\n",
      "{'loss': 3.0144, 'grad_norm': 7.968472003936768, 'learning_rate': 4.719354515385387e-06, 'epoch': 0.05612909692292272}\n",
      "{'loss': 2.9652, 'grad_norm': 10.518446922302246, 'learning_rate': 4.714342988874411e-06, 'epoch': 0.05713140222511777}\n",
      "{'loss': 3.0447, 'grad_norm': 14.25070571899414, 'learning_rate': 4.709331462363436e-06, 'epoch': 0.05813370752731282}\n",
      "{'loss': 3.7372, 'grad_norm': 15.059258460998535, 'learning_rate': 4.704319935852461e-06, 'epoch': 0.05913601282950787}\n",
      "{'loss': 2.7655, 'grad_norm': 13.603982925415039, 'learning_rate': 4.699308409341486e-06, 'epoch': 0.060138318131702916}\n",
      "{'loss': 3.3251, 'grad_norm': 6.068132400512695, 'learning_rate': 4.694296882830511e-06, 'epoch': 0.061140623433897964}\n",
      "{'loss': 3.2193, 'grad_norm': 8.282906532287598, 'learning_rate': 4.689285356319535e-06, 'epoch': 0.06214292873609301}\n",
      "{'loss': 3.7338, 'grad_norm': 8.403691291809082, 'learning_rate': 4.68427382980856e-06, 'epoch': 0.06314523403828806}\n",
      "{'loss': 3.1525, 'grad_norm': 12.29034423828125, 'learning_rate': 4.679262303297585e-06, 'epoch': 0.06414753934048312}\n",
      "{'loss': 2.8857, 'grad_norm': 11.466551780700684, 'learning_rate': 4.6742507767866095e-06, 'epoch': 0.06514984464267816}\n",
      "{'loss': 3.0099, 'grad_norm': 11.899383544921875, 'learning_rate': 4.669239250275635e-06, 'epoch': 0.06615214994487321}\n",
      "{'loss': 3.2351, 'grad_norm': 8.306724548339844, 'learning_rate': 4.664227723764659e-06, 'epoch': 0.06715445524706826}\n",
      "{'loss': 2.5166, 'grad_norm': 8.25860595703125, 'learning_rate': 4.659216197253683e-06, 'epoch': 0.06815676054926331}\n",
      "{'loss': 3.4145, 'grad_norm': 6.5865960121154785, 'learning_rate': 4.654204670742709e-06, 'epoch': 0.06915906585145835}\n",
      "{'loss': 3.4716, 'grad_norm': 28.919239044189453, 'learning_rate': 4.649193144231734e-06, 'epoch': 0.07016137115365341}\n",
      "{'loss': 3.1117, 'grad_norm': 12.253656387329102, 'learning_rate': 4.644181617720758e-06, 'epoch': 0.07116367645584845}\n",
      "{'loss': 3.1467, 'grad_norm': 12.134092330932617, 'learning_rate': 4.639170091209783e-06, 'epoch': 0.0721659817580435}\n",
      "{'loss': 2.7422, 'grad_norm': 4.167813301086426, 'learning_rate': 4.634158564698808e-06, 'epoch': 0.07316828706023855}\n",
      "{'loss': 3.6377, 'grad_norm': 16.090255737304688, 'learning_rate': 4.629147038187832e-06, 'epoch': 0.07417059236243359}\n",
      "{'loss': 3.3411, 'grad_norm': 21.949893951416016, 'learning_rate': 4.624135511676857e-06, 'epoch': 0.07517289766462865}\n",
      "{'loss': 3.2982, 'grad_norm': 7.594132900238037, 'learning_rate': 4.619123985165882e-06, 'epoch': 0.07617520296682369}\n",
      "{'loss': 3.1995, 'grad_norm': 17.500293731689453, 'learning_rate': 4.614112458654907e-06, 'epoch': 0.07717750826901874}\n",
      "{'loss': 3.0191, 'grad_norm': 3.805130958557129, 'learning_rate': 4.609100932143931e-06, 'epoch': 0.07817981357121379}\n",
      "{'loss': 2.882, 'grad_norm': 36.211727142333984, 'learning_rate': 4.604089405632956e-06, 'epoch': 0.07918211887340884}\n",
      "{'loss': 3.3628, 'grad_norm': 9.224641799926758, 'learning_rate': 4.599077879121981e-06, 'epoch': 0.08018442417560388}\n",
      "{'loss': 3.3163, 'grad_norm': 7.517578125, 'learning_rate': 4.594066352611006e-06, 'epoch': 0.08118672947779894}\n",
      "{'loss': 3.0551, 'grad_norm': 11.811894416809082, 'learning_rate': 4.58905482610003e-06, 'epoch': 0.08218903477999398}\n",
      "{'loss': 3.1352, 'grad_norm': 15.004830360412598, 'learning_rate': 4.584043299589056e-06, 'epoch': 0.08319134008218904}\n",
      "{'loss': 2.6243, 'grad_norm': 5.675110340118408, 'learning_rate': 4.57903177307808e-06, 'epoch': 0.08419364538438408}\n",
      "{'loss': 2.5757, 'grad_norm': 4.311030387878418, 'learning_rate': 4.574020246567104e-06, 'epoch': 0.08519595068657913}\n",
      "{'loss': 3.1773, 'grad_norm': 7.3154802322387695, 'learning_rate': 4.5690087200561296e-06, 'epoch': 0.08619825598877418}\n",
      "{'loss': 2.7758, 'grad_norm': 13.533498764038086, 'learning_rate': 4.563997193545155e-06, 'epoch': 0.08720056129096923}\n",
      "{'loss': 3.0548, 'grad_norm': 16.213830947875977, 'learning_rate': 4.558985667034179e-06, 'epoch': 0.08820286659316427}\n",
      "{'loss': 3.6739, 'grad_norm': 14.578377723693848, 'learning_rate': 4.5539741405232035e-06, 'epoch': 0.08920517189535933}\n",
      "{'loss': 3.4602, 'grad_norm': 11.874933242797852, 'learning_rate': 4.548962614012229e-06, 'epoch': 0.09020747719755437}\n",
      "{'loss': 3.3064, 'grad_norm': 17.114744186401367, 'learning_rate': 4.543951087501253e-06, 'epoch': 0.09120978249974943}\n",
      "{'loss': 2.9834, 'grad_norm': 13.012796401977539, 'learning_rate': 4.538939560990278e-06, 'epoch': 0.09221208780194447}\n",
      "{'loss': 3.5691, 'grad_norm': 8.512693405151367, 'learning_rate': 4.533928034479303e-06, 'epoch': 0.09321439310413952}\n",
      "{'loss': 2.8793, 'grad_norm': 16.488815307617188, 'learning_rate': 4.528916507968327e-06, 'epoch': 0.09421669840633456}\n",
      "{'loss': 3.6191, 'grad_norm': 19.867460250854492, 'learning_rate': 4.523904981457352e-06, 'epoch': 0.09521900370852962}\n",
      "{'loss': 3.1295, 'grad_norm': 6.652237892150879, 'learning_rate': 4.518893454946377e-06, 'epoch': 0.09622130901072466}\n",
      "{'loss': 2.8984, 'grad_norm': 4.593132019042969, 'learning_rate': 4.513881928435402e-06, 'epoch': 0.09722361431291972}\n",
      "{'loss': 2.6765, 'grad_norm': 10.29165267944336, 'learning_rate': 4.508870401924427e-06, 'epoch': 0.09822591961511476}\n",
      "{'loss': 2.7615, 'grad_norm': 13.023872375488281, 'learning_rate': 4.503858875413451e-06, 'epoch': 0.09922822491730982}\n",
      "{'loss': 2.9134, 'grad_norm': 15.363365173339844, 'learning_rate': 4.498847348902476e-06, 'epoch': 0.10023053021950486}\n",
      "{'loss': 2.6742, 'grad_norm': 0.0, 'learning_rate': 4.493835822391501e-06, 'epoch': 0.10123283552169991}\n",
      "{'loss': 3.2308, 'grad_norm': 21.409130096435547, 'learning_rate': 4.488824295880525e-06, 'epoch': 0.10223514082389495}\n",
      "{'loss': 3.0772, 'grad_norm': 11.833795547485352, 'learning_rate': 4.4838127693695505e-06, 'epoch': 0.10323744612609001}\n",
      "{'loss': 2.7524, 'grad_norm': 20.818510055541992, 'learning_rate': 4.478801242858576e-06, 'epoch': 0.10423975142828505}\n",
      "{'loss': 2.9627, 'grad_norm': 7.889997482299805, 'learning_rate': 4.473789716347599e-06, 'epoch': 0.10524205673048011}\n",
      "{'loss': 2.7903, 'grad_norm': 6.274357795715332, 'learning_rate': 4.4687781898366245e-06, 'epoch': 0.10624436203267515}\n",
      "{'loss': 2.5362, 'grad_norm': 8.476191520690918, 'learning_rate': 4.46376666332565e-06, 'epoch': 0.1072466673348702}\n",
      "{'loss': 2.8334, 'grad_norm': 28.34550666809082, 'learning_rate': 4.458755136814674e-06, 'epoch': 0.10824897263706525}\n",
      "{'loss': 2.1387, 'grad_norm': 5.0597734451293945, 'learning_rate': 4.453743610303699e-06, 'epoch': 0.1092512779392603}\n",
      "{'loss': 3.485, 'grad_norm': 9.36784839630127, 'learning_rate': 4.448732083792724e-06, 'epoch': 0.11025358324145534}\n",
      "{'loss': 3.0253, 'grad_norm': 3.4271440505981445, 'learning_rate': 4.443720557281748e-06, 'epoch': 0.1112558885436504}\n",
      "{'loss': 2.7743, 'grad_norm': 12.725995063781738, 'learning_rate': 4.438709030770773e-06, 'epoch': 0.11225819384584544}\n",
      "{'loss': 3.2889, 'grad_norm': 25.69308090209961, 'learning_rate': 4.4336975042597976e-06, 'epoch': 0.1132604991480405}\n",
      "{'loss': 2.9271, 'grad_norm': 18.043773651123047, 'learning_rate': 4.428685977748823e-06, 'epoch': 0.11426280445023554}\n",
      "{'loss': 2.4145, 'grad_norm': 0.0, 'learning_rate': 4.423674451237848e-06, 'epoch': 0.1152651097524306}\n",
      "{'loss': 2.6969, 'grad_norm': 18.943771362304688, 'learning_rate': 4.418662924726872e-06, 'epoch': 0.11626741505462564}\n",
      "{'loss': 2.7173, 'grad_norm': 21.68743133544922, 'learning_rate': 4.413651398215897e-06, 'epoch': 0.11726972035682069}\n",
      "{'loss': 3.2101, 'grad_norm': 23.296852111816406, 'learning_rate': 4.408639871704922e-06, 'epoch': 0.11827202565901573}\n",
      "{'loss': 3.2465, 'grad_norm': 28.659685134887695, 'learning_rate': 4.403628345193946e-06, 'epoch': 0.11927433096121079}\n",
      "{'loss': 2.8739, 'grad_norm': 11.179849624633789, 'learning_rate': 4.3986168186829715e-06, 'epoch': 0.12027663626340583}\n",
      "{'loss': 2.9874, 'grad_norm': 6.878505229949951, 'learning_rate': 4.393605292171996e-06, 'epoch': 0.12127894156560089}\n",
      "{'loss': 2.3946, 'grad_norm': 5.2900071144104, 'learning_rate': 4.38859376566102e-06, 'epoch': 0.12228124686779593}\n",
      "{'loss': 2.415, 'grad_norm': 9.006319046020508, 'learning_rate': 4.3835822391500454e-06, 'epoch': 0.12328355216999098}\n",
      "{'loss': 3.2532, 'grad_norm': 13.63676643371582, 'learning_rate': 4.378570712639071e-06, 'epoch': 0.12428585747218603}\n",
      "{'loss': 2.662, 'grad_norm': 5.494865417480469, 'learning_rate': 4.373559186128095e-06, 'epoch': 0.12528816277438107}\n",
      "{'loss': 2.671, 'grad_norm': 6.255380153656006, 'learning_rate': 4.368547659617119e-06, 'epoch': 0.12629046807657612}\n",
      "{'loss': 3.313, 'grad_norm': 11.414759635925293, 'learning_rate': 4.3635361331061446e-06, 'epoch': 0.12729277337877118}\n",
      "{'loss': 2.5609, 'grad_norm': 21.653955459594727, 'learning_rate': 4.358524606595169e-06, 'epoch': 0.12829507868096623}\n",
      "{'loss': 3.2046, 'grad_norm': 14.766209602355957, 'learning_rate': 4.353513080084194e-06, 'epoch': 0.12929738398316126}\n",
      "{'loss': 2.4248, 'grad_norm': 9.26445484161377, 'learning_rate': 4.3485015535732185e-06, 'epoch': 0.13029968928535632}\n",
      "{'loss': 2.6248, 'grad_norm': 8.0296630859375, 'learning_rate': 4.343490027062244e-06, 'epoch': 0.13130199458755137}\n",
      "{'loss': 2.7426, 'grad_norm': 11.973458290100098, 'learning_rate': 4.338478500551268e-06, 'epoch': 0.13230429988974643}\n",
      "{'loss': 2.5824, 'grad_norm': 15.92553997039795, 'learning_rate': 4.333466974040293e-06, 'epoch': 0.13330660519194146}\n",
      "{'loss': 2.1632, 'grad_norm': 8.332880973815918, 'learning_rate': 4.328455447529318e-06, 'epoch': 0.1343089104941365}\n",
      "{'loss': 3.1578, 'grad_norm': 14.239779472351074, 'learning_rate': 4.323443921018343e-06, 'epoch': 0.13531121579633157}\n",
      "{'loss': 2.6739, 'grad_norm': 17.614051818847656, 'learning_rate': 4.318432394507367e-06, 'epoch': 0.13631352109852662}\n",
      "{'loss': 2.8946, 'grad_norm': 20.68585205078125, 'learning_rate': 4.313420867996392e-06, 'epoch': 0.13731582640072165}\n",
      "{'loss': 3.2325, 'grad_norm': 17.858592987060547, 'learning_rate': 4.308409341485417e-06, 'epoch': 0.1383181317029167}\n",
      "{'loss': 3.2313, 'grad_norm': 15.197599411010742, 'learning_rate': 4.303397814974441e-06, 'epoch': 0.13932043700511176}\n",
      "{'loss': 2.5606, 'grad_norm': 9.019084930419922, 'learning_rate': 4.298386288463466e-06, 'epoch': 0.14032274230730682}\n",
      "{'loss': 3.4061, 'grad_norm': 10.548943519592285, 'learning_rate': 4.293374761952492e-06, 'epoch': 0.14132504760950185}\n",
      "{'loss': 2.5529, 'grad_norm': 10.891175270080566, 'learning_rate': 4.288363235441516e-06, 'epoch': 0.1423273529116969}\n",
      "{'loss': 2.3911, 'grad_norm': 5.027220726013184, 'learning_rate': 4.28335170893054e-06, 'epoch': 0.14332965821389196}\n",
      "{'loss': 2.8576, 'grad_norm': 37.163875579833984, 'learning_rate': 4.2783401824195655e-06, 'epoch': 0.144331963516087}\n",
      "{'loss': 2.7562, 'grad_norm': 17.1549129486084, 'learning_rate': 4.27332865590859e-06, 'epoch': 0.14533426881828204}\n",
      "{'loss': 2.3402, 'grad_norm': 20.474353790283203, 'learning_rate': 4.268317129397615e-06, 'epoch': 0.1463365741204771}\n",
      "{'loss': 3.0725, 'grad_norm': 12.425606727600098, 'learning_rate': 4.2633056028866395e-06, 'epoch': 0.14733887942267215}\n",
      "{'loss': 2.9544, 'grad_norm': 29.582544326782227, 'learning_rate': 4.258294076375664e-06, 'epoch': 0.14834118472486718}\n",
      "{'loss': 2.8081, 'grad_norm': 13.806907653808594, 'learning_rate': 4.253282549864689e-06, 'epoch': 0.14934349002706224}\n",
      "{'loss': 2.7011, 'grad_norm': 16.3719539642334, 'learning_rate': 4.248271023353714e-06, 'epoch': 0.1503457953292573}\n",
      "{'loss': 2.8968, 'grad_norm': 22.866514205932617, 'learning_rate': 4.243259496842739e-06, 'epoch': 0.15134810063145235}\n",
      "{'loss': 2.7794, 'grad_norm': 8.860776901245117, 'learning_rate': 4.238247970331764e-06, 'epoch': 0.15235040593364738}\n",
      "{'loss': 2.9582, 'grad_norm': 14.605880737304688, 'learning_rate': 4.233236443820788e-06, 'epoch': 0.15335271123584243}\n",
      "{'loss': 2.8998, 'grad_norm': 9.4662504196167, 'learning_rate': 4.2282249173098126e-06, 'epoch': 0.1543550165380375}\n",
      "{'loss': 2.3534, 'grad_norm': 17.783184051513672, 'learning_rate': 4.223213390798838e-06, 'epoch': 0.15535732184023254}\n",
      "{'loss': 2.5031, 'grad_norm': 13.571645736694336, 'learning_rate': 4.218201864287862e-06, 'epoch': 0.15635962714242757}\n",
      "{'loss': 2.0766, 'grad_norm': 12.388358116149902, 'learning_rate': 4.213190337776887e-06, 'epoch': 0.15736193244462263}\n",
      "{'loss': 2.978, 'grad_norm': 20.709562301635742, 'learning_rate': 4.2081788112659126e-06, 'epoch': 0.15836423774681768}\n",
      "{'loss': 2.2875, 'grad_norm': 7.70565128326416, 'learning_rate': 4.203167284754937e-06, 'epoch': 0.15936654304901274}\n",
      "{'loss': 3.5631, 'grad_norm': 18.39501190185547, 'learning_rate': 4.198155758243961e-06, 'epoch': 0.16036884835120777}\n",
      "{'loss': 2.4181, 'grad_norm': 10.674454689025879, 'learning_rate': 4.1931442317329865e-06, 'epoch': 0.16137115365340282}\n",
      "{'loss': 2.2695, 'grad_norm': 7.855875015258789, 'learning_rate': 4.188132705222011e-06, 'epoch': 0.16237345895559788}\n",
      "{'loss': 2.428, 'grad_norm': 10.730324745178223, 'learning_rate': 4.183121178711036e-06, 'epoch': 0.16337576425779293}\n",
      "{'loss': 3.1236, 'grad_norm': 2.053159236907959, 'learning_rate': 4.1781096522000604e-06, 'epoch': 0.16437806955998796}\n",
      "{'loss': 2.7911, 'grad_norm': 10.911821365356445, 'learning_rate': 4.173098125689085e-06, 'epoch': 0.16538037486218302}\n",
      "{'loss': 2.3941, 'grad_norm': 11.400936126708984, 'learning_rate': 4.16808659917811e-06, 'epoch': 0.16638268016437807}\n",
      "{'loss': 2.1393, 'grad_norm': 14.897773742675781, 'learning_rate': 4.163075072667135e-06, 'epoch': 0.16738498546657313}\n",
      "{'loss': 2.6103, 'grad_norm': 6.98033332824707, 'learning_rate': 4.15806354615616e-06, 'epoch': 0.16838729076876816}\n",
      "{'loss': 3.3925, 'grad_norm': 14.997917175292969, 'learning_rate': 4.153052019645184e-06, 'epoch': 0.1693895960709632}\n",
      "{'loss': 2.6919, 'grad_norm': 10.978208541870117, 'learning_rate': 4.148040493134209e-06, 'epoch': 0.17039190137315827}\n",
      "{'loss': 2.4288, 'grad_norm': 7.061734676361084, 'learning_rate': 4.1430289666232335e-06, 'epoch': 0.17139420667535332}\n",
      "{'loss': 2.6813, 'grad_norm': 41.351593017578125, 'learning_rate': 4.138017440112259e-06, 'epoch': 0.17239651197754835}\n",
      "{'loss': 3.1404, 'grad_norm': 17.332990646362305, 'learning_rate': 4.133005913601283e-06, 'epoch': 0.1733988172797434}\n",
      "{'loss': 2.1298, 'grad_norm': 12.12114143371582, 'learning_rate': 4.127994387090308e-06, 'epoch': 0.17440112258193846}\n",
      "{'loss': 2.8234, 'grad_norm': 8.548626899719238, 'learning_rate': 4.122982860579333e-06, 'epoch': 0.17540342788413352}\n",
      "{'loss': 2.6199, 'grad_norm': 1.856613039970398, 'learning_rate': 4.117971334068358e-06, 'epoch': 0.17640573318632854}\n",
      "{'loss': 2.1683, 'grad_norm': 27.210851669311523, 'learning_rate': 4.112959807557382e-06, 'epoch': 0.1774080384885236}\n",
      "{'loss': 2.6218, 'grad_norm': 18.473268508911133, 'learning_rate': 4.1079482810464075e-06, 'epoch': 0.17841034379071866}\n",
      "{'loss': 2.4364, 'grad_norm': 20.91373062133789, 'learning_rate': 4.102936754535432e-06, 'epoch': 0.1794126490929137}\n",
      "{'loss': 2.3624, 'grad_norm': 28.635684967041016, 'learning_rate': 4.097925228024456e-06, 'epoch': 0.18041495439510874}\n",
      "{'loss': 2.1545, 'grad_norm': 6.8819780349731445, 'learning_rate': 4.092913701513481e-06, 'epoch': 0.1814172596973038}\n",
      "{'loss': 2.799, 'grad_norm': 15.856755256652832, 'learning_rate': 4.087902175002506e-06, 'epoch': 0.18241956499949885}\n",
      "{'loss': 1.8008, 'grad_norm': 4.326847553253174, 'learning_rate': 4.082890648491531e-06, 'epoch': 0.1834218703016939}\n",
      "{'loss': 2.8546, 'grad_norm': 32.542518615722656, 'learning_rate': 4.077879121980556e-06, 'epoch': 0.18442417560388893}\n",
      "{'loss': 3.0525, 'grad_norm': 24.713563919067383, 'learning_rate': 4.07286759546958e-06, 'epoch': 0.185426480906084}\n",
      "{'loss': 2.7532, 'grad_norm': 21.750818252563477, 'learning_rate': 4.067856068958605e-06, 'epoch': 0.18642878620827905}\n",
      "{'loss': 2.971, 'grad_norm': 9.428975105285645, 'learning_rate': 4.06284454244763e-06, 'epoch': 0.1874310915104741}\n",
      "{'loss': 3.0771, 'grad_norm': 15.823325157165527, 'learning_rate': 4.0578330159366545e-06, 'epoch': 0.18843339681266913}\n",
      "{'loss': 2.992, 'grad_norm': 29.574909210205078, 'learning_rate': 4.05282148942568e-06, 'epoch': 0.18943570211486419}\n",
      "{'loss': 2.5067, 'grad_norm': 12.429540634155273, 'learning_rate': 4.047809962914704e-06, 'epoch': 0.19043800741705924}\n",
      "{'loss': 2.6586, 'grad_norm': 40.54244613647461, 'learning_rate': 4.042798436403728e-06, 'epoch': 0.1914403127192543}\n",
      "{'loss': 2.838, 'grad_norm': 15.948518753051758, 'learning_rate': 4.037786909892754e-06, 'epoch': 0.19244261802144932}\n",
      "{'loss': 2.288, 'grad_norm': 52.22605514526367, 'learning_rate': 4.032775383381779e-06, 'epoch': 0.19344492332364438}\n",
      "{'loss': 2.4951, 'grad_norm': 12.324312210083008, 'learning_rate': 4.027763856870803e-06, 'epoch': 0.19444722862583944}\n",
      "{'loss': 2.2775, 'grad_norm': 37.24799346923828, 'learning_rate': 4.022752330359828e-06, 'epoch': 0.1954495339280345}\n",
      "{'loss': 2.1436, 'grad_norm': 20.013227462768555, 'learning_rate': 4.017740803848853e-06, 'epoch': 0.19645183923022952}\n",
      "{'loss': 2.9535, 'grad_norm': 23.625629425048828, 'learning_rate': 4.012729277337877e-06, 'epoch': 0.19745414453242457}\n",
      "{'loss': 3.4887, 'grad_norm': 18.920310974121094, 'learning_rate': 4.007717750826902e-06, 'epoch': 0.19845644983461963}\n",
      "{'loss': 2.6139, 'grad_norm': 18.034053802490234, 'learning_rate': 4.002706224315927e-06, 'epoch': 0.19945875513681469}\n",
      "{'loss': 2.3703, 'grad_norm': 28.683914184570312, 'learning_rate': 3.997694697804952e-06, 'epoch': 0.20046106043900971}\n",
      "{'loss': 3.1022, 'grad_norm': 19.503952026367188, 'learning_rate': 3.992683171293976e-06, 'epoch': 0.20146336574120477}\n",
      "{'loss': 2.4647, 'grad_norm': 17.635578155517578, 'learning_rate': 3.987671644783001e-06, 'epoch': 0.20246567104339983}\n",
      "{'loss': 2.3756, 'grad_norm': 21.275135040283203, 'learning_rate': 3.982660118272026e-06, 'epoch': 0.20346797634559488}\n",
      "{'loss': 2.9138, 'grad_norm': 21.48904800415039, 'learning_rate': 3.977648591761051e-06, 'epoch': 0.2044702816477899}\n",
      "{'loss': 3.4647, 'grad_norm': 20.05755043029785, 'learning_rate': 3.9726370652500754e-06, 'epoch': 0.20547258694998496}\n",
      "{'loss': 2.3973, 'grad_norm': 12.06486701965332, 'learning_rate': 3.967625538739101e-06, 'epoch': 0.20647489225218002}\n",
      "{'loss': 2.8612, 'grad_norm': 12.44859790802002, 'learning_rate': 3.962614012228125e-06, 'epoch': 0.20747719755437508}\n",
      "{'loss': 2.6548, 'grad_norm': 13.510515213012695, 'learning_rate': 3.957602485717149e-06, 'epoch': 0.2084795028565701}\n",
      "{'loss': 2.5582, 'grad_norm': 14.618661880493164, 'learning_rate': 3.952590959206175e-06, 'epoch': 0.20948180815876516}\n",
      "{'loss': 3.107, 'grad_norm': 8.877166748046875, 'learning_rate': 3.9475794326952e-06, 'epoch': 0.21048411346096021}\n",
      "{'loss': 1.8497, 'grad_norm': 18.593732833862305, 'learning_rate': 3.942567906184224e-06, 'epoch': 0.21148641876315527}\n",
      "{'loss': 2.3289, 'grad_norm': 12.953186988830566, 'learning_rate': 3.9375563796732485e-06, 'epoch': 0.2124887240653503}\n",
      "{'loss': 3.1075, 'grad_norm': 12.543722152709961, 'learning_rate': 3.932544853162274e-06, 'epoch': 0.21349102936754535}\n",
      "{'loss': 2.8118, 'grad_norm': 18.57921600341797, 'learning_rate': 3.927533326651298e-06, 'epoch': 0.2144933346697404}\n",
      "{'loss': 2.3016, 'grad_norm': 17.77098846435547, 'learning_rate': 3.922521800140323e-06, 'epoch': 0.21549563997193547}\n",
      "{'loss': 2.7869, 'grad_norm': 9.438447952270508, 'learning_rate': 3.917510273629348e-06, 'epoch': 0.2164979452741305}\n",
      "{'loss': 3.0637, 'grad_norm': 8.47287654876709, 'learning_rate': 3.912498747118373e-06, 'epoch': 0.21750025057632555}\n",
      "{'loss': 2.4031, 'grad_norm': 20.092540740966797, 'learning_rate': 3.907487220607397e-06, 'epoch': 0.2185025558785206}\n",
      "{'loss': 1.9689, 'grad_norm': 0.0, 'learning_rate': 3.902475694096422e-06, 'epoch': 0.21950486118071563}\n",
      "{'loss': 2.3302, 'grad_norm': 10.41273021697998, 'learning_rate': 3.897464167585447e-06, 'epoch': 0.2205071664829107}\n",
      "{'loss': 2.507, 'grad_norm': 2.0526912212371826, 'learning_rate': 3.892452641074472e-06, 'epoch': 0.22150947178510574}\n",
      "{'loss': 2.5822, 'grad_norm': 18.367738723754883, 'learning_rate': 3.887441114563496e-06, 'epoch': 0.2225117770873008}\n",
      "{'loss': 2.201, 'grad_norm': 14.558588027954102, 'learning_rate': 3.882429588052521e-06, 'epoch': 0.22351408238949583}\n",
      "{'loss': 2.8463, 'grad_norm': 14.36070728302002, 'learning_rate': 3.877418061541546e-06, 'epoch': 0.22451638769169088}\n",
      "{'loss': 2.9318, 'grad_norm': 12.163250923156738, 'learning_rate': 3.87240653503057e-06, 'epoch': 0.22551869299388594}\n",
      "{'loss': 2.6053, 'grad_norm': 17.715553283691406, 'learning_rate': 3.8673950085195955e-06, 'epoch': 0.226520998296081}\n",
      "{'loss': 3.3473, 'grad_norm': 19.053810119628906, 'learning_rate': 3.862383482008621e-06, 'epoch': 0.22752330359827602}\n",
      "{'loss': 2.3254, 'grad_norm': 13.400337219238281, 'learning_rate': 3.857371955497644e-06, 'epoch': 0.22852560890047108}\n",
      "{'loss': 1.9509, 'grad_norm': 13.803082466125488, 'learning_rate': 3.8523604289866695e-06, 'epoch': 0.22952791420266613}\n",
      "{'loss': 2.0688, 'grad_norm': 28.6187801361084, 'learning_rate': 3.847348902475695e-06, 'epoch': 0.2305302195048612}\n",
      "{'loss': 2.5318, 'grad_norm': 4.503389358520508, 'learning_rate': 3.842337375964719e-06, 'epoch': 0.23153252480705622}\n",
      "{'loss': 2.6524, 'grad_norm': 14.897547721862793, 'learning_rate': 3.837325849453744e-06, 'epoch': 0.23253483010925127}\n",
      "{'loss': 2.3939, 'grad_norm': 11.014853477478027, 'learning_rate': 3.832314322942769e-06, 'epoch': 0.23353713541144633}\n",
      "{'loss': 2.1878, 'grad_norm': 2.2811484336853027, 'learning_rate': 3.827302796431793e-06, 'epoch': 0.23453944071364138}\n",
      "{'loss': 2.2353, 'grad_norm': 22.472610473632812, 'learning_rate': 3.822291269920818e-06, 'epoch': 0.2355417460158364}\n",
      "{'loss': 2.2663, 'grad_norm': 15.472726821899414, 'learning_rate': 3.8172797434098426e-06, 'epoch': 0.23654405131803147}\n",
      "{'loss': 2.9838, 'grad_norm': 16.61904525756836, 'learning_rate': 3.8122682168988678e-06, 'epoch': 0.23754635662022652}\n",
      "{'loss': 1.9703, 'grad_norm': 25.185678482055664, 'learning_rate': 3.8072566903878926e-06, 'epoch': 0.23854866192242158}\n",
      "{'loss': 2.1898, 'grad_norm': 26.767135620117188, 'learning_rate': 3.802245163876917e-06, 'epoch': 0.2395509672246166}\n",
      "{'loss': 2.8914, 'grad_norm': 29.49675941467285, 'learning_rate': 3.7972336373659417e-06, 'epoch': 0.24055327252681166}\n",
      "{'loss': 2.5425, 'grad_norm': 10.714730262756348, 'learning_rate': 3.792222110854967e-06, 'epoch': 0.24155557782900672}\n",
      "{'loss': 2.3021, 'grad_norm': 36.062255859375, 'learning_rate': 3.7872105843439917e-06, 'epoch': 0.24255788313120177}\n",
      "{'loss': 2.0099, 'grad_norm': 14.454582214355469, 'learning_rate': 3.7821990578330165e-06, 'epoch': 0.2435601884333968}\n",
      "{'loss': 2.7573, 'grad_norm': 11.624784469604492, 'learning_rate': 3.777187531322041e-06, 'epoch': 0.24456249373559186}\n",
      "{'loss': 2.1819, 'grad_norm': 19.5200138092041, 'learning_rate': 3.7721760048110657e-06, 'epoch': 0.2455647990377869}\n",
      "{'loss': 2.0964, 'grad_norm': 0.0, 'learning_rate': 3.7671644783000904e-06, 'epoch': 0.24656710433998197}\n",
      "{'loss': 2.4171, 'grad_norm': 15.402715682983398, 'learning_rate': 3.7621529517891152e-06, 'epoch': 0.247569409642177}\n",
      "{'loss': 2.6629, 'grad_norm': 20.36033821105957, 'learning_rate': 3.75714142527814e-06, 'epoch': 0.24857171494437205}\n",
      "{'loss': 2.0373, 'grad_norm': 19.324745178222656, 'learning_rate': 3.7521298987671652e-06, 'epoch': 0.2495740202465671}\n",
      "{'loss': 2.1845, 'grad_norm': 21.94066619873047, 'learning_rate': 3.747118372256189e-06, 'epoch': 0.25057632554876214}\n",
      "{'loss': 2.4905, 'grad_norm': 12.119895935058594, 'learning_rate': 3.7421068457452144e-06, 'epoch': 0.2515786308509572}\n",
      "{'loss': 2.3047, 'grad_norm': 8.012279510498047, 'learning_rate': 3.737095319234239e-06, 'epoch': 0.25258093615315225}\n",
      "{'loss': 2.6395, 'grad_norm': 10.973414421081543, 'learning_rate': 3.732083792723264e-06, 'epoch': 0.2535832414553473}\n",
      "{'loss': 2.0697, 'grad_norm': 33.06158447265625, 'learning_rate': 3.7270722662122887e-06, 'epoch': 0.25458554675754236}\n",
      "{'loss': 3.1465, 'grad_norm': 30.859888076782227, 'learning_rate': 3.722060739701313e-06, 'epoch': 0.2555878520597374}\n",
      "{'loss': 2.1475, 'grad_norm': 2.394641637802124, 'learning_rate': 3.717049213190338e-06, 'epoch': 0.25659015736193247}\n",
      "{'loss': 2.0663, 'grad_norm': 16.37485122680664, 'learning_rate': 3.7120376866793627e-06, 'epoch': 0.2575924626641275}\n",
      "{'loss': 1.9592, 'grad_norm': 29.766584396362305, 'learning_rate': 3.707026160168388e-06, 'epoch': 0.2585947679663225}\n",
      "{'loss': 2.4171, 'grad_norm': 40.4245491027832, 'learning_rate': 3.7020146336574127e-06, 'epoch': 0.2595970732685176}\n",
      "{'loss': 2.4924, 'grad_norm': 18.814735412597656, 'learning_rate': 3.697003107146437e-06, 'epoch': 0.26059937857071264}\n",
      "{'loss': 2.0261, 'grad_norm': 18.181297302246094, 'learning_rate': 3.691991580635462e-06, 'epoch': 0.26160168387290766}\n",
      "{'loss': 1.9185, 'grad_norm': 15.180625915527344, 'learning_rate': 3.6869800541244866e-06, 'epoch': 0.26260398917510275}\n",
      "{'loss': 1.435, 'grad_norm': 12.613743782043457, 'learning_rate': 3.6819685276135114e-06, 'epoch': 0.2636062944772978}\n",
      "{'loss': 2.2276, 'grad_norm': 15.839550018310547, 'learning_rate': 3.676957001102536e-06, 'epoch': 0.26460859977949286}\n",
      "{'loss': 3.0129, 'grad_norm': 39.97519302368164, 'learning_rate': 3.671945474591561e-06, 'epoch': 0.2656109050816879}\n",
      "{'loss': 2.6534, 'grad_norm': 26.082740783691406, 'learning_rate': 3.6669339480805853e-06, 'epoch': 0.2666132103838829}\n",
      "{'loss': 2.4372, 'grad_norm': 11.70413589477539, 'learning_rate': 3.66192242156961e-06, 'epoch': 0.267615515686078}\n",
      "{'loss': 2.1166, 'grad_norm': 32.92638397216797, 'learning_rate': 3.6569108950586353e-06, 'epoch': 0.268617820988273}\n",
      "{'loss': 2.243, 'grad_norm': 22.71257781982422, 'learning_rate': 3.65189936854766e-06, 'epoch': 0.26962012629046805}\n",
      "{'loss': 2.1757, 'grad_norm': 28.506853103637695, 'learning_rate': 3.646887842036685e-06, 'epoch': 0.27062243159266314}\n",
      "{'loss': 2.5293, 'grad_norm': 19.121614456176758, 'learning_rate': 3.6418763155257093e-06, 'epoch': 0.27162473689485817}\n",
      "{'loss': 2.2471, 'grad_norm': 13.164158821105957, 'learning_rate': 3.636864789014734e-06, 'epoch': 0.27262704219705325}\n",
      "{'loss': 1.6525, 'grad_norm': 15.67569351196289, 'learning_rate': 3.631853262503759e-06, 'epoch': 0.2736293474992483}\n",
      "{'loss': 1.7179, 'grad_norm': 29.47624969482422, 'learning_rate': 3.6268417359927836e-06, 'epoch': 0.2746316528014433}\n",
      "{'loss': 2.1468, 'grad_norm': 32.072330474853516, 'learning_rate': 3.6218302094818084e-06, 'epoch': 0.2756339581036384}\n",
      "{'loss': 1.9808, 'grad_norm': 15.926989555358887, 'learning_rate': 3.616818682970833e-06, 'epoch': 0.2766362634058334}\n",
      "{'loss': 1.3496, 'grad_norm': 16.111255645751953, 'learning_rate': 3.611807156459858e-06, 'epoch': 0.27763856870802844}\n",
      "{'loss': 1.6681, 'grad_norm': 27.538888931274414, 'learning_rate': 3.6067956299488828e-06, 'epoch': 0.2786408740102235}\n",
      "{'loss': 1.9898, 'grad_norm': 24.709707260131836, 'learning_rate': 3.6017841034379076e-06, 'epoch': 0.27964317931241855}\n",
      "{'loss': 1.7931, 'grad_norm': 14.055910110473633, 'learning_rate': 3.5967725769269324e-06, 'epoch': 0.28064548461461364}\n",
      "{'loss': 2.0673, 'grad_norm': 30.71940803527832, 'learning_rate': 3.591761050415957e-06, 'epoch': 0.28164778991680867}\n",
      "{'loss': 1.9324, 'grad_norm': 9.41800594329834, 'learning_rate': 3.5867495239049815e-06, 'epoch': 0.2826500952190037}\n",
      "{'loss': 2.1829, 'grad_norm': 13.495977401733398, 'learning_rate': 3.5817379973940063e-06, 'epoch': 0.2836524005211988}\n",
      "{'loss': 2.6665, 'grad_norm': 15.569901466369629, 'learning_rate': 3.576726470883031e-06, 'epoch': 0.2846547058233938}\n",
      "{'loss': 2.045, 'grad_norm': 33.03015899658203, 'learning_rate': 3.5717149443720563e-06, 'epoch': 0.28565701112558883}\n",
      "{'loss': 2.8711, 'grad_norm': 11.3110933303833, 'learning_rate': 3.566703417861081e-06, 'epoch': 0.2866593164277839}\n",
      "{'loss': 2.2564, 'grad_norm': 14.534026145935059, 'learning_rate': 3.5616918913501054e-06, 'epoch': 0.28766162172997894}\n",
      "{'loss': 2.4259, 'grad_norm': 21.971529006958008, 'learning_rate': 3.5566803648391302e-06, 'epoch': 0.288663927032174}\n",
      "{'loss': 1.6697, 'grad_norm': 11.098262786865234, 'learning_rate': 3.551668838328155e-06, 'epoch': 0.28966623233436906}\n",
      "{'loss': 3.0407, 'grad_norm': 6.379810810089111, 'learning_rate': 3.54665731181718e-06, 'epoch': 0.2906685376365641}\n",
      "{'loss': 2.4561, 'grad_norm': 0.0, 'learning_rate': 3.5416457853062046e-06, 'epoch': 0.29167084293875917}\n",
      "{'loss': 2.0822, 'grad_norm': 19.363374710083008, 'learning_rate': 3.5366342587952294e-06, 'epoch': 0.2926731482409542}\n",
      "{'loss': 2.3926, 'grad_norm': 14.03660774230957, 'learning_rate': 3.5316227322842537e-06, 'epoch': 0.2936754535431492}\n",
      "{'loss': 1.8882, 'grad_norm': 29.145448684692383, 'learning_rate': 3.526611205773279e-06, 'epoch': 0.2946777588453443}\n",
      "{'loss': 2.1899, 'grad_norm': 12.068282127380371, 'learning_rate': 3.5215996792623037e-06, 'epoch': 0.29568006414753933}\n",
      "{'loss': 1.9973, 'grad_norm': 18.928239822387695, 'learning_rate': 3.5165881527513285e-06, 'epoch': 0.29668236944973436}\n",
      "{'loss': 2.3401, 'grad_norm': 10.351922988891602, 'learning_rate': 3.5115766262403533e-06, 'epoch': 0.29768467475192945}\n",
      "{'loss': 2.5783, 'grad_norm': 24.263465881347656, 'learning_rate': 3.5065650997293777e-06, 'epoch': 0.2986869800541245}\n",
      "{'loss': 2.2583, 'grad_norm': 11.917476654052734, 'learning_rate': 3.5015535732184025e-06, 'epoch': 0.29968928535631956}\n",
      "{'loss': 2.1321, 'grad_norm': 19.813915252685547, 'learning_rate': 3.4965420467074273e-06, 'epoch': 0.3006915906585146}\n",
      "{'loss': 2.3801, 'grad_norm': 23.054725646972656, 'learning_rate': 3.491530520196452e-06, 'epoch': 0.3016938959607096}\n",
      "{'loss': 2.3437, 'grad_norm': 21.26167869567871, 'learning_rate': 3.4865189936854773e-06, 'epoch': 0.3026962012629047}\n",
      "{'loss': 1.5914, 'grad_norm': 23.158634185791016, 'learning_rate': 3.481507467174501e-06, 'epoch': 0.3036985065650997}\n",
      "{'loss': 1.3177, 'grad_norm': 10.779581069946289, 'learning_rate': 3.4764959406635264e-06, 'epoch': 0.30470081186729475}\n",
      "{'loss': 2.1183, 'grad_norm': 13.185844421386719, 'learning_rate': 3.471484414152551e-06, 'epoch': 0.30570311716948984}\n",
      "{'loss': 1.778, 'grad_norm': 12.728538513183594, 'learning_rate': 3.466472887641576e-06, 'epoch': 0.30670542247168486}\n",
      "{'loss': 2.2613, 'grad_norm': 21.242795944213867, 'learning_rate': 3.4614613611306008e-06, 'epoch': 0.30770772777387995}\n",
      "{'loss': 1.6295, 'grad_norm': 19.256669998168945, 'learning_rate': 3.4564498346196256e-06, 'epoch': 0.308710033076075}\n",
      "{'loss': 1.772, 'grad_norm': 3.097876787185669, 'learning_rate': 3.45143830810865e-06, 'epoch': 0.30971233837827}\n",
      "{'loss': 1.811, 'grad_norm': 8.594244003295898, 'learning_rate': 3.4464267815976747e-06, 'epoch': 0.3107146436804651}\n",
      "{'loss': 1.6156, 'grad_norm': 12.043975830078125, 'learning_rate': 3.4414152550867e-06, 'epoch': 0.3117169489826601}\n",
      "{'loss': 2.4745, 'grad_norm': 28.102096557617188, 'learning_rate': 3.4364037285757247e-06, 'epoch': 0.31271925428485514}\n",
      "{'loss': 1.7537, 'grad_norm': 12.377902030944824, 'learning_rate': 3.4313922020647495e-06, 'epoch': 0.3137215595870502}\n",
      "{'loss': 1.3582, 'grad_norm': 34.22419357299805, 'learning_rate': 3.426380675553774e-06, 'epoch': 0.31472386488924525}\n",
      "{'loss': 1.8131, 'grad_norm': 30.44569969177246, 'learning_rate': 3.4213691490427986e-06, 'epoch': 0.31572617019144034}\n",
      "{'loss': 1.5561, 'grad_norm': 10.474544525146484, 'learning_rate': 3.4163576225318234e-06, 'epoch': 0.31672847549363536}\n",
      "{'loss': 2.4336, 'grad_norm': 18.91280174255371, 'learning_rate': 3.4113460960208482e-06, 'epoch': 0.3177307807958304}\n",
      "{'loss': 1.8503, 'grad_norm': 17.98420524597168, 'learning_rate': 3.406334569509873e-06, 'epoch': 0.3187330860980255}\n",
      "{'loss': 1.2754, 'grad_norm': 18.75050926208496, 'learning_rate': 3.4013230429988974e-06, 'epoch': 0.3197353914002205}\n",
      "{'loss': 2.4262, 'grad_norm': 14.907161712646484, 'learning_rate': 3.396311516487922e-06, 'epoch': 0.32073769670241553}\n",
      "{'loss': 1.9589, 'grad_norm': 41.99705123901367, 'learning_rate': 3.3912999899769474e-06, 'epoch': 0.3217400020046106}\n",
      "{'loss': 2.1252, 'grad_norm': 75.35126495361328, 'learning_rate': 3.386288463465972e-06, 'epoch': 0.32274230730680564}\n",
      "{'loss': 2.1076, 'grad_norm': 22.942686080932617, 'learning_rate': 3.381276936954997e-06, 'epoch': 0.3237446126090007}\n",
      "{'loss': 2.3034, 'grad_norm': 20.32210922241211, 'learning_rate': 3.3762654104440217e-06, 'epoch': 0.32474691791119575}\n",
      "{'loss': 1.6708, 'grad_norm': 16.78330421447754, 'learning_rate': 3.371253883933046e-06, 'epoch': 0.3257492232133908}\n",
      "{'loss': 2.523, 'grad_norm': 18.944448471069336, 'learning_rate': 3.366242357422071e-06, 'epoch': 0.32675152851558587}\n",
      "{'loss': 1.6172, 'grad_norm': 35.875389099121094, 'learning_rate': 3.3612308309110957e-06, 'epoch': 0.3277538338177809}\n",
      "{'loss': 2.6308, 'grad_norm': 12.572975158691406, 'learning_rate': 3.356219304400121e-06, 'epoch': 0.3287561391199759}\n",
      "{'loss': 1.8849, 'grad_norm': 14.452402114868164, 'learning_rate': 3.3512077778891457e-06, 'epoch': 0.329758444422171}\n",
      "{'loss': 1.5793, 'grad_norm': 20.469600677490234, 'learning_rate': 3.34619625137817e-06, 'epoch': 0.33076074972436603}\n",
      "{'loss': 1.1668, 'grad_norm': 21.448827743530273, 'learning_rate': 3.341184724867195e-06, 'epoch': 0.3317630550265611}\n",
      "{'loss': 1.6958, 'grad_norm': 25.984941482543945, 'learning_rate': 3.3361731983562196e-06, 'epoch': 0.33276536032875614}\n",
      "{'loss': 1.9745, 'grad_norm': 23.326547622680664, 'learning_rate': 3.3311616718452444e-06, 'epoch': 0.33376766563095117}\n",
      "{'loss': 1.791, 'grad_norm': 34.24445343017578, 'learning_rate': 3.326150145334269e-06, 'epoch': 0.33476997093314625}\n",
      "{'loss': 1.6871, 'grad_norm': 11.096476554870605, 'learning_rate': 3.3211386188232935e-06, 'epoch': 0.3357722762353413}\n",
      "{'loss': 1.7283, 'grad_norm': 14.268548965454102, 'learning_rate': 3.3161270923123183e-06, 'epoch': 0.3367745815375363}\n",
      "{'loss': 2.2716, 'grad_norm': 11.255616188049316, 'learning_rate': 3.311115565801343e-06, 'epoch': 0.3377768868397314}\n",
      "{'loss': 2.3849, 'grad_norm': 28.002817153930664, 'learning_rate': 3.3061040392903683e-06, 'epoch': 0.3387791921419264}\n",
      "{'loss': 1.8952, 'grad_norm': 7.190925121307373, 'learning_rate': 3.301092512779393e-06, 'epoch': 0.3397814974441215}\n",
      "{'loss': 1.3754, 'grad_norm': 16.052125930786133, 'learning_rate': 3.296080986268418e-06, 'epoch': 0.34078380274631653}\n",
      "{'loss': 1.6127, 'grad_norm': 29.383153915405273, 'learning_rate': 3.2910694597574423e-06, 'epoch': 0.34178610804851156}\n",
      "{'loss': 2.4857, 'grad_norm': 27.113567352294922, 'learning_rate': 3.286057933246467e-06, 'epoch': 0.34278841335070664}\n",
      "{'loss': 2.2015, 'grad_norm': 19.661514282226562, 'learning_rate': 3.281046406735492e-06, 'epoch': 0.3437907186529017}\n",
      "{'loss': 1.6487, 'grad_norm': 18.621509552001953, 'learning_rate': 3.2760348802245166e-06, 'epoch': 0.3447930239550967}\n",
      "{'loss': 2.4471, 'grad_norm': 18.197633743286133, 'learning_rate': 3.271023353713542e-06, 'epoch': 0.3457953292572918}\n",
      "{'loss': 1.2027, 'grad_norm': 42.39752960205078, 'learning_rate': 3.2660118272025658e-06, 'epoch': 0.3467976345594868}\n",
      "{'loss': 1.6884, 'grad_norm': 12.999612808227539, 'learning_rate': 3.261000300691591e-06, 'epoch': 0.3477999398616819}\n",
      "{'loss': 1.7093, 'grad_norm': 13.690254211425781, 'learning_rate': 3.2559887741806158e-06, 'epoch': 0.3488022451638769}\n",
      "{'loss': 0.842, 'grad_norm': 19.235219955444336, 'learning_rate': 3.2509772476696406e-06, 'epoch': 0.34980455046607195}\n",
      "{'loss': 1.7753, 'grad_norm': 31.213014602661133, 'learning_rate': 3.2459657211586653e-06, 'epoch': 0.35080685576826703}\n",
      "{'loss': 1.2377, 'grad_norm': 31.1750545501709, 'learning_rate': 3.2409541946476897e-06, 'epoch': 0.35180916107046206}\n",
      "{'loss': 1.7688, 'grad_norm': 15.434914588928223, 'learning_rate': 3.2359426681367145e-06, 'epoch': 0.3528114663726571}\n",
      "{'loss': 1.9327, 'grad_norm': 6.439074993133545, 'learning_rate': 3.2309311416257393e-06, 'epoch': 0.3538137716748522}\n",
      "{'loss': 1.9144, 'grad_norm': 29.96079444885254, 'learning_rate': 3.225919615114764e-06, 'epoch': 0.3548160769770472}\n",
      "{'loss': 2.3566, 'grad_norm': 14.335406303405762, 'learning_rate': 3.2209080886037893e-06, 'epoch': 0.3558183822792423}\n",
      "{'loss': 2.7689, 'grad_norm': 10.0647611618042, 'learning_rate': 3.215896562092814e-06, 'epoch': 0.3568206875814373}\n",
      "{'loss': 1.6195, 'grad_norm': 10.661757469177246, 'learning_rate': 3.2108850355818384e-06, 'epoch': 0.35782299288363234}\n",
      "{'loss': 1.4604, 'grad_norm': 19.318662643432617, 'learning_rate': 3.2058735090708632e-06, 'epoch': 0.3588252981858274}\n",
      "{'loss': 1.4682, 'grad_norm': 15.30923843383789, 'learning_rate': 3.200861982559888e-06, 'epoch': 0.35982760348802245}\n",
      "{'loss': 1.4841, 'grad_norm': 22.214365005493164, 'learning_rate': 3.195850456048913e-06, 'epoch': 0.3608299087902175}\n",
      "{'loss': 1.4824, 'grad_norm': 7.474881172180176, 'learning_rate': 3.1908389295379376e-06, 'epoch': 0.36183221409241256}\n",
      "{'loss': 2.4088, 'grad_norm': 23.04401969909668, 'learning_rate': 3.185827403026962e-06, 'epoch': 0.3628345193946076}\n",
      "{'loss': 1.3262, 'grad_norm': 22.648784637451172, 'learning_rate': 3.1808158765159867e-06, 'epoch': 0.3638368246968026}\n",
      "{'loss': 1.8827, 'grad_norm': 10.796849250793457, 'learning_rate': 3.175804350005012e-06, 'epoch': 0.3648391299989977}\n",
      "{'loss': 2.3367, 'grad_norm': 22.637182235717773, 'learning_rate': 3.1707928234940367e-06, 'epoch': 0.36584143530119273}\n",
      "{'loss': 1.4714, 'grad_norm': 0.0, 'learning_rate': 3.1657812969830615e-06, 'epoch': 0.3668437406033878}\n",
      "{'loss': 1.444, 'grad_norm': 16.159509658813477, 'learning_rate': 3.1607697704720863e-06, 'epoch': 0.36784604590558284}\n",
      "{'loss': 1.9296, 'grad_norm': 15.817381858825684, 'learning_rate': 3.1557582439611107e-06, 'epoch': 0.36884835120777787}\n",
      "{'loss': 2.0606, 'grad_norm': 23.310453414916992, 'learning_rate': 3.1507467174501355e-06, 'epoch': 0.36985065650997295}\n",
      "{'loss': 1.8278, 'grad_norm': 45.597938537597656, 'learning_rate': 3.1457351909391602e-06, 'epoch': 0.370852961812168}\n",
      "{'loss': 1.7479, 'grad_norm': 25.685544967651367, 'learning_rate': 3.140723664428185e-06, 'epoch': 0.371855267114363}\n",
      "{'loss': 1.5727, 'grad_norm': 23.105148315429688, 'learning_rate': 3.1357121379172102e-06, 'epoch': 0.3728575724165581}\n",
      "{'loss': 1.5545, 'grad_norm': 19.803730010986328, 'learning_rate': 3.130700611406234e-06, 'epoch': 0.3738598777187531}\n",
      "{'loss': 2.0472, 'grad_norm': 18.99385643005371, 'learning_rate': 3.1256890848952594e-06, 'epoch': 0.3748621830209482}\n",
      "{'loss': 1.7541, 'grad_norm': 22.107084274291992, 'learning_rate': 3.120677558384284e-06, 'epoch': 0.37586448832314323}\n",
      "{'loss': 1.9861, 'grad_norm': 14.070734024047852, 'learning_rate': 3.115666031873309e-06, 'epoch': 0.37686679362533826}\n",
      "{'loss': 2.2213, 'grad_norm': 23.696063995361328, 'learning_rate': 3.1106545053623338e-06, 'epoch': 0.37786909892753334}\n",
      "{'loss': 1.538, 'grad_norm': 25.946935653686523, 'learning_rate': 3.105642978851358e-06, 'epoch': 0.37887140422972837}\n",
      "{'loss': 2.5011, 'grad_norm': 18.887271881103516, 'learning_rate': 3.100631452340383e-06, 'epoch': 0.3798737095319234}\n",
      "{'loss': 2.157, 'grad_norm': 12.257218360900879, 'learning_rate': 3.0956199258294077e-06, 'epoch': 0.3808760148341185}\n",
      "{'loss': 1.2147, 'grad_norm': 13.689434051513672, 'learning_rate': 3.090608399318433e-06, 'epoch': 0.3818783201363135}\n",
      "{'loss': 1.3516, 'grad_norm': 40.57477951049805, 'learning_rate': 3.0855968728074577e-06, 'epoch': 0.3828806254385086}\n",
      "{'loss': 1.4848, 'grad_norm': 23.526687622070312, 'learning_rate': 3.0805853462964825e-06, 'epoch': 0.3838829307407036}\n",
      "{'loss': 1.7422, 'grad_norm': 18.148893356323242, 'learning_rate': 3.075573819785507e-06, 'epoch': 0.38488523604289865}\n",
      "{'loss': 1.9095, 'grad_norm': 12.548009872436523, 'learning_rate': 3.0705622932745316e-06, 'epoch': 0.38588754134509373}\n",
      "{'loss': 2.0115, 'grad_norm': 10.707274436950684, 'learning_rate': 3.0655507667635564e-06, 'epoch': 0.38688984664728876}\n",
      "{'loss': 1.5062, 'grad_norm': 18.103200912475586, 'learning_rate': 3.060539240252581e-06, 'epoch': 0.3878921519494838}\n",
      "{'loss': 1.9201, 'grad_norm': 16.358501434326172, 'learning_rate': 3.055527713741606e-06, 'epoch': 0.38889445725167887}\n",
      "{'loss': 1.8302, 'grad_norm': 20.281843185424805, 'learning_rate': 3.0505161872306304e-06, 'epoch': 0.3898967625538739}\n",
      "{'loss': 2.5594, 'grad_norm': 1.2252271175384521, 'learning_rate': 3.045504660719655e-06, 'epoch': 0.390899067856069}\n",
      "{'loss': 1.9046, 'grad_norm': 20.557273864746094, 'learning_rate': 3.0404931342086804e-06, 'epoch': 0.391901373158264}\n",
      "{'loss': 2.3568, 'grad_norm': 19.834104537963867, 'learning_rate': 3.035481607697705e-06, 'epoch': 0.39290367846045904}\n",
      "{'loss': 2.3762, 'grad_norm': 22.822179794311523, 'learning_rate': 3.03047008118673e-06, 'epoch': 0.3939059837626541}\n",
      "{'loss': 1.4808, 'grad_norm': 15.033088684082031, 'learning_rate': 3.0254585546757543e-06, 'epoch': 0.39490828906484915}\n",
      "{'loss': 1.2244, 'grad_norm': 33.828712463378906, 'learning_rate': 3.020447028164779e-06, 'epoch': 0.3959105943670442}\n",
      "{'loss': 1.6243, 'grad_norm': 17.410348892211914, 'learning_rate': 3.015435501653804e-06, 'epoch': 0.39691289966923926}\n",
      "{'loss': 1.6091, 'grad_norm': 11.691789627075195, 'learning_rate': 3.0104239751428287e-06, 'epoch': 0.3979152049714343}\n",
      "{'loss': 1.953, 'grad_norm': 19.291345596313477, 'learning_rate': 3.005412448631854e-06, 'epoch': 0.39891751027362937}\n",
      "{'loss': 2.2871, 'grad_norm': 17.92603874206543, 'learning_rate': 3.0004009221208787e-06, 'epoch': 0.3999198155758244}\n",
      "{'loss': 1.5566, 'grad_norm': 7.90007209777832, 'learning_rate': 2.995389395609903e-06, 'epoch': 0.40092212087801943}\n",
      "{'loss': 1.48, 'grad_norm': 66.00887298583984, 'learning_rate': 2.990377869098928e-06, 'epoch': 0.4019244261802145}\n",
      "{'loss': 1.6352, 'grad_norm': 21.200481414794922, 'learning_rate': 2.9853663425879526e-06, 'epoch': 0.40292673148240954}\n",
      "{'loss': 2.0226, 'grad_norm': 17.537128448486328, 'learning_rate': 2.9803548160769774e-06, 'epoch': 0.40392903678460457}\n",
      "{'loss': 1.8912, 'grad_norm': 8.521039009094238, 'learning_rate': 2.975343289566002e-06, 'epoch': 0.40493134208679965}\n",
      "{'loss': 1.4857, 'grad_norm': 17.23647117614746, 'learning_rate': 2.9703317630550265e-06, 'epoch': 0.4059336473889947}\n",
      "{'loss': 1.9859, 'grad_norm': 32.37384796142578, 'learning_rate': 2.9653202365440513e-06, 'epoch': 0.40693595269118976}\n",
      "{'loss': 1.8264, 'grad_norm': 21.131624221801758, 'learning_rate': 2.960308710033076e-06, 'epoch': 0.4079382579933848}\n",
      "{'loss': 1.8377, 'grad_norm': 14.463652610778809, 'learning_rate': 2.9552971835221013e-06, 'epoch': 0.4089405632955798}\n",
      "{'loss': 1.6969, 'grad_norm': 11.071208000183105, 'learning_rate': 2.950285657011126e-06, 'epoch': 0.4099428685977749}\n",
      "{'loss': 1.6882, 'grad_norm': 9.171740531921387, 'learning_rate': 2.9452741305001505e-06, 'epoch': 0.41094517389996993}\n",
      "{'loss': 2.1604, 'grad_norm': 26.124231338500977, 'learning_rate': 2.9402626039891753e-06, 'epoch': 0.41194747920216496}\n",
      "{'loss': 2.2459, 'grad_norm': 7.1056718826293945, 'learning_rate': 2.9352510774782e-06, 'epoch': 0.41294978450436004}\n",
      "{'loss': 2.439, 'grad_norm': 23.6311092376709, 'learning_rate': 2.930239550967225e-06, 'epoch': 0.41395208980655507}\n",
      "{'loss': 1.8151, 'grad_norm': 20.843673706054688, 'learning_rate': 2.9252280244562496e-06, 'epoch': 0.41495439510875015}\n",
      "{'loss': 1.5527, 'grad_norm': 33.31316375732422, 'learning_rate': 2.920216497945275e-06, 'epoch': 0.4159567004109452}\n",
      "{'loss': 2.0845, 'grad_norm': 16.67808723449707, 'learning_rate': 2.9152049714342988e-06, 'epoch': 0.4169590057131402}\n",
      "{'loss': 1.5537, 'grad_norm': 11.836519241333008, 'learning_rate': 2.910193444923324e-06, 'epoch': 0.4179613110153353}\n",
      "{'loss': 1.5237, 'grad_norm': 0.0, 'learning_rate': 2.9051819184123488e-06, 'epoch': 0.4189636163175303}\n",
      "{'loss': 2.1935, 'grad_norm': 20.083209991455078, 'learning_rate': 2.9001703919013735e-06, 'epoch': 0.41996592161972535}\n",
      "{'loss': 1.6977, 'grad_norm': 16.338653564453125, 'learning_rate': 2.8951588653903983e-06, 'epoch': 0.42096822692192043}\n",
      "{'loss': 2.1904, 'grad_norm': 22.435977935791016, 'learning_rate': 2.8901473388794227e-06, 'epoch': 0.42197053222411546}\n",
      "{'loss': 1.9823, 'grad_norm': 13.139481544494629, 'learning_rate': 2.8851358123684475e-06, 'epoch': 0.42297283752631054}\n",
      "{'loss': 1.7788, 'grad_norm': 25.585397720336914, 'learning_rate': 2.8801242858574723e-06, 'epoch': 0.42397514282850557}\n",
      "{'loss': 1.3406, 'grad_norm': 30.20383644104004, 'learning_rate': 2.875112759346497e-06, 'epoch': 0.4249774481307006}\n",
      "{'loss': 1.8637, 'grad_norm': 13.139487266540527, 'learning_rate': 2.8701012328355223e-06, 'epoch': 0.4259797534328957}\n",
      "{'loss': 1.8333, 'grad_norm': 26.315441131591797, 'learning_rate': 2.8650897063245462e-06, 'epoch': 0.4269820587350907}\n",
      "{'loss': 2.5569, 'grad_norm': 39.62575149536133, 'learning_rate': 2.8600781798135714e-06, 'epoch': 0.42798436403728574}\n",
      "{'loss': 1.72, 'grad_norm': 12.967079162597656, 'learning_rate': 2.855066653302596e-06, 'epoch': 0.4289866693394808}\n",
      "{'loss': 1.7946, 'grad_norm': 10.997302055358887, 'learning_rate': 2.850055126791621e-06, 'epoch': 0.42998897464167585}\n",
      "{'loss': 1.3913, 'grad_norm': 30.097782135009766, 'learning_rate': 2.8450436002806458e-06, 'epoch': 0.43099127994387093}\n",
      "{'loss': 2.4587, 'grad_norm': 15.959368705749512, 'learning_rate': 2.8400320737696706e-06, 'epoch': 0.43199358524606596}\n",
      "{'loss': 1.6548, 'grad_norm': 47.956485748291016, 'learning_rate': 2.835020547258695e-06, 'epoch': 0.432995890548261}\n",
      "{'loss': 1.4306, 'grad_norm': 15.144124031066895, 'learning_rate': 2.8300090207477197e-06, 'epoch': 0.43399819585045607}\n",
      "{'loss': 2.2275, 'grad_norm': 15.38988971710205, 'learning_rate': 2.824997494236745e-06, 'epoch': 0.4350005011526511}\n",
      "{'loss': 2.1178, 'grad_norm': 24.984346389770508, 'learning_rate': 2.8199859677257697e-06, 'epoch': 0.4360028064548461}\n",
      "{'loss': 2.9179, 'grad_norm': 21.784717559814453, 'learning_rate': 2.8149744412147945e-06, 'epoch': 0.4370051117570412}\n",
      "{'loss': 2.5518, 'grad_norm': 10.226993560791016, 'learning_rate': 2.809962914703819e-06, 'epoch': 0.43800741705923624}\n",
      "{'loss': 1.9482, 'grad_norm': 18.865358352661133, 'learning_rate': 2.8049513881928437e-06, 'epoch': 0.43900972236143126}\n",
      "{'loss': 1.8204, 'grad_norm': 13.66934871673584, 'learning_rate': 2.7999398616818684e-06, 'epoch': 0.44001202766362635}\n",
      "{'loss': 1.9146, 'grad_norm': 14.751152992248535, 'learning_rate': 2.7949283351708932e-06, 'epoch': 0.4410143329658214}\n",
      "{'loss': 1.6742, 'grad_norm': 20.409643173217773, 'learning_rate': 2.789916808659918e-06, 'epoch': 0.44201663826801646}\n",
      "{'loss': 2.3121, 'grad_norm': 28.121740341186523, 'learning_rate': 2.7849052821489432e-06, 'epoch': 0.4430189435702115}\n",
      "{'loss': 2.4229, 'grad_norm': 22.448741912841797, 'learning_rate': 2.779893755637967e-06, 'epoch': 0.4440212488724065}\n",
      "{'loss': 1.2602, 'grad_norm': 16.054973602294922, 'learning_rate': 2.7748822291269924e-06, 'epoch': 0.4450235541746016}\n",
      "{'loss': 2.0737, 'grad_norm': 14.187671661376953, 'learning_rate': 2.769870702616017e-06, 'epoch': 0.4460258594767966}\n",
      "{'loss': 1.7172, 'grad_norm': 11.78368854522705, 'learning_rate': 2.764859176105042e-06, 'epoch': 0.44702816477899165}\n",
      "{'loss': 1.9204, 'grad_norm': 8.317859649658203, 'learning_rate': 2.7598476495940667e-06, 'epoch': 0.44803047008118674}\n",
      "{'loss': 1.5634, 'grad_norm': 15.676145553588867, 'learning_rate': 2.754836123083091e-06, 'epoch': 0.44903277538338177}\n",
      "{'loss': 1.6765, 'grad_norm': 9.425673484802246, 'learning_rate': 2.749824596572116e-06, 'epoch': 0.45003508068557685}\n",
      "{'loss': 1.8157, 'grad_norm': 18.417163848876953, 'learning_rate': 2.7448130700611407e-06, 'epoch': 0.4510373859877719}\n",
      "{'loss': 1.6314, 'grad_norm': 13.28204345703125, 'learning_rate': 2.739801543550166e-06, 'epoch': 0.4520396912899669}\n",
      "{'loss': 1.7755, 'grad_norm': 21.94873809814453, 'learning_rate': 2.7347900170391907e-06, 'epoch': 0.453041996592162}\n",
      "{'loss': 1.435, 'grad_norm': 10.263040542602539, 'learning_rate': 2.729778490528215e-06, 'epoch': 0.454044301894357}\n",
      "{'loss': 1.0661, 'grad_norm': 26.24846839904785, 'learning_rate': 2.72476696401724e-06, 'epoch': 0.45504660719655204}\n",
      "{'loss': 1.9621, 'grad_norm': 11.382489204406738, 'learning_rate': 2.7197554375062646e-06, 'epoch': 0.4560489124987471}\n",
      "{'loss': 1.2153, 'grad_norm': 1.2404754161834717, 'learning_rate': 2.7147439109952894e-06, 'epoch': 0.45705121780094216}\n",
      "{'loss': 1.5159, 'grad_norm': 17.552457809448242, 'learning_rate': 2.709732384484314e-06, 'epoch': 0.45805352310313724}\n",
      "{'loss': 1.9516, 'grad_norm': 15.185454368591309, 'learning_rate': 2.704720857973339e-06, 'epoch': 0.45905582840533227}\n",
      "{'loss': 1.647, 'grad_norm': 40.34528350830078, 'learning_rate': 2.6997093314623633e-06, 'epoch': 0.4600581337075273}\n",
      "{'loss': 1.9737, 'grad_norm': 22.298059463500977, 'learning_rate': 2.694697804951388e-06, 'epoch': 0.4610604390097224}\n",
      "{'loss': 2.3964, 'grad_norm': 14.589385032653809, 'learning_rate': 2.6896862784404133e-06, 'epoch': 0.4620627443119174}\n",
      "{'loss': 2.1916, 'grad_norm': 9.117607116699219, 'learning_rate': 2.684674751929438e-06, 'epoch': 0.46306504961411243}\n",
      "{'loss': 2.2437, 'grad_norm': 23.053617477416992, 'learning_rate': 2.679663225418463e-06, 'epoch': 0.4640673549163075}\n",
      "{'loss': 1.5841, 'grad_norm': 48.22798538208008, 'learning_rate': 2.6746516989074873e-06, 'epoch': 0.46506966021850255}\n",
      "{'loss': 1.7876, 'grad_norm': 16.74138641357422, 'learning_rate': 2.669640172396512e-06, 'epoch': 0.46607196552069763}\n",
      "{'loss': 2.0376, 'grad_norm': 18.967954635620117, 'learning_rate': 2.664628645885537e-06, 'epoch': 0.46707427082289266}\n",
      "{'loss': 1.4874, 'grad_norm': 0.0, 'learning_rate': 2.6596171193745616e-06, 'epoch': 0.4680765761250877}\n",
      "{'loss': 1.8056, 'grad_norm': 23.44109344482422, 'learning_rate': 2.654605592863587e-06, 'epoch': 0.46907888142728277}\n",
      "{'loss': 0.9411, 'grad_norm': 8.854888916015625, 'learning_rate': 2.649594066352611e-06, 'epoch': 0.4700811867294778}\n",
      "{'loss': 2.2878, 'grad_norm': 15.7144775390625, 'learning_rate': 2.644582539841636e-06, 'epoch': 0.4710834920316728}\n",
      "{'loss': 1.6856, 'grad_norm': 0.0, 'learning_rate': 2.639571013330661e-06, 'epoch': 0.4720857973338679}\n",
      "{'loss': 2.5019, 'grad_norm': 24.615354537963867, 'learning_rate': 2.6345594868196856e-06, 'epoch': 0.47308810263606293}\n",
      "{'loss': 1.1225, 'grad_norm': 21.730148315429688, 'learning_rate': 2.6295479603087104e-06, 'epoch': 0.474090407938258}\n",
      "{'loss': 2.1611, 'grad_norm': 28.62973976135254, 'learning_rate': 2.624536433797735e-06, 'epoch': 0.47509271324045305}\n",
      "{'loss': 1.0461, 'grad_norm': 14.386490821838379, 'learning_rate': 2.6195249072867595e-06, 'epoch': 0.4760950185426481}\n",
      "{'loss': 1.6572, 'grad_norm': 23.662607192993164, 'learning_rate': 2.6145133807757843e-06, 'epoch': 0.47709732384484316}\n",
      "{'loss': 1.4564, 'grad_norm': 23.742067337036133, 'learning_rate': 2.609501854264809e-06, 'epoch': 0.4780996291470382}\n",
      "{'loss': 1.477, 'grad_norm': 14.08755111694336, 'learning_rate': 2.6044903277538343e-06, 'epoch': 0.4791019344492332}\n",
      "{'loss': 1.9672, 'grad_norm': 36.54613494873047, 'learning_rate': 2.599478801242859e-06, 'epoch': 0.4801042397514283}\n",
      "{'loss': 1.6123, 'grad_norm': 7.23251485824585, 'learning_rate': 2.5944672747318835e-06, 'epoch': 0.4811065450536233}\n",
      "{'loss': 1.7844, 'grad_norm': 13.679847717285156, 'learning_rate': 2.5894557482209082e-06, 'epoch': 0.4821088503558184}\n",
      "{'loss': 0.9793, 'grad_norm': 20.563940048217773, 'learning_rate': 2.584444221709933e-06, 'epoch': 0.48311115565801344}\n",
      "{'loss': 2.5272, 'grad_norm': 32.069122314453125, 'learning_rate': 2.579432695198958e-06, 'epoch': 0.48411346096020846}\n",
      "{'loss': 2.0031, 'grad_norm': 20.68134880065918, 'learning_rate': 2.5744211686879826e-06, 'epoch': 0.48511576626240355}\n",
      "{'loss': 1.3032, 'grad_norm': 32.32259750366211, 'learning_rate': 2.569409642177007e-06, 'epoch': 0.4861180715645986}\n",
      "{'loss': 2.1977, 'grad_norm': 17.003524780273438, 'learning_rate': 2.5643981156660318e-06, 'epoch': 0.4871203768667936}\n",
      "{'loss': 1.5607, 'grad_norm': 27.125173568725586, 'learning_rate': 2.559386589155057e-06, 'epoch': 0.4881226821689887}\n",
      "{'loss': 1.8966, 'grad_norm': 12.285494804382324, 'learning_rate': 2.5543750626440818e-06, 'epoch': 0.4891249874711837}\n",
      "{'loss': 2.3225, 'grad_norm': 12.96548080444336, 'learning_rate': 2.5493635361331065e-06, 'epoch': 0.4901272927733788}\n",
      "{'loss': 2.156, 'grad_norm': 17.09759521484375, 'learning_rate': 2.5443520096221313e-06, 'epoch': 0.4911295980755738}\n",
      "{'loss': 1.8455, 'grad_norm': 14.664448738098145, 'learning_rate': 2.5393404831111557e-06, 'epoch': 0.49213190337776885}\n",
      "{'loss': 1.9802, 'grad_norm': 15.11320972442627, 'learning_rate': 2.5343289566001805e-06, 'epoch': 0.49313420867996394}\n",
      "{'loss': 1.2255, 'grad_norm': 25.06056785583496, 'learning_rate': 2.5293174300892053e-06, 'epoch': 0.49413651398215896}\n",
      "{'loss': 2.2487, 'grad_norm': 0.0, 'learning_rate': 2.52430590357823e-06, 'epoch': 0.495138819284354}\n",
      "{'loss': 2.0793, 'grad_norm': 29.826175689697266, 'learning_rate': 2.5192943770672553e-06, 'epoch': 0.4961411245865491}\n",
      "{'loss': 1.1389, 'grad_norm': 40.93832778930664, 'learning_rate': 2.514282850556279e-06, 'epoch': 0.4971434298887441}\n",
      "{'loss': 1.8077, 'grad_norm': 20.613704681396484, 'learning_rate': 2.5092713240453044e-06, 'epoch': 0.4981457351909392}\n",
      "{'loss': 1.3732, 'grad_norm': 30.297163009643555, 'learning_rate': 2.504259797534329e-06, 'epoch': 0.4991480404931342}\n",
      "{'loss': 1.4133, 'grad_norm': 7.035092830657959, 'learning_rate': 2.499248271023354e-06, 'epoch': 0.5001503457953292}\n",
      "{'loss': 2.3133, 'grad_norm': 18.292850494384766, 'learning_rate': 2.4942367445123788e-06, 'epoch': 0.5011526510975243}\n",
      "{'loss': 1.1038, 'grad_norm': 21.3258056640625, 'learning_rate': 2.4892252180014036e-06, 'epoch': 0.5021549563997194}\n",
      "{'loss': 2.1122, 'grad_norm': 22.027130126953125, 'learning_rate': 2.4842136914904283e-06, 'epoch': 0.5031572617019144}\n",
      "{'loss': 1.9751, 'grad_norm': 19.127717971801758, 'learning_rate': 2.4792021649794527e-06, 'epoch': 0.5041595670041095}\n",
      "{'loss': 2.0123, 'grad_norm': 26.602811813354492, 'learning_rate': 2.474190638468478e-06, 'epoch': 0.5051618723063045}\n",
      "{'loss': 1.8786, 'grad_norm': 7.758487701416016, 'learning_rate': 2.4691791119575027e-06, 'epoch': 0.5061641776084995}\n",
      "{'loss': 1.9847, 'grad_norm': 30.697856903076172, 'learning_rate': 2.464167585446527e-06, 'epoch': 0.5071664829106945}\n",
      "{'loss': 2.0001, 'grad_norm': 25.43557357788086, 'learning_rate': 2.459156058935552e-06, 'epoch': 0.5081687882128897}\n",
      "{'loss': 1.7352, 'grad_norm': 15.677594184875488, 'learning_rate': 2.4541445324245766e-06, 'epoch': 0.5091710935150847}\n",
      "{'loss': 1.4894, 'grad_norm': 10.757564544677734, 'learning_rate': 2.4491330059136014e-06, 'epoch': 0.5101733988172797}\n",
      "{'loss': 1.6457, 'grad_norm': 16.50285530090332, 'learning_rate': 2.4441214794026262e-06, 'epoch': 0.5111757041194748}\n",
      "{'loss': 2.5094, 'grad_norm': 14.27043342590332, 'learning_rate': 2.439109952891651e-06, 'epoch': 0.5121780094216698}\n",
      "{'loss': 1.2175, 'grad_norm': 10.349200248718262, 'learning_rate': 2.434098426380676e-06, 'epoch': 0.5131803147238649}\n",
      "{'loss': 1.5624, 'grad_norm': 14.470362663269043, 'learning_rate': 2.4290868998697006e-06, 'epoch': 0.51418262002606}\n",
      "{'loss': 1.5648, 'grad_norm': 21.219816207885742, 'learning_rate': 2.4240753733587254e-06, 'epoch': 0.515184925328255}\n",
      "{'loss': 2.0433, 'grad_norm': 14.02691650390625, 'learning_rate': 2.41906384684775e-06, 'epoch': 0.51618723063045}\n",
      "{'loss': 1.4668, 'grad_norm': 18.93947410583496, 'learning_rate': 2.4140523203367745e-06, 'epoch': 0.517189535932645}\n",
      "{'loss': 2.1914, 'grad_norm': 11.609066009521484, 'learning_rate': 2.4090407938257997e-06, 'epoch': 0.5181918412348401}\n",
      "{'loss': 1.8621, 'grad_norm': 20.928390502929688, 'learning_rate': 2.4040292673148245e-06, 'epoch': 0.5191941465370352}\n",
      "{'loss': 1.3317, 'grad_norm': 19.461341857910156, 'learning_rate': 2.399017740803849e-06, 'epoch': 0.5201964518392302}\n",
      "{'loss': 1.8203, 'grad_norm': 12.655245780944824, 'learning_rate': 2.3940062142928737e-06, 'epoch': 0.5211987571414253}\n",
      "{'loss': 1.5779, 'grad_norm': 28.64376449584961, 'learning_rate': 2.388994687781899e-06, 'epoch': 0.5222010624436203}\n",
      "{'loss': 1.8157, 'grad_norm': 34.49773025512695, 'learning_rate': 2.3839831612709232e-06, 'epoch': 0.5232033677458153}\n",
      "{'loss': 1.1257, 'grad_norm': 37.93175506591797, 'learning_rate': 2.378971634759948e-06, 'epoch': 0.5242056730480105}\n",
      "{'loss': 1.8103, 'grad_norm': 22.779502868652344, 'learning_rate': 2.373960108248973e-06, 'epoch': 0.5252079783502055}\n",
      "{'loss': 1.3511, 'grad_norm': 10.318770408630371, 'learning_rate': 2.3689485817379976e-06, 'epoch': 0.5262102836524005}\n",
      "{'loss': 1.9093, 'grad_norm': 16.478473663330078, 'learning_rate': 2.3639370552270224e-06, 'epoch': 0.5272125889545956}\n",
      "{'loss': 1.7033, 'grad_norm': 10.66750431060791, 'learning_rate': 2.358925528716047e-06, 'epoch': 0.5282148942567906}\n",
      "{'loss': 1.8433, 'grad_norm': 22.29216957092285, 'learning_rate': 2.353914002205072e-06, 'epoch': 0.5292171995589857}\n",
      "{'loss': 1.6437, 'grad_norm': 30.938213348388672, 'learning_rate': 2.3489024756940968e-06, 'epoch': 0.5302195048611807}\n",
      "{'loss': 1.68, 'grad_norm': 29.718168258666992, 'learning_rate': 2.343890949183121e-06, 'epoch': 0.5312218101633758}\n",
      "{'loss': 2.2351, 'grad_norm': 24.964599609375, 'learning_rate': 2.3388794226721463e-06, 'epoch': 0.5322241154655708}\n",
      "{'loss': 1.382, 'grad_norm': 13.361470222473145, 'learning_rate': 2.3338678961611707e-06, 'epoch': 0.5332264207677658}\n",
      "{'loss': 2.5894, 'grad_norm': 23.16930389404297, 'learning_rate': 2.3288563696501955e-06, 'epoch': 0.5342287260699609}\n",
      "{'loss': 1.7503, 'grad_norm': 9.154236793518066, 'learning_rate': 2.3238448431392207e-06, 'epoch': 0.535231031372156}\n",
      "{'loss': 2.2946, 'grad_norm': 34.1849250793457, 'learning_rate': 2.318833316628245e-06, 'epoch': 0.536233336674351}\n",
      "{'loss': 1.6321, 'grad_norm': 24.04475975036621, 'learning_rate': 2.31382179011727e-06, 'epoch': 0.537235641976546}\n",
      "{'loss': 1.6057, 'grad_norm': 28.280488967895508, 'learning_rate': 2.3088102636062946e-06, 'epoch': 0.5382379472787411}\n",
      "{'loss': 2.4209, 'grad_norm': 18.25520133972168, 'learning_rate': 2.3037987370953194e-06, 'epoch': 0.5392402525809361}\n",
      "{'loss': 2.0151, 'grad_norm': 14.294781684875488, 'learning_rate': 2.298787210584344e-06, 'epoch': 0.5402425578831312}\n",
      "{'loss': 2.3619, 'grad_norm': 30.29970932006836, 'learning_rate': 2.293775684073369e-06, 'epoch': 0.5412448631853263}\n",
      "{'loss': 1.8129, 'grad_norm': 31.062746047973633, 'learning_rate': 2.2887641575623938e-06, 'epoch': 0.5422471684875213}\n",
      "{'loss': 1.4828, 'grad_norm': 19.0107479095459, 'learning_rate': 2.2837526310514186e-06, 'epoch': 0.5432494737897163}\n",
      "{'loss': 2.5344, 'grad_norm': 21.703344345092773, 'learning_rate': 2.278741104540443e-06, 'epoch': 0.5442517790919114}\n",
      "{'loss': 1.9181, 'grad_norm': 24.835052490234375, 'learning_rate': 2.273729578029468e-06, 'epoch': 0.5452540843941065}\n",
      "{'loss': 2.3928, 'grad_norm': 16.04286766052246, 'learning_rate': 2.268718051518493e-06, 'epoch': 0.5462563896963015}\n",
      "{'loss': 1.8845, 'grad_norm': 12.834399223327637, 'learning_rate': 2.2637065250075173e-06, 'epoch': 0.5472586949984966}\n",
      "{'loss': 2.6339, 'grad_norm': 10.620990753173828, 'learning_rate': 2.258694998496542e-06, 'epoch': 0.5482610003006916}\n",
      "{'loss': 2.1818, 'grad_norm': 29.270816802978516, 'learning_rate': 2.253683471985567e-06, 'epoch': 0.5492633056028866}\n",
      "{'loss': 2.0574, 'grad_norm': 15.348689079284668, 'learning_rate': 2.2486719454745917e-06, 'epoch': 0.5502656109050816}\n",
      "{'loss': 1.4805, 'grad_norm': 29.979082107543945, 'learning_rate': 2.2436604189636164e-06, 'epoch': 0.5512679162072768}\n",
      "{'loss': 2.3357, 'grad_norm': 28.576135635375977, 'learning_rate': 2.2386488924526412e-06, 'epoch': 0.5522702215094718}\n",
      "{'loss': 1.7876, 'grad_norm': 57.309425354003906, 'learning_rate': 2.233637365941666e-06, 'epoch': 0.5532725268116668}\n",
      "{'loss': 1.0695, 'grad_norm': 29.124319076538086, 'learning_rate': 2.228625839430691e-06, 'epoch': 0.5542748321138619}\n",
      "{'loss': 1.859, 'grad_norm': 18.345380783081055, 'learning_rate': 2.2236143129197156e-06, 'epoch': 0.5552771374160569}\n",
      "{'loss': 1.7158, 'grad_norm': 14.207679748535156, 'learning_rate': 2.2186027864087404e-06, 'epoch': 0.556279442718252}\n",
      "{'loss': 1.7363, 'grad_norm': 14.8231782913208, 'learning_rate': 2.2135912598977647e-06, 'epoch': 0.557281748020447}\n",
      "{'loss': 1.9183, 'grad_norm': 50.49065017700195, 'learning_rate': 2.20857973338679e-06, 'epoch': 0.5582840533226421}\n",
      "{'loss': 1.7844, 'grad_norm': 16.80405616760254, 'learning_rate': 2.2035682068758147e-06, 'epoch': 0.5592863586248371}\n",
      "{'loss': 1.4432, 'grad_norm': 33.21187973022461, 'learning_rate': 2.198556680364839e-06, 'epoch': 0.5602886639270321}\n",
      "{'loss': 2.0726, 'grad_norm': 15.764235496520996, 'learning_rate': 2.193545153853864e-06, 'epoch': 0.5612909692292273}\n",
      "{'loss': 0.8838, 'grad_norm': 22.31670379638672, 'learning_rate': 2.188533627342889e-06, 'epoch': 0.5622932745314223}\n",
      "{'loss': 0.8676, 'grad_norm': 18.73031234741211, 'learning_rate': 2.1835221008319135e-06, 'epoch': 0.5632955798336173}\n",
      "{'loss': 1.2854, 'grad_norm': 7.823204040527344, 'learning_rate': 2.1785105743209383e-06, 'epoch': 0.5642978851358124}\n",
      "{'loss': 2.0375, 'grad_norm': 25.29512596130371, 'learning_rate': 2.173499047809963e-06, 'epoch': 0.5653001904380074}\n",
      "{'loss': 1.7999, 'grad_norm': 50.9864501953125, 'learning_rate': 2.168487521298988e-06, 'epoch': 0.5663024957402024}\n",
      "{'loss': 1.6778, 'grad_norm': 18.34617042541504, 'learning_rate': 2.1634759947880126e-06, 'epoch': 0.5673048010423976}\n",
      "{'loss': 1.8215, 'grad_norm': 24.925161361694336, 'learning_rate': 2.1584644682770374e-06, 'epoch': 0.5683071063445926}\n",
      "{'loss': 2.3797, 'grad_norm': 12.931238174438477, 'learning_rate': 2.153452941766062e-06, 'epoch': 0.5693094116467876}\n",
      "{'loss': 1.9009, 'grad_norm': 14.694170951843262, 'learning_rate': 2.148441415255087e-06, 'epoch': 0.5703117169489826}\n",
      "{'loss': 1.8156, 'grad_norm': 26.447891235351562, 'learning_rate': 2.1434298887441118e-06, 'epoch': 0.5713140222511777}\n",
      "{'loss': 2.4308, 'grad_norm': 8.585958480834961, 'learning_rate': 2.1384183622331365e-06, 'epoch': 0.5723163275533728}\n",
      "{'loss': 1.6403, 'grad_norm': 27.168073654174805, 'learning_rate': 2.133406835722161e-06, 'epoch': 0.5733186328555678}\n",
      "{'loss': 1.3479, 'grad_norm': 12.507533073425293, 'learning_rate': 2.1283953092111857e-06, 'epoch': 0.5743209381577629}\n",
      "{'loss': 1.9483, 'grad_norm': 21.791889190673828, 'learning_rate': 2.123383782700211e-06, 'epoch': 0.5753232434599579}\n",
      "{'loss': 1.9312, 'grad_norm': 9.93465805053711, 'learning_rate': 2.1183722561892353e-06, 'epoch': 0.5763255487621529}\n",
      "{'loss': 1.3429, 'grad_norm': 34.41703414916992, 'learning_rate': 2.11336072967826e-06, 'epoch': 0.577327854064348}\n",
      "{'loss': 1.9855, 'grad_norm': 23.43069839477539, 'learning_rate': 2.108349203167285e-06, 'epoch': 0.5783301593665431}\n",
      "{'loss': 1.9075, 'grad_norm': 20.762468338012695, 'learning_rate': 2.1033376766563096e-06, 'epoch': 0.5793324646687381}\n",
      "{'loss': 1.7654, 'grad_norm': 18.417499542236328, 'learning_rate': 2.0983261501453344e-06, 'epoch': 0.5803347699709331}\n",
      "{'loss': 1.2493, 'grad_norm': 11.851383209228516, 'learning_rate': 2.093314623634359e-06, 'epoch': 0.5813370752731282}\n",
      "{'loss': 1.7911, 'grad_norm': 19.064577102661133, 'learning_rate': 2.088303097123384e-06, 'epoch': 0.5823393805753232}\n",
      "{'loss': 1.8553, 'grad_norm': 15.325608253479004, 'learning_rate': 2.0832915706124088e-06, 'epoch': 0.5833416858775183}\n",
      "{'loss': 1.7651, 'grad_norm': 0.0, 'learning_rate': 2.078280044101433e-06, 'epoch': 0.5843439911797134}\n",
      "{'loss': 2.2925, 'grad_norm': 25.579139709472656, 'learning_rate': 2.0732685175904584e-06, 'epoch': 0.5853462964819084}\n",
      "{'loss': 1.764, 'grad_norm': 16.867908477783203, 'learning_rate': 2.068256991079483e-06, 'epoch': 0.5863486017841034}\n",
      "{'loss': 1.7341, 'grad_norm': 21.152748107910156, 'learning_rate': 2.0632454645685075e-06, 'epoch': 0.5873509070862984}\n",
      "{'loss': 0.9825, 'grad_norm': 7.610731601715088, 'learning_rate': 2.0582339380575327e-06, 'epoch': 0.5883532123884936}\n",
      "{'loss': 2.0179, 'grad_norm': 0.0, 'learning_rate': 2.0532224115465575e-06, 'epoch': 0.5893555176906886}\n",
      "{'loss': 0.9144, 'grad_norm': 40.06932830810547, 'learning_rate': 2.048210885035582e-06, 'epoch': 0.5903578229928836}\n",
      "{'loss': 2.2507, 'grad_norm': 27.76888656616211, 'learning_rate': 2.0431993585246067e-06, 'epoch': 0.5913601282950787}\n",
      "{'loss': 1.489, 'grad_norm': 10.364253997802734, 'learning_rate': 2.0381878320136314e-06, 'epoch': 0.5923624335972737}\n",
      "{'loss': 2.2851, 'grad_norm': 15.372896194458008, 'learning_rate': 2.0331763055026562e-06, 'epoch': 0.5933647388994687}\n",
      "{'loss': 1.6045, 'grad_norm': 32.24555587768555, 'learning_rate': 2.028164778991681e-06, 'epoch': 0.5943670442016639}\n",
      "{'loss': 1.8659, 'grad_norm': 0.0, 'learning_rate': 2.023153252480706e-06, 'epoch': 0.5953693495038589}\n",
      "{'loss': 2.3429, 'grad_norm': 14.125127792358398, 'learning_rate': 2.0181417259697306e-06, 'epoch': 0.5963716548060539}\n",
      "{'loss': 2.3501, 'grad_norm': 42.430938720703125, 'learning_rate': 2.0131301994587554e-06, 'epoch': 0.597373960108249}\n",
      "{'loss': 1.9242, 'grad_norm': 14.577751159667969, 'learning_rate': 2.00811867294778e-06, 'epoch': 0.598376265410444}\n",
      "{'loss': 1.3556, 'grad_norm': 27.969196319580078, 'learning_rate': 2.003107146436805e-06, 'epoch': 0.5993785707126391}\n",
      "{'loss': 1.5835, 'grad_norm': 23.523292541503906, 'learning_rate': 1.9980956199258293e-06, 'epoch': 0.6003808760148341}\n",
      "{'loss': 1.5654, 'grad_norm': 24.390914916992188, 'learning_rate': 1.993084093414854e-06, 'epoch': 0.6013831813170292}\n",
      "{'loss': 2.284, 'grad_norm': 17.197864532470703, 'learning_rate': 1.9880725669038793e-06, 'epoch': 0.6023854866192242}\n",
      "{'loss': 1.8152, 'grad_norm': 13.351236343383789, 'learning_rate': 1.9830610403929037e-06, 'epoch': 0.6033877919214192}\n",
      "{'loss': 1.3847, 'grad_norm': 16.88017463684082, 'learning_rate': 1.9780495138819285e-06, 'epoch': 0.6043900972236144}\n",
      "{'loss': 2.4604, 'grad_norm': 11.152670860290527, 'learning_rate': 1.9730379873709537e-06, 'epoch': 0.6053924025258094}\n",
      "{'loss': 1.7655, 'grad_norm': 13.024029731750488, 'learning_rate': 1.968026460859978e-06, 'epoch': 0.6063947078280044}\n",
      "{'loss': 1.4224, 'grad_norm': 18.186311721801758, 'learning_rate': 1.963014934349003e-06, 'epoch': 0.6073970131301994}\n",
      "{'loss': 2.0432, 'grad_norm': 17.56293487548828, 'learning_rate': 1.9580034078380276e-06, 'epoch': 0.6083993184323945}\n",
      "{'loss': 1.5024, 'grad_norm': 28.601116180419922, 'learning_rate': 1.9529918813270524e-06, 'epoch': 0.6094016237345895}\n",
      "{'loss': 1.545, 'grad_norm': 16.76556396484375, 'learning_rate': 1.947980354816077e-06, 'epoch': 0.6104039290367846}\n",
      "{'loss': 1.5047, 'grad_norm': 15.904329299926758, 'learning_rate': 1.942968828305102e-06, 'epoch': 0.6114062343389797}\n",
      "{'loss': 1.7849, 'grad_norm': 13.74686336517334, 'learning_rate': 1.9379573017941268e-06, 'epoch': 0.6124085396411747}\n",
      "{'loss': 2.5485, 'grad_norm': 19.799457550048828, 'learning_rate': 1.9329457752831516e-06, 'epoch': 0.6134108449433697}\n",
      "{'loss': 1.5401, 'grad_norm': 69.4921646118164, 'learning_rate': 1.927934248772176e-06, 'epoch': 0.6144131502455648}\n",
      "{'loss': 3.1487, 'grad_norm': 13.80070972442627, 'learning_rate': 1.922922722261201e-06, 'epoch': 0.6154154555477599}\n",
      "{'loss': 2.3012, 'grad_norm': 18.87267303466797, 'learning_rate': 1.9179111957502255e-06, 'epoch': 0.6164177608499549}\n",
      "{'loss': 2.5778, 'grad_norm': 15.54175090789795, 'learning_rate': 1.9128996692392503e-06, 'epoch': 0.61742006615215}\n",
      "{'loss': 1.5202, 'grad_norm': 16.10654640197754, 'learning_rate': 1.907888142728275e-06, 'epoch': 0.618422371454345}\n",
      "{'loss': 1.5644, 'grad_norm': 14.767258644104004, 'learning_rate': 1.9028766162172999e-06, 'epoch': 0.61942467675654}\n",
      "{'loss': 1.9489, 'grad_norm': 19.044267654418945, 'learning_rate': 1.8978650897063246e-06, 'epoch': 0.6204269820587351}\n",
      "{'loss': 2.7603, 'grad_norm': 25.541831970214844, 'learning_rate': 1.8928535631953496e-06, 'epoch': 0.6214292873609302}\n",
      "{'loss': 1.6598, 'grad_norm': 13.265106201171875, 'learning_rate': 1.8878420366843742e-06, 'epoch': 0.6224315926631252}\n",
      "{'loss': 2.2758, 'grad_norm': 23.437667846679688, 'learning_rate': 1.882830510173399e-06, 'epoch': 0.6234338979653202}\n",
      "{'loss': 2.1224, 'grad_norm': 17.189495086669922, 'learning_rate': 1.8778189836624236e-06, 'epoch': 0.6244362032675153}\n",
      "{'loss': 2.1107, 'grad_norm': 18.521520614624023, 'learning_rate': 1.8728074571514484e-06, 'epoch': 0.6254385085697103}\n",
      "{'loss': 2.063, 'grad_norm': 17.060056686401367, 'learning_rate': 1.8677959306404734e-06, 'epoch': 0.6264408138719054}\n",
      "{'loss': 2.0137, 'grad_norm': 14.819575309753418, 'learning_rate': 1.862784404129498e-06, 'epoch': 0.6274431191741004}\n",
      "{'loss': 2.3232, 'grad_norm': 11.192570686340332, 'learning_rate': 1.8577728776185227e-06, 'epoch': 0.6284454244762955}\n",
      "{'loss': 1.6873, 'grad_norm': 19.01528549194336, 'learning_rate': 1.8527613511075477e-06, 'epoch': 0.6294477297784905}\n",
      "{'loss': 1.9527, 'grad_norm': 9.7551851272583, 'learning_rate': 1.8477498245965723e-06, 'epoch': 0.6304500350806855}\n",
      "{'loss': 1.0329, 'grad_norm': 24.627599716186523, 'learning_rate': 1.842738298085597e-06, 'epoch': 0.6314523403828807}\n",
      "{'loss': 1.1526, 'grad_norm': 8.722798347473145, 'learning_rate': 1.8377267715746217e-06, 'epoch': 0.6324546456850757}\n",
      "{'loss': 2.4957, 'grad_norm': 25.193349838256836, 'learning_rate': 1.8327152450636465e-06, 'epoch': 0.6334569509872707}\n",
      "{'loss': 1.766, 'grad_norm': 13.99744701385498, 'learning_rate': 1.8277037185526715e-06, 'epoch': 0.6344592562894658}\n",
      "{'loss': 1.2064, 'grad_norm': 20.685558319091797, 'learning_rate': 1.822692192041696e-06, 'epoch': 0.6354615615916608}\n",
      "{'loss': 1.6387, 'grad_norm': 24.73430061340332, 'learning_rate': 1.8176806655307208e-06, 'epoch': 0.6364638668938559}\n",
      "{'loss': 1.9114, 'grad_norm': 18.80787467956543, 'learning_rate': 1.8126691390197456e-06, 'epoch': 0.637466172196051}\n",
      "{'loss': 1.4467, 'grad_norm': 15.234659194946289, 'learning_rate': 1.8076576125087702e-06, 'epoch': 0.638468477498246}\n",
      "{'loss': 2.0441, 'grad_norm': 34.63645553588867, 'learning_rate': 1.8026460859977952e-06, 'epoch': 0.639470782800441}\n",
      "{'loss': 1.8051, 'grad_norm': 28.930805206298828, 'learning_rate': 1.7976345594868198e-06, 'epoch': 0.640473088102636}\n",
      "{'loss': 1.4357, 'grad_norm': 18.361434936523438, 'learning_rate': 1.7926230329758445e-06, 'epoch': 0.6414753934048311}\n",
      "{'loss': 1.9972, 'grad_norm': 23.253854751586914, 'learning_rate': 1.7876115064648693e-06, 'epoch': 0.6424776987070262}\n",
      "{'loss': 1.8093, 'grad_norm': 16.604827880859375, 'learning_rate': 1.782599979953894e-06, 'epoch': 0.6434800040092212}\n",
      "{'loss': 1.4995, 'grad_norm': 19.80672264099121, 'learning_rate': 1.777588453442919e-06, 'epoch': 0.6444823093114163}\n",
      "{'loss': 1.9524, 'grad_norm': 8.336345672607422, 'learning_rate': 1.7725769269319437e-06, 'epoch': 0.6454846146136113}\n",
      "{'loss': 1.6618, 'grad_norm': 20.65984344482422, 'learning_rate': 1.7675654004209683e-06, 'epoch': 0.6464869199158063}\n",
      "{'loss': 2.2829, 'grad_norm': 19.623233795166016, 'learning_rate': 1.7625538739099933e-06, 'epoch': 0.6474892252180015}\n",
      "{'loss': 1.4627, 'grad_norm': 13.694612503051758, 'learning_rate': 1.757542347399018e-06, 'epoch': 0.6484915305201965}\n",
      "{'loss': 1.5653, 'grad_norm': 20.947710037231445, 'learning_rate': 1.7525308208880426e-06, 'epoch': 0.6494938358223915}\n",
      "{'loss': 1.212, 'grad_norm': 0.0, 'learning_rate': 1.7475192943770674e-06, 'epoch': 0.6504961411245865}\n",
      "{'loss': 1.4947, 'grad_norm': 15.36255931854248, 'learning_rate': 1.742507767866092e-06, 'epoch': 0.6514984464267816}\n",
      "{'loss': 2.0197, 'grad_norm': 25.3331241607666, 'learning_rate': 1.737496241355117e-06, 'epoch': 0.6525007517289766}\n",
      "{'loss': 1.227, 'grad_norm': 8.890912055969238, 'learning_rate': 1.7324847148441418e-06, 'epoch': 0.6535030570311717}\n",
      "{'loss': 2.2685, 'grad_norm': 15.468182563781738, 'learning_rate': 1.7274731883331663e-06, 'epoch': 0.6545053623333668}\n",
      "{'loss': 2.3763, 'grad_norm': 18.10525131225586, 'learning_rate': 1.7224616618221911e-06, 'epoch': 0.6555076676355618}\n",
      "{'loss': 2.0121, 'grad_norm': 17.630422592163086, 'learning_rate': 1.7174501353112161e-06, 'epoch': 0.6565099729377568}\n",
      "{'loss': 1.9093, 'grad_norm': 29.37942886352539, 'learning_rate': 1.7124386088002407e-06, 'epoch': 0.6575122782399518}\n",
      "{'loss': 1.6991, 'grad_norm': 23.976093292236328, 'learning_rate': 1.7074270822892655e-06, 'epoch': 0.658514583542147}\n",
      "{'loss': 2.0176, 'grad_norm': 25.55145263671875, 'learning_rate': 1.70241555577829e-06, 'epoch': 0.659516888844342}\n",
      "{'loss': 1.5828, 'grad_norm': 24.170034408569336, 'learning_rate': 1.6974040292673149e-06, 'epoch': 0.660519194146537}\n",
      "{'loss': 2.6717, 'grad_norm': 21.209529876708984, 'learning_rate': 1.6923925027563399e-06, 'epoch': 0.6615214994487321}\n",
      "{'loss': 1.8472, 'grad_norm': 23.6422119140625, 'learning_rate': 1.6873809762453644e-06, 'epoch': 0.6625238047509271}\n",
      "{'loss': 1.3357, 'grad_norm': 9.43464469909668, 'learning_rate': 1.6823694497343892e-06, 'epoch': 0.6635261100531222}\n",
      "{'loss': 1.7138, 'grad_norm': 21.296524047851562, 'learning_rate': 1.6773579232234142e-06, 'epoch': 0.6645284153553173}\n",
      "{'loss': 1.7348, 'grad_norm': 10.786099433898926, 'learning_rate': 1.6723463967124388e-06, 'epoch': 0.6655307206575123}\n",
      "{'loss': 1.5571, 'grad_norm': 15.385625839233398, 'learning_rate': 1.6673348702014636e-06, 'epoch': 0.6665330259597073}\n",
      "{'loss': 1.4958, 'grad_norm': 7.019373416900635, 'learning_rate': 1.6623233436904882e-06, 'epoch': 0.6675353312619023}\n",
      "{'loss': 1.3588, 'grad_norm': 22.855941772460938, 'learning_rate': 1.657311817179513e-06, 'epoch': 0.6685376365640974}\n",
      "{'loss': 1.6927, 'grad_norm': 20.146991729736328, 'learning_rate': 1.652300290668538e-06, 'epoch': 0.6695399418662925}\n",
      "{'loss': 1.8929, 'grad_norm': 12.75666332244873, 'learning_rate': 1.6472887641575625e-06, 'epoch': 0.6705422471684875}\n",
      "{'loss': 1.2789, 'grad_norm': 9.290813446044922, 'learning_rate': 1.6422772376465873e-06, 'epoch': 0.6715445524706826}\n",
      "{'loss': 1.6143, 'grad_norm': 26.164331436157227, 'learning_rate': 1.637265711135612e-06, 'epoch': 0.6725468577728776}\n",
      "{'loss': 1.7525, 'grad_norm': 11.560271263122559, 'learning_rate': 1.6322541846246367e-06, 'epoch': 0.6735491630750726}\n",
      "{'loss': 0.9877, 'grad_norm': 19.13532066345215, 'learning_rate': 1.6272426581136617e-06, 'epoch': 0.6745514683772678}\n",
      "{'loss': 2.2388, 'grad_norm': 9.762094497680664, 'learning_rate': 1.6222311316026862e-06, 'epoch': 0.6755537736794628}\n",
      "{'loss': 1.7089, 'grad_norm': 25.330120086669922, 'learning_rate': 1.617219605091711e-06, 'epoch': 0.6765560789816578}\n",
      "{'loss': 2.2268, 'grad_norm': 14.032017707824707, 'learning_rate': 1.6122080785807358e-06, 'epoch': 0.6775583842838528}\n",
      "{'loss': 2.0939, 'grad_norm': 21.628599166870117, 'learning_rate': 1.6071965520697604e-06, 'epoch': 0.6785606895860479}\n",
      "{'loss': 1.6834, 'grad_norm': 27.170412063598633, 'learning_rate': 1.6021850255587854e-06, 'epoch': 0.679562994888243}\n",
      "{'loss': 1.0618, 'grad_norm': 6.867924690246582, 'learning_rate': 1.5971734990478102e-06, 'epoch': 0.680565300190438}\n",
      "{'loss': 1.9551, 'grad_norm': 17.240421295166016, 'learning_rate': 1.5921619725368348e-06, 'epoch': 0.6815676054926331}\n",
      "{'loss': 1.7818, 'grad_norm': 11.908332824707031, 'learning_rate': 1.5871504460258598e-06, 'epoch': 0.6825699107948281}\n",
      "{'loss': 1.6666, 'grad_norm': 24.442737579345703, 'learning_rate': 1.5821389195148843e-06, 'epoch': 0.6835722160970231}\n",
      "{'loss': 1.8108, 'grad_norm': 22.20199203491211, 'learning_rate': 1.5771273930039091e-06, 'epoch': 0.6845745213992181}\n",
      "{'loss': 1.6553, 'grad_norm': 29.395675659179688, 'learning_rate': 1.572115866492934e-06, 'epoch': 0.6855768267014133}\n",
      "{'loss': 1.2598, 'grad_norm': 43.544395446777344, 'learning_rate': 1.5671043399819585e-06, 'epoch': 0.6865791320036083}\n",
      "{'loss': 1.0877, 'grad_norm': 32.88429641723633, 'learning_rate': 1.5620928134709835e-06, 'epoch': 0.6875814373058033}\n",
      "{'loss': 2.2118, 'grad_norm': 24.007883071899414, 'learning_rate': 1.5570812869600083e-06, 'epoch': 0.6885837426079984}\n",
      "{'loss': 2.0107, 'grad_norm': 20.44447898864746, 'learning_rate': 1.5520697604490328e-06, 'epoch': 0.6895860479101934}\n",
      "{'loss': 1.5826, 'grad_norm': 25.832090377807617, 'learning_rate': 1.5470582339380576e-06, 'epoch': 0.6905883532123885}\n",
      "{'loss': 2.543, 'grad_norm': 19.98027229309082, 'learning_rate': 1.5420467074270822e-06, 'epoch': 0.6915906585145836}\n",
      "{'loss': 2.0866, 'grad_norm': 22.438045501708984, 'learning_rate': 1.5370351809161072e-06, 'epoch': 0.6925929638167786}\n",
      "{'loss': 1.5202, 'grad_norm': 10.620649337768555, 'learning_rate': 1.532023654405132e-06, 'epoch': 0.6935952691189736}\n",
      "{'loss': 2.1722, 'grad_norm': 11.667606353759766, 'learning_rate': 1.5270121278941566e-06, 'epoch': 0.6945975744211687}\n",
      "{'loss': 1.934, 'grad_norm': 22.439348220825195, 'learning_rate': 1.5220006013831814e-06, 'epoch': 0.6955998797233638}\n",
      "{'loss': 1.4177, 'grad_norm': 35.296600341796875, 'learning_rate': 1.5169890748722064e-06, 'epoch': 0.6966021850255588}\n",
      "{'loss': 1.839, 'grad_norm': 19.01930046081543, 'learning_rate': 1.511977548361231e-06, 'epoch': 0.6976044903277538}\n",
      "{'loss': 2.1838, 'grad_norm': 15.98401927947998, 'learning_rate': 1.5069660218502557e-06, 'epoch': 0.6986067956299489}\n",
      "{'loss': 2.2449, 'grad_norm': 22.488609313964844, 'learning_rate': 1.5019544953392803e-06, 'epoch': 0.6996091009321439}\n",
      "{'loss': 2.0572, 'grad_norm': 12.277952194213867, 'learning_rate': 1.4969429688283053e-06, 'epoch': 0.7006114062343389}\n",
      "{'loss': 1.9743, 'grad_norm': 16.082427978515625, 'learning_rate': 1.49193144231733e-06, 'epoch': 0.7016137115365341}\n",
      "{'loss': 1.1721, 'grad_norm': 27.28813934326172, 'learning_rate': 1.4869199158063547e-06, 'epoch': 0.7026160168387291}\n",
      "{'loss': 2.0396, 'grad_norm': 24.892152786254883, 'learning_rate': 1.4819083892953794e-06, 'epoch': 0.7036183221409241}\n",
      "{'loss': 2.0031, 'grad_norm': 13.602418899536133, 'learning_rate': 1.4768968627844044e-06, 'epoch': 0.7046206274431192}\n",
      "{'loss': 1.7544, 'grad_norm': 16.349260330200195, 'learning_rate': 1.471885336273429e-06, 'epoch': 0.7056229327453142}\n",
      "{'loss': 1.7999, 'grad_norm': 25.091495513916016, 'learning_rate': 1.4668738097624538e-06, 'epoch': 0.7066252380475093}\n",
      "{'loss': 1.4717, 'grad_norm': 6.215387344360352, 'learning_rate': 1.4618622832514784e-06, 'epoch': 0.7076275433497043}\n",
      "{'loss': 2.8179, 'grad_norm': 17.197416305541992, 'learning_rate': 1.4568507567405032e-06, 'epoch': 0.7086298486518994}\n",
      "{'loss': 2.763, 'grad_norm': 47.02121353149414, 'learning_rate': 1.4518392302295282e-06, 'epoch': 0.7096321539540944}\n",
      "{'loss': 1.5552, 'grad_norm': 37.890281677246094, 'learning_rate': 1.4468277037185527e-06, 'epoch': 0.7106344592562894}\n",
      "{'loss': 2.0055, 'grad_norm': 31.76397705078125, 'learning_rate': 1.4418161772075775e-06, 'epoch': 0.7116367645584846}\n",
      "{'loss': 1.9488, 'grad_norm': 18.86794090270996, 'learning_rate': 1.4368046506966023e-06, 'epoch': 0.7126390698606796}\n",
      "{'loss': 1.2766, 'grad_norm': 18.689990997314453, 'learning_rate': 1.4317931241856269e-06, 'epoch': 0.7136413751628746}\n",
      "{'loss': 1.7739, 'grad_norm': 28.496047973632812, 'learning_rate': 1.4267815976746519e-06, 'epoch': 0.7146436804650697}\n",
      "{'loss': 1.9167, 'grad_norm': 11.407424926757812, 'learning_rate': 1.4217700711636765e-06, 'epoch': 0.7156459857672647}\n",
      "{'loss': 2.0058, 'grad_norm': 14.864058494567871, 'learning_rate': 1.4167585446527012e-06, 'epoch': 0.7166482910694597}\n",
      "{'loss': 2.5858, 'grad_norm': 20.964475631713867, 'learning_rate': 1.4117470181417262e-06, 'epoch': 0.7176505963716548}\n",
      "{'loss': 1.8658, 'grad_norm': 15.94112777709961, 'learning_rate': 1.4067354916307508e-06, 'epoch': 0.7186529016738499}\n",
      "{'loss': 1.5858, 'grad_norm': 11.659048080444336, 'learning_rate': 1.4017239651197756e-06, 'epoch': 0.7196552069760449}\n",
      "{'loss': 1.1629, 'grad_norm': 12.475556373596191, 'learning_rate': 1.3967124386088004e-06, 'epoch': 0.7206575122782399}\n",
      "{'loss': 1.7784, 'grad_norm': 14.566603660583496, 'learning_rate': 1.391700912097825e-06, 'epoch': 0.721659817580435}\n",
      "{'loss': 2.165, 'grad_norm': 26.759260177612305, 'learning_rate': 1.38668938558685e-06, 'epoch': 0.7226621228826301}\n",
      "{'loss': 2.1891, 'grad_norm': 0.0, 'learning_rate': 1.3816778590758748e-06, 'epoch': 0.7236644281848251}\n",
      "{'loss': 1.6534, 'grad_norm': 3.715818405151367, 'learning_rate': 1.3766663325648993e-06, 'epoch': 0.7246667334870202}\n",
      "{'loss': 0.9932, 'grad_norm': 13.778925895690918, 'learning_rate': 1.3716548060539241e-06, 'epoch': 0.7256690387892152}\n",
      "{'loss': 2.6006, 'grad_norm': 12.679759979248047, 'learning_rate': 1.3666432795429487e-06, 'epoch': 0.7266713440914102}\n",
      "{'loss': 1.6207, 'grad_norm': 11.747459411621094, 'learning_rate': 1.3616317530319737e-06, 'epoch': 0.7276736493936052}\n",
      "{'loss': 2.4703, 'grad_norm': 31.573163986206055, 'learning_rate': 1.3566202265209985e-06, 'epoch': 0.7286759546958004}\n",
      "{'loss': 2.2817, 'grad_norm': 18.360511779785156, 'learning_rate': 1.351608700010023e-06, 'epoch': 0.7296782599979954}\n",
      "{'loss': 1.2642, 'grad_norm': 7.228450775146484, 'learning_rate': 1.3465971734990478e-06, 'epoch': 0.7306805653001904}\n",
      "{'loss': 1.8487, 'grad_norm': 20.746604919433594, 'learning_rate': 1.3415856469880728e-06, 'epoch': 0.7316828706023855}\n",
      "{'loss': 2.048, 'grad_norm': 18.066688537597656, 'learning_rate': 1.3365741204770974e-06, 'epoch': 0.7326851759045805}\n",
      "{'loss': 1.245, 'grad_norm': 15.942821502685547, 'learning_rate': 1.3315625939661222e-06, 'epoch': 0.7336874812067756}\n",
      "{'loss': 1.8158, 'grad_norm': 21.486480712890625, 'learning_rate': 1.3265510674551468e-06, 'epoch': 0.7346897865089707}\n",
      "{'loss': 1.5915, 'grad_norm': 21.225507736206055, 'learning_rate': 1.3215395409441718e-06, 'epoch': 0.7356920918111657}\n",
      "{'loss': 0.9899, 'grad_norm': 20.636415481567383, 'learning_rate': 1.3165280144331966e-06, 'epoch': 0.7366943971133607}\n",
      "{'loss': 1.7223, 'grad_norm': 21.809972763061523, 'learning_rate': 1.3115164879222211e-06, 'epoch': 0.7376967024155557}\n",
      "{'loss': 1.8062, 'grad_norm': 27.982561111450195, 'learning_rate': 1.306504961411246e-06, 'epoch': 0.7386990077177509}\n",
      "{'loss': 2.5996, 'grad_norm': 15.788095474243164, 'learning_rate': 1.301493434900271e-06, 'epoch': 0.7397013130199459}\n",
      "{'loss': 1.4791, 'grad_norm': 18.590913772583008, 'learning_rate': 1.2964819083892955e-06, 'epoch': 0.7407036183221409}\n",
      "{'loss': 2.0873, 'grad_norm': 10.891634941101074, 'learning_rate': 1.2914703818783203e-06, 'epoch': 0.741705923624336}\n",
      "{'loss': 2.2001, 'grad_norm': 24.6270751953125, 'learning_rate': 1.2864588553673449e-06, 'epoch': 0.742708228926531}\n",
      "{'loss': 1.5971, 'grad_norm': 23.63734245300293, 'learning_rate': 1.2814473288563697e-06, 'epoch': 0.743710534228726}\n",
      "{'loss': 2.7228, 'grad_norm': 15.085556983947754, 'learning_rate': 1.2764358023453947e-06, 'epoch': 0.7447128395309212}\n",
      "{'loss': 2.0584, 'grad_norm': 18.152219772338867, 'learning_rate': 1.2714242758344192e-06, 'epoch': 0.7457151448331162}\n",
      "{'loss': 1.5288, 'grad_norm': 20.107837677001953, 'learning_rate': 1.266412749323444e-06, 'epoch': 0.7467174501353112}\n",
      "{'loss': 1.5749, 'grad_norm': 22.26878547668457, 'learning_rate': 1.2614012228124688e-06, 'epoch': 0.7477197554375062}\n",
      "{'loss': 2.1968, 'grad_norm': 32.1392707824707, 'learning_rate': 1.2563896963014936e-06, 'epoch': 0.7487220607397013}\n",
      "{'loss': 3.0196, 'grad_norm': 34.94682312011719, 'learning_rate': 1.2513781697905184e-06, 'epoch': 0.7497243660418964}\n",
      "{'loss': 1.9334, 'grad_norm': 12.876938819885254, 'learning_rate': 1.2463666432795432e-06, 'epoch': 0.7507266713440914}\n",
      "{'loss': 1.3081, 'grad_norm': 18.60787010192871, 'learning_rate': 1.2413551167685677e-06, 'epoch': 0.7517289766462865}\n",
      "{'loss': 1.5743, 'grad_norm': 9.557378768920898, 'learning_rate': 1.2363435902575925e-06, 'epoch': 0.7527312819484815}\n",
      "{'loss': 1.4522, 'grad_norm': 15.12777042388916, 'learning_rate': 1.2313320637466173e-06, 'epoch': 0.7537335872506765}\n",
      "{'loss': 1.9504, 'grad_norm': 18.085453033447266, 'learning_rate': 1.226320537235642e-06, 'epoch': 0.7547358925528717}\n",
      "{'loss': 2.0095, 'grad_norm': 24.249574661254883, 'learning_rate': 1.2213090107246669e-06, 'epoch': 0.7557381978550667}\n",
      "{'loss': 1.8058, 'grad_norm': 14.451106071472168, 'learning_rate': 1.2162974842136915e-06, 'epoch': 0.7567405031572617}\n",
      "{'loss': 1.7366, 'grad_norm': 15.240290641784668, 'learning_rate': 1.2112859577027165e-06, 'epoch': 0.7577428084594567}\n",
      "{'loss': 2.0547, 'grad_norm': 22.765974044799805, 'learning_rate': 1.206274431191741e-06, 'epoch': 0.7587451137616518}\n",
      "{'loss': 1.9856, 'grad_norm': 26.78643798828125, 'learning_rate': 1.2012629046807658e-06, 'epoch': 0.7597474190638468}\n",
      "{'loss': 1.1137, 'grad_norm': 20.6516056060791, 'learning_rate': 1.1962513781697906e-06, 'epoch': 0.7607497243660419}\n",
      "{'loss': 1.802, 'grad_norm': 18.80110740661621, 'learning_rate': 1.1912398516588154e-06, 'epoch': 0.761752029668237}\n",
      "{'loss': 2.4362, 'grad_norm': 15.678092956542969, 'learning_rate': 1.1862283251478402e-06, 'epoch': 0.762754334970432}\n",
      "{'loss': 2.1941, 'grad_norm': 23.389171600341797, 'learning_rate': 1.1812167986368648e-06, 'epoch': 0.763756640272627}\n",
      "{'loss': 1.5558, 'grad_norm': 13.455206871032715, 'learning_rate': 1.1762052721258896e-06, 'epoch': 0.764758945574822}\n",
      "{'loss': 0.9621, 'grad_norm': 14.166265487670898, 'learning_rate': 1.1711937456149143e-06, 'epoch': 0.7657612508770172}\n",
      "{'loss': 1.7211, 'grad_norm': 20.50478172302246, 'learning_rate': 1.1661822191039391e-06, 'epoch': 0.7667635561792122}\n",
      "{'loss': 1.9187, 'grad_norm': 21.278993606567383, 'learning_rate': 1.161170692592964e-06, 'epoch': 0.7677658614814072}\n",
      "{'loss': 2.1338, 'grad_norm': 0.0, 'learning_rate': 1.1561591660819887e-06, 'epoch': 0.7687681667836023}\n",
      "{'loss': 1.8928, 'grad_norm': 21.835329055786133, 'learning_rate': 1.1511476395710135e-06, 'epoch': 0.7697704720857973}\n",
      "{'loss': 1.679, 'grad_norm': 32.61851119995117, 'learning_rate': 1.1461361130600383e-06, 'epoch': 0.7707727773879924}\n",
      "{'loss': 1.7761, 'grad_norm': 14.334002494812012, 'learning_rate': 1.1411245865490629e-06, 'epoch': 0.7717750826901875}\n",
      "{'loss': 2.3585, 'grad_norm': 20.58883285522461, 'learning_rate': 1.1361130600380876e-06, 'epoch': 0.7727773879923825}\n",
      "{'loss': 1.473, 'grad_norm': 21.058671951293945, 'learning_rate': 1.1311015335271124e-06, 'epoch': 0.7737796932945775}\n",
      "{'loss': 1.2935, 'grad_norm': 14.358698844909668, 'learning_rate': 1.1260900070161372e-06, 'epoch': 0.7747819985967725}\n",
      "{'loss': 1.4587, 'grad_norm': 14.664727210998535, 'learning_rate': 1.121078480505162e-06, 'epoch': 0.7757843038989676}\n",
      "{'loss': 2.4306, 'grad_norm': 20.704896926879883, 'learning_rate': 1.1160669539941866e-06, 'epoch': 0.7767866092011627}\n",
      "{'loss': 2.2702, 'grad_norm': 12.648483276367188, 'learning_rate': 1.1110554274832116e-06, 'epoch': 0.7777889145033577}\n",
      "{'loss': 1.9424, 'grad_norm': 4.854770660400391, 'learning_rate': 1.1060439009722362e-06, 'epoch': 0.7787912198055528}\n",
      "{'loss': 1.4162, 'grad_norm': 37.55738067626953, 'learning_rate': 1.101032374461261e-06, 'epoch': 0.7797935251077478}\n",
      "{'loss': 1.9328, 'grad_norm': 17.912357330322266, 'learning_rate': 1.0960208479502857e-06, 'epoch': 0.7807958304099428}\n",
      "{'loss': 1.5054, 'grad_norm': 11.69030475616455, 'learning_rate': 1.0910093214393105e-06, 'epoch': 0.781798135712138}\n",
      "{'loss': 1.6207, 'grad_norm': 25.83049964904785, 'learning_rate': 1.0859977949283353e-06, 'epoch': 0.782800441014333}\n",
      "{'loss': 1.4167, 'grad_norm': 17.635679244995117, 'learning_rate': 1.08098626841736e-06, 'epoch': 0.783802746316528}\n",
      "{'loss': 1.1671, 'grad_norm': 43.621891021728516, 'learning_rate': 1.0759747419063847e-06, 'epoch': 0.784805051618723}\n",
      "{'loss': 1.7497, 'grad_norm': 22.737041473388672, 'learning_rate': 1.0709632153954097e-06, 'epoch': 0.7858073569209181}\n",
      "{'loss': 1.6284, 'grad_norm': 13.95639705657959, 'learning_rate': 1.0659516888844342e-06, 'epoch': 0.7868096622231132}\n",
      "{'loss': 2.743, 'grad_norm': 17.602245330810547, 'learning_rate': 1.060940162373459e-06, 'epoch': 0.7878119675253082}\n",
      "{'loss': 1.6823, 'grad_norm': 6.952133655548096, 'learning_rate': 1.0559286358624838e-06, 'epoch': 0.7888142728275033}\n",
      "{'loss': 1.5863, 'grad_norm': 5.797457218170166, 'learning_rate': 1.0509171093515086e-06, 'epoch': 0.7898165781296983}\n",
      "{'loss': 1.6264, 'grad_norm': 16.84606170654297, 'learning_rate': 1.0459055828405334e-06, 'epoch': 0.7908188834318933}\n",
      "{'loss': 1.7329, 'grad_norm': 15.104601860046387, 'learning_rate': 1.040894056329558e-06, 'epoch': 0.7918211887340884}\n",
      "{'loss': 1.5188, 'grad_norm': 22.055524826049805, 'learning_rate': 1.035882529818583e-06, 'epoch': 0.7928234940362835}\n",
      "{'loss': 1.8705, 'grad_norm': 24.38692855834961, 'learning_rate': 1.0308710033076075e-06, 'epoch': 0.7938257993384785}\n",
      "{'loss': 1.2637, 'grad_norm': 15.951728820800781, 'learning_rate': 1.0258594767966323e-06, 'epoch': 0.7948281046406735}\n",
      "{'loss': 0.9738, 'grad_norm': 14.324845314025879, 'learning_rate': 1.0208479502856571e-06, 'epoch': 0.7958304099428686}\n",
      "{'loss': 1.6832, 'grad_norm': 28.89191246032715, 'learning_rate': 1.015836423774682e-06, 'epoch': 0.7968327152450636}\n",
      "{'loss': 1.84, 'grad_norm': 28.22456169128418, 'learning_rate': 1.0108248972637067e-06, 'epoch': 0.7978350205472587}\n",
      "{'loss': 1.9382, 'grad_norm': 16.033004760742188, 'learning_rate': 1.0058133707527313e-06, 'epoch': 0.7988373258494538}\n",
      "{'loss': 1.6542, 'grad_norm': 30.59048080444336, 'learning_rate': 1.000801844241756e-06, 'epoch': 0.7998396311516488}\n",
      "{'loss': 2.056, 'grad_norm': 17.14793586730957, 'learning_rate': 9.95790317730781e-07, 'epoch': 0.8008419364538438}\n",
      "{'loss': 1.7339, 'grad_norm': 12.45125675201416, 'learning_rate': 9.907787912198056e-07, 'epoch': 0.8018442417560389}\n",
      "{'loss': 1.0559, 'grad_norm': 7.567980766296387, 'learning_rate': 9.857672647088304e-07, 'epoch': 0.8028465470582339}\n",
      "{'loss': 2.3275, 'grad_norm': 20.7774658203125, 'learning_rate': 9.807557381978552e-07, 'epoch': 0.803848852360429}\n",
      "{'loss': 1.4034, 'grad_norm': 27.30914306640625, 'learning_rate': 9.7574421168688e-07, 'epoch': 0.804851157662624}\n",
      "{'loss': 1.8783, 'grad_norm': 17.43794822692871, 'learning_rate': 9.707326851759048e-07, 'epoch': 0.8058534629648191}\n",
      "{'loss': 1.6652, 'grad_norm': 11.755666732788086, 'learning_rate': 9.657211586649293e-07, 'epoch': 0.8068557682670141}\n",
      "{'loss': 1.7623, 'grad_norm': 21.60682487487793, 'learning_rate': 9.607096321539541e-07, 'epoch': 0.8078580735692091}\n",
      "{'loss': 1.8178, 'grad_norm': 27.11344337463379, 'learning_rate': 9.55698105642979e-07, 'epoch': 0.8088603788714043}\n",
      "{'loss': 2.4853, 'grad_norm': 21.18438720703125, 'learning_rate': 9.506865791320037e-07, 'epoch': 0.8098626841735993}\n",
      "{'loss': 2.3964, 'grad_norm': 14.51669692993164, 'learning_rate': 9.456750526210284e-07, 'epoch': 0.8108649894757943}\n",
      "{'loss': 1.7007, 'grad_norm': 15.34001636505127, 'learning_rate': 9.406635261100532e-07, 'epoch': 0.8118672947779894}\n",
      "{'loss': 1.718, 'grad_norm': 12.194077491760254, 'learning_rate': 9.35651999599078e-07, 'epoch': 0.8128696000801844}\n",
      "{'loss': 1.7168, 'grad_norm': 25.26068878173828, 'learning_rate': 9.306404730881028e-07, 'epoch': 0.8138719053823795}\n",
      "{'loss': 1.1732, 'grad_norm': 0.0, 'learning_rate': 9.256289465771274e-07, 'epoch': 0.8148742106845746}\n",
      "{'loss': 1.7168, 'grad_norm': 20.72665786743164, 'learning_rate': 9.206174200661522e-07, 'epoch': 0.8158765159867696}\n",
      "{'loss': 2.0715, 'grad_norm': 24.219810485839844, 'learning_rate': 9.15605893555177e-07, 'epoch': 0.8168788212889646}\n",
      "{'loss': 1.0146, 'grad_norm': 25.52149200439453, 'learning_rate': 9.105943670442018e-07, 'epoch': 0.8178811265911596}\n",
      "{'loss': 0.7938, 'grad_norm': 38.51618576049805, 'learning_rate': 9.055828405332265e-07, 'epoch': 0.8188834318933547}\n",
      "{'loss': 1.2875, 'grad_norm': 0.0, 'learning_rate': 9.005713140222512e-07, 'epoch': 0.8198857371955498}\n",
      "{'loss': 1.8057, 'grad_norm': 25.661405563354492, 'learning_rate': 8.95559787511276e-07, 'epoch': 0.8208880424977448}\n",
      "{'loss': 1.9723, 'grad_norm': 31.858076095581055, 'learning_rate': 8.905482610003007e-07, 'epoch': 0.8218903477999399}\n",
      "{'loss': 1.9817, 'grad_norm': 22.726715087890625, 'learning_rate': 8.855367344893255e-07, 'epoch': 0.8228926531021349}\n",
      "{'loss': 1.2503, 'grad_norm': 12.83688735961914, 'learning_rate': 8.805252079783502e-07, 'epoch': 0.8238949584043299}\n",
      "{'loss': 2.169, 'grad_norm': 22.262042999267578, 'learning_rate': 8.755136814673751e-07, 'epoch': 0.824897263706525}\n",
      "{'loss': 1.1341, 'grad_norm': 14.999442100524902, 'learning_rate': 8.705021549563998e-07, 'epoch': 0.8258995690087201}\n",
      "{'loss': 1.78, 'grad_norm': 21.883390426635742, 'learning_rate': 8.654906284454246e-07, 'epoch': 0.8269018743109151}\n",
      "{'loss': 1.7404, 'grad_norm': 19.550193786621094, 'learning_rate': 8.604791019344492e-07, 'epoch': 0.8279041796131101}\n",
      "{'loss': 1.7351, 'grad_norm': 0.0, 'learning_rate': 8.554675754234741e-07, 'epoch': 0.8289064849153052}\n",
      "{'loss': 2.3415, 'grad_norm': 22.715862274169922, 'learning_rate': 8.504560489124988e-07, 'epoch': 0.8299087902175003}\n",
      "{'loss': 2.3426, 'grad_norm': 18.32806396484375, 'learning_rate': 8.454445224015236e-07, 'epoch': 0.8309110955196953}\n",
      "{'loss': 1.7329, 'grad_norm': 19.654075622558594, 'learning_rate': 8.404329958905483e-07, 'epoch': 0.8319134008218904}\n",
      "{'loss': 1.8551, 'grad_norm': 28.15332794189453, 'learning_rate': 8.354214693795732e-07, 'epoch': 0.8329157061240854}\n",
      "{'loss': 1.9839, 'grad_norm': 25.9284725189209, 'learning_rate': 8.304099428685979e-07, 'epoch': 0.8339180114262804}\n",
      "{'loss': 2.1247, 'grad_norm': 12.422741889953613, 'learning_rate': 8.253984163576225e-07, 'epoch': 0.8349203167284754}\n",
      "{'loss': 1.7559, 'grad_norm': 19.066547393798828, 'learning_rate': 8.203868898466473e-07, 'epoch': 0.8359226220306706}\n",
      "{'loss': 1.2125, 'grad_norm': 17.331684112548828, 'learning_rate': 8.153753633356721e-07, 'epoch': 0.8369249273328656}\n",
      "{'loss': 2.0671, 'grad_norm': 19.33244514465332, 'learning_rate': 8.103638368246969e-07, 'epoch': 0.8379272326350606}\n",
      "{'loss': 2.0647, 'grad_norm': 24.542724609375, 'learning_rate': 8.053523103137216e-07, 'epoch': 0.8389295379372557}\n",
      "{'loss': 2.0058, 'grad_norm': 14.988444328308105, 'learning_rate': 8.003407838027464e-07, 'epoch': 0.8399318432394507}\n",
      "{'loss': 2.058, 'grad_norm': 52.024688720703125, 'learning_rate': 7.953292572917712e-07, 'epoch': 0.8409341485416458}\n",
      "{'loss': 1.6273, 'grad_norm': 12.559087753295898, 'learning_rate': 7.903177307807959e-07, 'epoch': 0.8419364538438409}\n",
      "{'loss': 1.9241, 'grad_norm': 30.33455467224121, 'learning_rate': 7.853062042698206e-07, 'epoch': 0.8429387591460359}\n",
      "{'loss': 2.0139, 'grad_norm': 12.851896286010742, 'learning_rate': 7.802946777588453e-07, 'epoch': 0.8439410644482309}\n",
      "{'loss': 2.1864, 'grad_norm': 22.946460723876953, 'learning_rate': 7.752831512478702e-07, 'epoch': 0.8449433697504259}\n",
      "{'loss': 1.9005, 'grad_norm': 22.85470199584961, 'learning_rate': 7.702716247368949e-07, 'epoch': 0.8459456750526211}\n",
      "{'loss': 1.9261, 'grad_norm': 15.711882591247559, 'learning_rate': 7.652600982259197e-07, 'epoch': 0.8469479803548161}\n",
      "{'loss': 1.6498, 'grad_norm': 25.072134017944336, 'learning_rate': 7.602485717149444e-07, 'epoch': 0.8479502856570111}\n",
      "{'loss': 1.3682, 'grad_norm': 18.63750648498535, 'learning_rate': 7.552370452039692e-07, 'epoch': 0.8489525909592062}\n",
      "{'loss': 2.0142, 'grad_norm': 32.25332260131836, 'learning_rate': 7.502255186929939e-07, 'epoch': 0.8499548962614012}\n",
      "{'loss': 1.8382, 'grad_norm': 23.210800170898438, 'learning_rate': 7.452139921820187e-07, 'epoch': 0.8509572015635962}\n",
      "{'loss': 2.3596, 'grad_norm': 28.3026123046875, 'learning_rate': 7.402024656710434e-07, 'epoch': 0.8519595068657914}\n",
      "{'loss': 1.627, 'grad_norm': 22.629770278930664, 'learning_rate': 7.351909391600683e-07, 'epoch': 0.8529618121679864}\n",
      "{'loss': 1.8761, 'grad_norm': 14.163463592529297, 'learning_rate': 7.30179412649093e-07, 'epoch': 0.8539641174701814}\n",
      "{'loss': 1.7713, 'grad_norm': 22.801883697509766, 'learning_rate': 7.251678861381177e-07, 'epoch': 0.8549664227723764}\n",
      "{'loss': 1.8383, 'grad_norm': 23.928937911987305, 'learning_rate': 7.201563596271424e-07, 'epoch': 0.8559687280745715}\n",
      "{'loss': 2.7524, 'grad_norm': 18.842729568481445, 'learning_rate': 7.151448331161673e-07, 'epoch': 0.8569710333767666}\n",
      "{'loss': 1.9582, 'grad_norm': 15.646851539611816, 'learning_rate': 7.10133306605192e-07, 'epoch': 0.8579733386789616}\n",
      "{'loss': 1.4788, 'grad_norm': 16.771759033203125, 'learning_rate': 7.051217800942167e-07, 'epoch': 0.8589756439811567}\n",
      "{'loss': 2.3761, 'grad_norm': 12.122095108032227, 'learning_rate': 7.001102535832415e-07, 'epoch': 0.8599779492833517}\n",
      "{'loss': 1.5086, 'grad_norm': 13.117817878723145, 'learning_rate': 6.950987270722663e-07, 'epoch': 0.8609802545855467}\n",
      "{'loss': 1.7786, 'grad_norm': 14.551653861999512, 'learning_rate': 6.900872005612911e-07, 'epoch': 0.8619825598877419}\n",
      "{'loss': 1.7682, 'grad_norm': 24.830692291259766, 'learning_rate': 6.850756740503157e-07, 'epoch': 0.8629848651899369}\n",
      "{'loss': 1.2286, 'grad_norm': 14.542632102966309, 'learning_rate': 6.800641475393406e-07, 'epoch': 0.8639871704921319}\n",
      "{'loss': 1.6956, 'grad_norm': 11.248918533325195, 'learning_rate': 6.750526210283653e-07, 'epoch': 0.864989475794327}\n",
      "{'loss': 2.0263, 'grad_norm': 13.969023704528809, 'learning_rate': 6.700410945173901e-07, 'epoch': 0.865991781096522}\n",
      "{'loss': 2.3168, 'grad_norm': 21.906566619873047, 'learning_rate': 6.650295680064148e-07, 'epoch': 0.866994086398717}\n",
      "{'loss': 2.1624, 'grad_norm': 13.343104362487793, 'learning_rate': 6.600180414954397e-07, 'epoch': 0.8679963917009121}\n",
      "{'loss': 2.2789, 'grad_norm': 27.97653579711914, 'learning_rate': 6.550065149844644e-07, 'epoch': 0.8689986970031072}\n",
      "{'loss': 1.8684, 'grad_norm': 33.34150695800781, 'learning_rate': 6.49994988473489e-07, 'epoch': 0.8700010023053022}\n",
      "{'loss': 2.068, 'grad_norm': 29.096210479736328, 'learning_rate': 6.449834619625138e-07, 'epoch': 0.8710033076074972}\n",
      "{'loss': 1.7155, 'grad_norm': 27.537837982177734, 'learning_rate': 6.399719354515386e-07, 'epoch': 0.8720056129096923}\n",
      "{'loss': 1.7769, 'grad_norm': 11.424225807189941, 'learning_rate': 6.349604089405634e-07, 'epoch': 0.8730079182118874}\n",
      "{'loss': 1.6403, 'grad_norm': 23.535640716552734, 'learning_rate': 6.299488824295881e-07, 'epoch': 0.8740102235140824}\n",
      "{'loss': 1.8449, 'grad_norm': 12.608829498291016, 'learning_rate': 6.249373559186129e-07, 'epoch': 0.8750125288162774}\n",
      "{'loss': 1.2089, 'grad_norm': 18.394126892089844, 'learning_rate': 6.199258294076377e-07, 'epoch': 0.8760148341184725}\n",
      "{'loss': 2.3385, 'grad_norm': 23.29644012451172, 'learning_rate': 6.149143028966624e-07, 'epoch': 0.8770171394206675}\n",
      "{'loss': 1.7538, 'grad_norm': 23.38736343383789, 'learning_rate': 6.099027763856871e-07, 'epoch': 0.8780194447228625}\n",
      "{'loss': 1.69, 'grad_norm': 24.92213249206543, 'learning_rate': 6.048912498747119e-07, 'epoch': 0.8790217500250577}\n",
      "{'loss': 2.5056, 'grad_norm': 22.65917205810547, 'learning_rate': 5.998797233637366e-07, 'epoch': 0.8800240553272527}\n",
      "{'loss': 1.1354, 'grad_norm': 61.037445068359375, 'learning_rate': 5.948681968527614e-07, 'epoch': 0.8810263606294477}\n",
      "{'loss': 1.1829, 'grad_norm': 35.12098693847656, 'learning_rate': 5.898566703417862e-07, 'epoch': 0.8820286659316428}\n",
      "{'loss': 1.371, 'grad_norm': 20.70281982421875, 'learning_rate': 5.84845143830811e-07, 'epoch': 0.8830309712338378}\n",
      "{'loss': 1.4738, 'grad_norm': 16.277774810791016, 'learning_rate': 5.798336173198356e-07, 'epoch': 0.8840332765360329}\n",
      "{'loss': 2.2533, 'grad_norm': 19.291725158691406, 'learning_rate': 5.748220908088604e-07, 'epoch': 0.885035581838228}\n",
      "{'loss': 2.1425, 'grad_norm': 20.487573623657227, 'learning_rate': 5.698105642978852e-07, 'epoch': 0.886037887140423}\n",
      "{'loss': 1.9358, 'grad_norm': 18.478849411010742, 'learning_rate': 5.6479903778691e-07, 'epoch': 0.887040192442618}\n",
      "{'loss': 1.6001, 'grad_norm': 23.597753524780273, 'learning_rate': 5.597875112759347e-07, 'epoch': 0.888042497744813}\n",
      "{'loss': 1.6495, 'grad_norm': 6.46192741394043, 'learning_rate': 5.547759847649595e-07, 'epoch': 0.8890448030470082}\n",
      "{'loss': 2.2167, 'grad_norm': 30.19916343688965, 'learning_rate': 5.497644582539841e-07, 'epoch': 0.8900471083492032}\n",
      "{'loss': 2.4106, 'grad_norm': 12.789665222167969, 'learning_rate': 5.44752931743009e-07, 'epoch': 0.8910494136513982}\n",
      "{'loss': 1.6941, 'grad_norm': 14.583744049072266, 'learning_rate': 5.397414052320337e-07, 'epoch': 0.8920517189535933}\n",
      "{'loss': 1.9855, 'grad_norm': 17.90545082092285, 'learning_rate': 5.347298787210585e-07, 'epoch': 0.8930540242557883}\n",
      "{'loss': 1.5126, 'grad_norm': 7.890397071838379, 'learning_rate': 5.297183522100832e-07, 'epoch': 0.8940563295579833}\n",
      "{'loss': 1.6874, 'grad_norm': 12.903464317321777, 'learning_rate': 5.24706825699108e-07, 'epoch': 0.8950586348601784}\n",
      "{'loss': 1.8854, 'grad_norm': 34.17465591430664, 'learning_rate': 5.196952991881328e-07, 'epoch': 0.8960609401623735}\n",
      "{'loss': 2.1189, 'grad_norm': 15.358769416809082, 'learning_rate': 5.146837726771575e-07, 'epoch': 0.8970632454645685}\n",
      "{'loss': 2.4476, 'grad_norm': 25.422164916992188, 'learning_rate': 5.096722461661822e-07, 'epoch': 0.8980655507667635}\n",
      "{'loss': 2.3659, 'grad_norm': 16.11573028564453, 'learning_rate': 5.04660719655207e-07, 'epoch': 0.8990678560689586}\n",
      "{'loss': 1.7677, 'grad_norm': 27.245059967041016, 'learning_rate': 4.996491931442318e-07, 'epoch': 0.9000701613711537}\n",
      "{'loss': 1.5128, 'grad_norm': 22.63775062561035, 'learning_rate': 4.946376666332566e-07, 'epoch': 0.9010724666733487}\n",
      "{'loss': 1.9231, 'grad_norm': 28.883026123046875, 'learning_rate': 4.896261401222813e-07, 'epoch': 0.9020747719755438}\n",
      "{'loss': 1.5697, 'grad_norm': 13.202535629272461, 'learning_rate': 4.846146136113061e-07, 'epoch': 0.9030770772777388}\n",
      "{'loss': 1.7837, 'grad_norm': 22.4156494140625, 'learning_rate': 4.796030871003307e-07, 'epoch': 0.9040793825799338}\n",
      "{'loss': 1.0699, 'grad_norm': 15.008858680725098, 'learning_rate': 4.745915605893556e-07, 'epoch': 0.905081687882129}\n",
      "{'loss': 2.1763, 'grad_norm': 18.363826751708984, 'learning_rate': 4.695800340783803e-07, 'epoch': 0.906083993184324}\n",
      "{'loss': 1.9773, 'grad_norm': 16.194746017456055, 'learning_rate': 4.645685075674051e-07, 'epoch': 0.907086298486519}\n",
      "{'loss': 1.5544, 'grad_norm': 12.009571075439453, 'learning_rate': 4.595569810564298e-07, 'epoch': 0.908088603788714}\n",
      "{'loss': 2.0948, 'grad_norm': 17.736806869506836, 'learning_rate': 4.5454545454545457e-07, 'epoch': 0.9090909090909091}\n",
      "{'loss': 1.6716, 'grad_norm': 31.57282257080078, 'learning_rate': 4.495339280344793e-07, 'epoch': 0.9100932143931041}\n",
      "{'loss': 2.111, 'grad_norm': 7.157641887664795, 'learning_rate': 4.445224015235041e-07, 'epoch': 0.9110955196952992}\n",
      "{'loss': 1.7805, 'grad_norm': 12.860553741455078, 'learning_rate': 4.3951087501252883e-07, 'epoch': 0.9120978249974943}\n",
      "{'loss': 1.7288, 'grad_norm': 25.345134735107422, 'learning_rate': 4.344993485015536e-07, 'epoch': 0.9131001302996893}\n",
      "{'loss': 1.3381, 'grad_norm': 17.870494842529297, 'learning_rate': 4.2948782199057835e-07, 'epoch': 0.9141024356018843}\n",
      "{'loss': 2.2941, 'grad_norm': 21.46088218688965, 'learning_rate': 4.2447629547960314e-07, 'epoch': 0.9151047409040793}\n",
      "{'loss': 1.4895, 'grad_norm': 39.424560546875, 'learning_rate': 4.1946476896862787e-07, 'epoch': 0.9161070462062745}\n",
      "{'loss': 2.1866, 'grad_norm': 16.784181594848633, 'learning_rate': 4.1445324245765266e-07, 'epoch': 0.9171093515084695}\n",
      "{'loss': 1.8891, 'grad_norm': 19.0873966217041, 'learning_rate': 4.0944171594667734e-07, 'epoch': 0.9181116568106645}\n",
      "{'loss': 1.6765, 'grad_norm': 23.292560577392578, 'learning_rate': 4.044301894357022e-07, 'epoch': 0.9191139621128596}\n",
      "{'loss': 1.89, 'grad_norm': 13.855417251586914, 'learning_rate': 3.9941866292472686e-07, 'epoch': 0.9201162674150546}\n",
      "{'loss': 2.314, 'grad_norm': 7.583832740783691, 'learning_rate': 3.9440713641375165e-07, 'epoch': 0.9211185727172497}\n",
      "{'loss': 1.3637, 'grad_norm': 30.94233512878418, 'learning_rate': 3.893956099027764e-07, 'epoch': 0.9221208780194448}\n",
      "{'loss': 1.1981, 'grad_norm': 12.521316528320312, 'learning_rate': 3.8438408339180117e-07, 'epoch': 0.9231231833216398}\n",
      "{'loss': 2.3202, 'grad_norm': 21.490478515625, 'learning_rate': 3.793725568808259e-07, 'epoch': 0.9241254886238348}\n",
      "{'loss': 2.4085, 'grad_norm': 23.166229248046875, 'learning_rate': 3.743610303698507e-07, 'epoch': 0.9251277939260298}\n",
      "{'loss': 1.8211, 'grad_norm': 19.77764892578125, 'learning_rate': 3.693495038588754e-07, 'epoch': 0.9261300992282249}\n",
      "{'loss': 1.8462, 'grad_norm': 24.834320068359375, 'learning_rate': 3.643379773479002e-07, 'epoch': 0.92713240453042}\n",
      "{'loss': 1.7312, 'grad_norm': 17.37371826171875, 'learning_rate': 3.5932645083692495e-07, 'epoch': 0.928134709832615}\n",
      "{'loss': 1.649, 'grad_norm': 19.604738235473633, 'learning_rate': 3.5431492432594974e-07, 'epoch': 0.9291370151348101}\n",
      "{'loss': 2.8807, 'grad_norm': 15.884188652038574, 'learning_rate': 3.493033978149744e-07, 'epoch': 0.9301393204370051}\n",
      "{'loss': 2.2831, 'grad_norm': 18.65757179260254, 'learning_rate': 3.442918713039992e-07, 'epoch': 0.9311416257392001}\n",
      "{'loss': 1.5466, 'grad_norm': 33.9162712097168, 'learning_rate': 3.3928034479302394e-07, 'epoch': 0.9321439310413953}\n",
      "{'loss': 1.4392, 'grad_norm': 26.375595092773438, 'learning_rate': 3.342688182820487e-07, 'epoch': 0.9331462363435903}\n",
      "{'loss': 1.9609, 'grad_norm': 13.728096008300781, 'learning_rate': 3.2925729177107346e-07, 'epoch': 0.9341485416457853}\n",
      "{'loss': 1.7067, 'grad_norm': 21.4542179107666, 'learning_rate': 3.2424576526009825e-07, 'epoch': 0.9351508469479803}\n",
      "{'loss': 2.2575, 'grad_norm': 16.806913375854492, 'learning_rate': 3.1923423874912303e-07, 'epoch': 0.9361531522501754}\n",
      "{'loss': 1.7034, 'grad_norm': 0.0, 'learning_rate': 3.1422271223814777e-07, 'epoch': 0.9371554575523704}\n",
      "{'loss': 2.328, 'grad_norm': 14.952293395996094, 'learning_rate': 3.092111857271725e-07, 'epoch': 0.9381577628545655}\n",
      "{'loss': 1.4086, 'grad_norm': 18.126880645751953, 'learning_rate': 3.041996592161973e-07, 'epoch': 0.9391600681567606}\n",
      "{'loss': 2.2261, 'grad_norm': 18.457117080688477, 'learning_rate': 2.99188132705222e-07, 'epoch': 0.9401623734589556}\n",
      "{'loss': 1.6196, 'grad_norm': 21.47428321838379, 'learning_rate': 2.941766061942468e-07, 'epoch': 0.9411646787611506}\n",
      "{'loss': 1.6758, 'grad_norm': 12.54623794555664, 'learning_rate': 2.8916507968327155e-07, 'epoch': 0.9421669840633456}\n",
      "{'loss': 1.4912, 'grad_norm': 20.378520965576172, 'learning_rate': 2.841535531722963e-07, 'epoch': 0.9431692893655408}\n",
      "{'loss': 1.2165, 'grad_norm': 13.446174621582031, 'learning_rate': 2.7914202666132107e-07, 'epoch': 0.9441715946677358}\n",
      "{'loss': 1.5166, 'grad_norm': 13.85741138458252, 'learning_rate': 2.741305001503458e-07, 'epoch': 0.9451738999699308}\n",
      "{'loss': 1.19, 'grad_norm': 25.6822509765625, 'learning_rate': 2.691189736393706e-07, 'epoch': 0.9461762052721259}\n",
      "{'loss': 1.5871, 'grad_norm': 20.258398056030273, 'learning_rate': 2.641074471283953e-07, 'epoch': 0.9471785105743209}\n",
      "{'loss': 2.078, 'grad_norm': 25.58857536315918, 'learning_rate': 2.5909592061742006e-07, 'epoch': 0.948180815876516}\n",
      "{'loss': 1.6868, 'grad_norm': 31.337373733520508, 'learning_rate': 2.5408439410644484e-07, 'epoch': 0.9491831211787111}\n",
      "{'loss': 1.8468, 'grad_norm': 28.141456604003906, 'learning_rate': 2.490728675954696e-07, 'epoch': 0.9501854264809061}\n",
      "{'loss': 2.2826, 'grad_norm': 13.05356502532959, 'learning_rate': 2.4406134108449437e-07, 'epoch': 0.9511877317831011}\n",
      "{'loss': 1.6254, 'grad_norm': 17.7492733001709, 'learning_rate': 2.390498145735191e-07, 'epoch': 0.9521900370852961}\n",
      "{'loss': 1.6296, 'grad_norm': 17.260173797607422, 'learning_rate': 2.3403828806254386e-07, 'epoch': 0.9531923423874912}\n",
      "{'loss': 1.607, 'grad_norm': 12.026115417480469, 'learning_rate': 2.2902676155156862e-07, 'epoch': 0.9541946476896863}\n",
      "{'loss': 1.6736, 'grad_norm': 11.287433624267578, 'learning_rate': 2.2401523504059338e-07, 'epoch': 0.9551969529918813}\n",
      "{'loss': 1.9715, 'grad_norm': 15.676373481750488, 'learning_rate': 2.1900370852961812e-07, 'epoch': 0.9561992582940764}\n",
      "{'loss': 1.4231, 'grad_norm': 11.989718437194824, 'learning_rate': 2.1399218201864288e-07, 'epoch': 0.9572015635962714}\n",
      "{'loss': 1.9288, 'grad_norm': 23.926788330078125, 'learning_rate': 2.0898065550766764e-07, 'epoch': 0.9582038688984664}\n",
      "{'loss': 2.0861, 'grad_norm': 27.717363357543945, 'learning_rate': 2.039691289966924e-07, 'epoch': 0.9592061742006616}\n",
      "{'loss': 2.0749, 'grad_norm': 12.374755859375, 'learning_rate': 1.9895760248571716e-07, 'epoch': 0.9602084795028566}\n",
      "{'loss': 1.824, 'grad_norm': 20.886760711669922, 'learning_rate': 1.9394607597474192e-07, 'epoch': 0.9612107848050516}\n",
      "{'loss': 1.711, 'grad_norm': 24.889724731445312, 'learning_rate': 1.8893454946376665e-07, 'epoch': 0.9622130901072466}\n",
      "{'loss': 1.4324, 'grad_norm': 21.330318450927734, 'learning_rate': 1.8392302295279142e-07, 'epoch': 0.9632153954094417}\n",
      "{'loss': 1.6622, 'grad_norm': 21.992359161376953, 'learning_rate': 1.7891149644181618e-07, 'epoch': 0.9642177007116368}\n",
      "{'loss': 2.3158, 'grad_norm': 22.81171417236328, 'learning_rate': 1.7389996993084094e-07, 'epoch': 0.9652200060138318}\n",
      "{'loss': 2.0963, 'grad_norm': 17.924222946166992, 'learning_rate': 1.688884434198657e-07, 'epoch': 0.9662223113160269}\n",
      "{'loss': 1.6044, 'grad_norm': 22.678813934326172, 'learning_rate': 1.6387691690889046e-07, 'epoch': 0.9672246166182219}\n",
      "{'loss': 1.7217, 'grad_norm': 25.45572280883789, 'learning_rate': 1.588653903979152e-07, 'epoch': 0.9682269219204169}\n",
      "{'loss': 1.6087, 'grad_norm': 22.412748336791992, 'learning_rate': 1.5385386388693998e-07, 'epoch': 0.969229227222612}\n",
      "{'loss': 2.7148, 'grad_norm': 14.33699893951416, 'learning_rate': 1.4884233737596474e-07, 'epoch': 0.9702315325248071}\n",
      "{'loss': 1.1493, 'grad_norm': 28.558528900146484, 'learning_rate': 1.4383081086498947e-07, 'epoch': 0.9712338378270021}\n",
      "{'loss': 2.0645, 'grad_norm': 26.33506965637207, 'learning_rate': 1.3881928435401424e-07, 'epoch': 0.9722361431291972}\n",
      "{'loss': 1.6158, 'grad_norm': 18.333463668823242, 'learning_rate': 1.33807757843039e-07, 'epoch': 0.9732384484313922}\n",
      "{'loss': 1.44, 'grad_norm': 14.62443733215332, 'learning_rate': 1.2879623133206376e-07, 'epoch': 0.9742407537335872}\n",
      "{'loss': 1.9234, 'grad_norm': 18.53670310974121, 'learning_rate': 1.2378470482108852e-07, 'epoch': 0.9752430590357823}\n",
      "{'loss': 1.9074, 'grad_norm': 16.20378875732422, 'learning_rate': 1.1877317831011327e-07, 'epoch': 0.9762453643379774}\n",
      "{'loss': 2.0293, 'grad_norm': 15.63719367980957, 'learning_rate': 1.1376165179913803e-07, 'epoch': 0.9772476696401724}\n",
      "{'loss': 1.8663, 'grad_norm': 0.0, 'learning_rate': 1.0875012528816277e-07, 'epoch': 0.9782499749423674}\n",
      "{'loss': 1.5386, 'grad_norm': 12.850590705871582, 'learning_rate': 1.0373859877718753e-07, 'epoch': 0.9792522802445625}\n",
      "{'loss': 1.5185, 'grad_norm': 13.59787368774414, 'learning_rate': 9.87270722662123e-08, 'epoch': 0.9802545855467576}\n",
      "{'loss': 2.1865, 'grad_norm': 15.894773483276367, 'learning_rate': 9.371554575523704e-08, 'epoch': 0.9812568908489526}\n",
      "{'loss': 1.7449, 'grad_norm': 30.14683723449707, 'learning_rate': 8.87040192442618e-08, 'epoch': 0.9822591961511477}\n",
      "{'loss': 1.4397, 'grad_norm': 20.23345947265625, 'learning_rate': 8.369249273328656e-08, 'epoch': 0.9832615014533427}\n",
      "{'loss': 1.9818, 'grad_norm': 25.916656494140625, 'learning_rate': 7.868096622231131e-08, 'epoch': 0.9842638067555377}\n",
      "{'loss': 1.8917, 'grad_norm': 28.26260757446289, 'learning_rate': 7.366943971133609e-08, 'epoch': 0.9852661120577327}\n",
      "{'loss': 1.3093, 'grad_norm': 20.70667839050293, 'learning_rate': 6.865791320036083e-08, 'epoch': 0.9862684173599279}\n",
      "{'loss': 1.7982, 'grad_norm': 17.01548957824707, 'learning_rate': 6.36463866893856e-08, 'epoch': 0.9872707226621229}\n",
      "{'loss': 0.7249, 'grad_norm': 0.0, 'learning_rate': 5.863486017841035e-08, 'epoch': 0.9882730279643179}\n",
      "{'loss': 2.3876, 'grad_norm': 19.09221076965332, 'learning_rate': 5.36233336674351e-08, 'epoch': 0.989275333266513}\n",
      "{'loss': 1.1867, 'grad_norm': 30.874080657958984, 'learning_rate': 4.861180715645986e-08, 'epoch': 0.990277638568708}\n",
      "{'loss': 1.8133, 'grad_norm': 9.81879997253418, 'learning_rate': 4.360028064548462e-08, 'epoch': 0.9912799438709031}\n",
      "{'loss': 1.0218, 'grad_norm': 24.970783233642578, 'learning_rate': 3.858875413450937e-08, 'epoch': 0.9922822491730982}\n",
      "{'loss': 1.9039, 'grad_norm': 14.296759605407715, 'learning_rate': 3.357722762353413e-08, 'epoch': 0.9932845544752932}\n",
      "{'loss': 1.8241, 'grad_norm': 22.311079025268555, 'learning_rate': 2.856570111255889e-08, 'epoch': 0.9942868597774882}\n",
      "{'loss': 1.9678, 'grad_norm': 21.81912612915039, 'learning_rate': 2.3554174601583647e-08, 'epoch': 0.9952891650796832}\n",
      "{'loss': 1.5243, 'grad_norm': 22.397489547729492, 'learning_rate': 1.85426480906084e-08, 'epoch': 0.9962914703818784}\n",
      "{'loss': 1.7028, 'grad_norm': 31.9311580657959, 'learning_rate': 1.3531121579633159e-08, 'epoch': 0.9972937756840734}\n",
      "{'loss': 1.9384, 'grad_norm': 14.447050094604492, 'learning_rate': 8.519595068657914e-09, 'epoch': 0.9982960809862684}\n",
      "{'loss': 1.6072, 'grad_norm': 26.711244583129883, 'learning_rate': 3.5080685576826705e-09, 'epoch': 0.9992983862884635}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9d884d2c8844c5931fd6a93530bdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_runtime': 357.4155, 'eval_samples_per_second': 6.955, 'eval_steps_per_second': 6.955, 'epoch': 1.0}\n",
      "{'train_runtime': 9916.5914, 'train_samples_per_second': 2.012, 'train_steps_per_second': 1.006, 'train_loss': 2.152799887397646, 'epoch': 1.0}\n",
      "[COMPLETE] Elapsed: 9916.80s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7fe30c482ad0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train the Llama 3.2 model with the quest data\n",
    "llama32_trainer: Trainer = llama32_model.tokenize_and_train(quest_set)\n",
    "llama32_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7bf488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DOWNLOAD] tinyllama-1.1b-chat (TinyLlama/TinyLlama-1.1B-Chat-v1.0)\n",
      "[LoRAINFO] trainable params: 6,307,840 || all params: 621,914,112 || trainable%: 1.0143\n",
      "[COMPLETE] \"tinyllama-1.1b-chat\" ready in 46.91s.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuestGenLLM(tokenizer=LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama-1.1B-Chat-v1.0', vocab_size=32000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "), model=PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       "), model_key='tinyllama-1.1b-chat', model_id='TinyLlama/TinyLlama-1.1B-Chat-v1.0', fp16_available=True, device='cuda:0', dtype='float32')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the TinyLlama model\n",
    "tinyllama_model: QuestGenLLM = QuestGenLLM.from_pretrained(\n",
    "    model_key=\"tinyllama-1.1b-chat\", model_id=MODEL_IDENTIFIERS[\"tinyllama-1.1b-chat\"]\n",
    ")\n",
    "tinyllama_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0a31f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOKENIZE] tinyllama-1.1b-chat (TinyLlama/TinyLlama-1.1B-Chat-v1.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfd650d8a4c4d00a09d05108581ddd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19954 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4f9e291ab04f52992a672fd91d60f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMPLETE] Elapsed: 1.59s\n",
      "\n",
      "[FINETUNE] tinyllama-1.1b-chat (TinyLlama/TinyLlama-1.1B-Chat-v1.0)\n",
      "{'loss': 4.6219, 'grad_norm': 5.794121742248535, 'learning_rate': 4.994988473489026e-06, 'epoch': 0.0010023053021950487}\n",
      "{'loss': 4.3511, 'grad_norm': 8.858926773071289, 'learning_rate': 4.98997694697805e-06, 'epoch': 0.0020046106043900974}\n",
      "{'loss': 4.4122, 'grad_norm': 8.283576965332031, 'learning_rate': 4.984965420467074e-06, 'epoch': 0.0030069159065851457}\n",
      "{'loss': 4.7192, 'grad_norm': 5.620419979095459, 'learning_rate': 4.9799538939560996e-06, 'epoch': 0.004009221208780195}\n",
      "{'loss': 4.6064, 'grad_norm': 7.443430423736572, 'learning_rate': 4.974942367445124e-06, 'epoch': 0.005011526510975243}\n",
      "{'loss': 4.2972, 'grad_norm': 6.061771392822266, 'learning_rate': 4.969930840934149e-06, 'epoch': 0.006013831813170291}\n",
      "{'loss': 4.413, 'grad_norm': 6.0641398429870605, 'learning_rate': 4.9649193144231735e-06, 'epoch': 0.00701613711536534}\n",
      "{'loss': 4.259, 'grad_norm': 6.6521453857421875, 'learning_rate': 4.959907787912199e-06, 'epoch': 0.00801844241756039}\n",
      "{'loss': 4.0255, 'grad_norm': 6.9097418785095215, 'learning_rate': 4.954896261401223e-06, 'epoch': 0.009020747719755437}\n",
      "{'loss': 3.9917, 'grad_norm': 5.87017297744751, 'learning_rate': 4.949884734890248e-06, 'epoch': 0.010023053021950485}\n",
      "{'loss': 4.1143, 'grad_norm': 11.801094055175781, 'learning_rate': 4.944873208379273e-06, 'epoch': 0.011025358324145534}\n",
      "{'loss': 4.0142, 'grad_norm': 5.559512138366699, 'learning_rate': 4.939861681868298e-06, 'epoch': 0.012027663626340583}\n",
      "{'loss': 3.7959, 'grad_norm': 8.669825553894043, 'learning_rate': 4.934850155357322e-06, 'epoch': 0.013029968928535631}\n",
      "{'loss': 3.1517, 'grad_norm': 4.330870628356934, 'learning_rate': 4.929838628846347e-06, 'epoch': 0.01403227423073068}\n",
      "{'loss': 3.8267, 'grad_norm': 7.528854846954346, 'learning_rate': 4.924827102335372e-06, 'epoch': 0.015034579532925729}\n",
      "{'loss': 3.5143, 'grad_norm': 6.0271711349487305, 'learning_rate': 4.919815575824396e-06, 'epoch': 0.01603688483512078}\n",
      "{'loss': 4.0694, 'grad_norm': 6.849555492401123, 'learning_rate': 4.914804049313421e-06, 'epoch': 0.017039190137315828}\n",
      "{'loss': 3.5929, 'grad_norm': 11.478789329528809, 'learning_rate': 4.909792522802447e-06, 'epoch': 0.018041495439510873}\n",
      "{'loss': 4.2044, 'grad_norm': 7.334666728973389, 'learning_rate': 4.904780996291471e-06, 'epoch': 0.019043800741705922}\n",
      "{'loss': 3.9097, 'grad_norm': 6.7780280113220215, 'learning_rate': 4.899769469780495e-06, 'epoch': 0.02004610604390097}\n",
      "{'loss': 3.9365, 'grad_norm': 6.163989543914795, 'learning_rate': 4.8947579432695205e-06, 'epoch': 0.02104841134609602}\n",
      "{'loss': 3.5074, 'grad_norm': 4.10105562210083, 'learning_rate': 4.889746416758545e-06, 'epoch': 0.022050716648291068}\n",
      "{'loss': 3.5617, 'grad_norm': 9.600977897644043, 'learning_rate': 4.88473489024757e-06, 'epoch': 0.023053021950486117}\n",
      "{'loss': 2.9519, 'grad_norm': 5.533262729644775, 'learning_rate': 4.8797233637365945e-06, 'epoch': 0.024055327252681166}\n",
      "{'loss': 3.4526, 'grad_norm': 5.099752426147461, 'learning_rate': 4.874711837225619e-06, 'epoch': 0.025057632554876214}\n",
      "{'loss': 3.6043, 'grad_norm': 7.60128927230835, 'learning_rate': 4.869700310714644e-06, 'epoch': 0.026059937857071263}\n",
      "{'loss': 3.6388, 'grad_norm': 5.5349555015563965, 'learning_rate': 4.864688784203669e-06, 'epoch': 0.02706224315926631}\n",
      "{'loss': 3.2494, 'grad_norm': 6.906347751617432, 'learning_rate': 4.859677257692694e-06, 'epoch': 0.02806454846146136}\n",
      "{'loss': 3.5765, 'grad_norm': 6.800473213195801, 'learning_rate': 4.854665731181719e-06, 'epoch': 0.02906685376365641}\n",
      "{'loss': 3.05, 'grad_norm': 11.752552032470703, 'learning_rate': 4.849654204670743e-06, 'epoch': 0.030069159065851458}\n",
      "{'loss': 3.4946, 'grad_norm': 4.572638034820557, 'learning_rate': 4.8446426781597675e-06, 'epoch': 0.031071464368046506}\n",
      "{'loss': 3.1408, 'grad_norm': 8.493046760559082, 'learning_rate': 4.839631151648793e-06, 'epoch': 0.03207376967024156}\n",
      "{'loss': 2.7898, 'grad_norm': 6.391335964202881, 'learning_rate': 4.834619625137817e-06, 'epoch': 0.03307607497243661}\n",
      "{'loss': 3.396, 'grad_norm': 19.573375701904297, 'learning_rate': 4.829608098626842e-06, 'epoch': 0.034078380274631656}\n",
      "{'loss': 2.7525, 'grad_norm': 11.258013725280762, 'learning_rate': 4.824596572115867e-06, 'epoch': 0.035080685576826705}\n",
      "{'loss': 3.2418, 'grad_norm': 13.893001556396484, 'learning_rate': 4.819585045604892e-06, 'epoch': 0.03608299087902175}\n",
      "{'loss': 3.3717, 'grad_norm': 4.910453796386719, 'learning_rate': 4.814573519093916e-06, 'epoch': 0.037085296181216795}\n",
      "{'loss': 3.0225, 'grad_norm': 19.042057037353516, 'learning_rate': 4.8095619925829415e-06, 'epoch': 0.038087601483411844}\n",
      "{'loss': 2.6408, 'grad_norm': 8.795781135559082, 'learning_rate': 4.804550466071966e-06, 'epoch': 0.03908990678560689}\n",
      "{'loss': 3.0807, 'grad_norm': 10.67573356628418, 'learning_rate': 4.799538939560991e-06, 'epoch': 0.04009221208780194}\n",
      "{'loss': 2.5529, 'grad_norm': 8.179611206054688, 'learning_rate': 4.794527413050015e-06, 'epoch': 0.04109451738999699}\n",
      "{'loss': 2.5193, 'grad_norm': 6.986227512359619, 'learning_rate': 4.78951588653904e-06, 'epoch': 0.04209682269219204}\n",
      "{'loss': 2.54, 'grad_norm': 11.2771577835083, 'learning_rate': 4.784504360028065e-06, 'epoch': 0.04309912799438709}\n",
      "{'loss': 3.0068, 'grad_norm': 20.192319869995117, 'learning_rate': 4.77949283351709e-06, 'epoch': 0.044101433296582136}\n",
      "{'loss': 3.1534, 'grad_norm': 6.464644432067871, 'learning_rate': 4.7744813070061146e-06, 'epoch': 0.045103738598777185}\n",
      "{'loss': 2.488, 'grad_norm': 19.31744384765625, 'learning_rate': 4.769469780495139e-06, 'epoch': 0.046106043900972234}\n",
      "{'loss': 2.6282, 'grad_norm': 17.837711334228516, 'learning_rate': 4.764458253984164e-06, 'epoch': 0.04710834920316728}\n",
      "{'loss': 2.1488, 'grad_norm': 10.630842208862305, 'learning_rate': 4.7594467274731885e-06, 'epoch': 0.04811065450536233}\n",
      "{'loss': 2.9219, 'grad_norm': 23.94199562072754, 'learning_rate': 4.754435200962214e-06, 'epoch': 0.04911295980755738}\n",
      "{'loss': 2.2346, 'grad_norm': 7.722855091094971, 'learning_rate': 4.749423674451238e-06, 'epoch': 0.05011526510975243}\n",
      "{'loss': 2.6193, 'grad_norm': 6.10984992980957, 'learning_rate': 4.7444121479402624e-06, 'epoch': 0.05111757041194748}\n",
      "{'loss': 2.5231, 'grad_norm': 8.682435989379883, 'learning_rate': 4.739400621429288e-06, 'epoch': 0.052119875714142526}\n",
      "{'loss': 2.0652, 'grad_norm': 20.917972564697266, 'learning_rate': 4.734389094918313e-06, 'epoch': 0.053122181016337575}\n",
      "{'loss': 2.4651, 'grad_norm': 10.525022506713867, 'learning_rate': 4.729377568407337e-06, 'epoch': 0.05412448631853262}\n",
      "{'loss': 1.8096, 'grad_norm': 8.253711700439453, 'learning_rate': 4.7243660418963624e-06, 'epoch': 0.05512679162072767}\n",
      "{'loss': 2.0834, 'grad_norm': 8.234801292419434, 'learning_rate': 4.719354515385387e-06, 'epoch': 0.05612909692292272}\n",
      "{'loss': 2.0622, 'grad_norm': 8.333616256713867, 'learning_rate': 4.714342988874411e-06, 'epoch': 0.05713140222511777}\n",
      "{'loss': 2.3344, 'grad_norm': 16.752498626708984, 'learning_rate': 4.709331462363436e-06, 'epoch': 0.05813370752731282}\n",
      "{'loss': 2.8058, 'grad_norm': 12.066044807434082, 'learning_rate': 4.704319935852461e-06, 'epoch': 0.05913601282950787}\n",
      "{'loss': 1.6582, 'grad_norm': 21.506357192993164, 'learning_rate': 4.699308409341486e-06, 'epoch': 0.060138318131702916}\n",
      "{'loss': 2.2703, 'grad_norm': 26.61865997314453, 'learning_rate': 4.694296882830511e-06, 'epoch': 0.061140623433897964}\n",
      "{'loss': 2.165, 'grad_norm': 11.927509307861328, 'learning_rate': 4.689285356319535e-06, 'epoch': 0.06214292873609301}\n",
      "{'loss': 2.7949, 'grad_norm': 8.64112377166748, 'learning_rate': 4.68427382980856e-06, 'epoch': 0.06314523403828806}\n",
      "{'loss': 2.1233, 'grad_norm': 22.025859832763672, 'learning_rate': 4.679262303297585e-06, 'epoch': 0.06414753934048312}\n",
      "{'loss': 1.8149, 'grad_norm': 11.218350410461426, 'learning_rate': 4.6742507767866095e-06, 'epoch': 0.06514984464267816}\n",
      "{'loss': 1.9349, 'grad_norm': 7.840991497039795, 'learning_rate': 4.669239250275635e-06, 'epoch': 0.06615214994487321}\n",
      "{'loss': 1.9712, 'grad_norm': 8.712388038635254, 'learning_rate': 4.664227723764659e-06, 'epoch': 0.06715445524706826}\n",
      "{'loss': 1.423, 'grad_norm': 12.546646118164062, 'learning_rate': 4.659216197253683e-06, 'epoch': 0.06815676054926331}\n",
      "{'loss': 2.3316, 'grad_norm': 8.953971862792969, 'learning_rate': 4.654204670742709e-06, 'epoch': 0.06915906585145835}\n",
      "{'loss': 2.462, 'grad_norm': 34.652313232421875, 'learning_rate': 4.649193144231734e-06, 'epoch': 0.07016137115365341}\n",
      "{'loss': 2.0339, 'grad_norm': 8.05300235748291, 'learning_rate': 4.644181617720758e-06, 'epoch': 0.07116367645584845}\n",
      "{'loss': 1.9623, 'grad_norm': 12.6895112991333, 'learning_rate': 4.639170091209783e-06, 'epoch': 0.0721659817580435}\n",
      "{'loss': 1.7795, 'grad_norm': 19.307607650756836, 'learning_rate': 4.634158564698808e-06, 'epoch': 0.07316828706023855}\n",
      "{'loss': 2.4651, 'grad_norm': 40.272518157958984, 'learning_rate': 4.629147038187832e-06, 'epoch': 0.07417059236243359}\n",
      "{'loss': 2.6418, 'grad_norm': 27.14664077758789, 'learning_rate': 4.624135511676857e-06, 'epoch': 0.07517289766462865}\n",
      "{'loss': 1.9505, 'grad_norm': 6.743839263916016, 'learning_rate': 4.619123985165882e-06, 'epoch': 0.07617520296682369}\n",
      "{'loss': 2.1283, 'grad_norm': 19.398080825805664, 'learning_rate': 4.614112458654907e-06, 'epoch': 0.07717750826901874}\n",
      "{'loss': 1.7463, 'grad_norm': 16.907365798950195, 'learning_rate': 4.609100932143931e-06, 'epoch': 0.07817981357121379}\n",
      "{'loss': 1.7098, 'grad_norm': 46.89305114746094, 'learning_rate': 4.604089405632956e-06, 'epoch': 0.07918211887340884}\n",
      "{'loss': 2.1561, 'grad_norm': 8.723442077636719, 'learning_rate': 4.599077879121981e-06, 'epoch': 0.08018442417560388}\n",
      "{'loss': 2.1197, 'grad_norm': 15.305167198181152, 'learning_rate': 4.594066352611006e-06, 'epoch': 0.08118672947779894}\n",
      "{'loss': 2.0232, 'grad_norm': 8.248736381530762, 'learning_rate': 4.58905482610003e-06, 'epoch': 0.08218903477999398}\n",
      "{'loss': 1.9301, 'grad_norm': 15.36130428314209, 'learning_rate': 4.584043299589056e-06, 'epoch': 0.08319134008218904}\n",
      "{'loss': 1.2509, 'grad_norm': 11.872076034545898, 'learning_rate': 4.57903177307808e-06, 'epoch': 0.08419364538438408}\n",
      "{'loss': 1.4433, 'grad_norm': 11.163718223571777, 'learning_rate': 4.574020246567104e-06, 'epoch': 0.08519595068657913}\n",
      "{'loss': 1.9576, 'grad_norm': 16.407548904418945, 'learning_rate': 4.5690087200561296e-06, 'epoch': 0.08619825598877418}\n",
      "{'loss': 1.5314, 'grad_norm': 8.458722114562988, 'learning_rate': 4.563997193545155e-06, 'epoch': 0.08720056129096923}\n",
      "{'loss': 2.0491, 'grad_norm': 29.48937225341797, 'learning_rate': 4.558985667034179e-06, 'epoch': 0.08820286659316427}\n",
      "{'loss': 2.5006, 'grad_norm': 17.03314781188965, 'learning_rate': 4.5539741405232035e-06, 'epoch': 0.08920517189535933}\n",
      "{'loss': 2.236, 'grad_norm': 25.027172088623047, 'learning_rate': 4.548962614012229e-06, 'epoch': 0.09020747719755437}\n",
      "{'loss': 2.1902, 'grad_norm': 15.496479034423828, 'learning_rate': 4.543951087501253e-06, 'epoch': 0.09120978249974943}\n",
      "{'loss': 1.624, 'grad_norm': 11.275654792785645, 'learning_rate': 4.538939560990278e-06, 'epoch': 0.09221208780194447}\n",
      "{'loss': 2.3026, 'grad_norm': 12.639338493347168, 'learning_rate': 4.533928034479303e-06, 'epoch': 0.09321439310413952}\n",
      "{'loss': 2.1936, 'grad_norm': 49.87843322753906, 'learning_rate': 4.528916507968327e-06, 'epoch': 0.09421669840633456}\n",
      "{'loss': 2.4437, 'grad_norm': 23.465412139892578, 'learning_rate': 4.523904981457352e-06, 'epoch': 0.09521900370852962}\n",
      "{'loss': 1.9003, 'grad_norm': 5.9673590660095215, 'learning_rate': 4.518893454946377e-06, 'epoch': 0.09622130901072466}\n",
      "{'loss': 2.0485, 'grad_norm': 20.135499954223633, 'learning_rate': 4.513881928435402e-06, 'epoch': 0.09722361431291972}\n",
      "{'loss': 1.681, 'grad_norm': 13.924528121948242, 'learning_rate': 4.508870401924427e-06, 'epoch': 0.09822591961511476}\n",
      "{'loss': 1.8194, 'grad_norm': 8.911381721496582, 'learning_rate': 4.503858875413451e-06, 'epoch': 0.09922822491730982}\n",
      "{'loss': 1.6969, 'grad_norm': 12.924745559692383, 'learning_rate': 4.498847348902476e-06, 'epoch': 0.10023053021950486}\n",
      "{'loss': 1.7062, 'grad_norm': 0.0, 'learning_rate': 4.493835822391501e-06, 'epoch': 0.10123283552169991}\n",
      "{'loss': 1.8981, 'grad_norm': 14.829939842224121, 'learning_rate': 4.488824295880525e-06, 'epoch': 0.10223514082389495}\n",
      "{'loss': 1.9248, 'grad_norm': 16.612926483154297, 'learning_rate': 4.4838127693695505e-06, 'epoch': 0.10323744612609001}\n",
      "{'loss': 1.815, 'grad_norm': 21.529008865356445, 'learning_rate': 4.478801242858576e-06, 'epoch': 0.10423975142828505}\n",
      "{'loss': 1.8403, 'grad_norm': 6.88084602355957, 'learning_rate': 4.473789716347599e-06, 'epoch': 0.10524205673048011}\n",
      "{'loss': 1.5148, 'grad_norm': 7.8790788650512695, 'learning_rate': 4.4687781898366245e-06, 'epoch': 0.10624436203267515}\n",
      "{'loss': 1.4545, 'grad_norm': 9.546725273132324, 'learning_rate': 4.46376666332565e-06, 'epoch': 0.1072466673348702}\n",
      "{'loss': 1.8225, 'grad_norm': 14.2974271774292, 'learning_rate': 4.458755136814674e-06, 'epoch': 0.10824897263706525}\n",
      "{'loss': 0.9473, 'grad_norm': 17.827547073364258, 'learning_rate': 4.453743610303699e-06, 'epoch': 0.1092512779392603}\n",
      "{'loss': 2.4398, 'grad_norm': 9.194403648376465, 'learning_rate': 4.448732083792724e-06, 'epoch': 0.11025358324145534}\n",
      "{'loss': 2.1138, 'grad_norm': 9.076650619506836, 'learning_rate': 4.443720557281748e-06, 'epoch': 0.1112558885436504}\n",
      "{'loss': 1.601, 'grad_norm': 19.59773063659668, 'learning_rate': 4.438709030770773e-06, 'epoch': 0.11225819384584544}\n",
      "{'loss': 2.0346, 'grad_norm': 16.63969612121582, 'learning_rate': 4.4336975042597976e-06, 'epoch': 0.1132604991480405}\n",
      "{'loss': 1.6684, 'grad_norm': 12.672318458557129, 'learning_rate': 4.428685977748823e-06, 'epoch': 0.11426280445023554}\n",
      "{'loss': 1.4656, 'grad_norm': 0.0, 'learning_rate': 4.423674451237848e-06, 'epoch': 0.1152651097524306}\n",
      "{'loss': 1.6615, 'grad_norm': 14.93428897857666, 'learning_rate': 4.418662924726872e-06, 'epoch': 0.11626741505462564}\n",
      "{'loss': 1.7401, 'grad_norm': 21.85869026184082, 'learning_rate': 4.413651398215897e-06, 'epoch': 0.11726972035682069}\n",
      "{'loss': 1.764, 'grad_norm': 15.18657398223877, 'learning_rate': 4.408639871704922e-06, 'epoch': 0.11827202565901573}\n",
      "{'loss': 1.94, 'grad_norm': 20.05885887145996, 'learning_rate': 4.403628345193946e-06, 'epoch': 0.11927433096121079}\n",
      "{'loss': 1.7941, 'grad_norm': 14.435506820678711, 'learning_rate': 4.3986168186829715e-06, 'epoch': 0.12027663626340583}\n",
      "{'loss': 2.0585, 'grad_norm': 21.175704956054688, 'learning_rate': 4.393605292171996e-06, 'epoch': 0.12127894156560089}\n",
      "{'loss': 1.2992, 'grad_norm': 10.993672370910645, 'learning_rate': 4.38859376566102e-06, 'epoch': 0.12228124686779593}\n",
      "{'loss': 1.4815, 'grad_norm': 9.20276165008545, 'learning_rate': 4.3835822391500454e-06, 'epoch': 0.12328355216999098}\n",
      "{'loss': 2.0662, 'grad_norm': 15.53120231628418, 'learning_rate': 4.378570712639071e-06, 'epoch': 0.12428585747218603}\n",
      "{'loss': 1.575, 'grad_norm': 13.09457778930664, 'learning_rate': 4.373559186128095e-06, 'epoch': 0.12528816277438107}\n",
      "{'loss': 1.7392, 'grad_norm': 17.591794967651367, 'learning_rate': 4.368547659617119e-06, 'epoch': 0.12629046807657612}\n",
      "{'loss': 2.2821, 'grad_norm': 9.521756172180176, 'learning_rate': 4.3635361331061446e-06, 'epoch': 0.12729277337877118}\n",
      "{'loss': 1.4244, 'grad_norm': 13.75451946258545, 'learning_rate': 4.358524606595169e-06, 'epoch': 0.12829507868096623}\n",
      "{'loss': 1.6905, 'grad_norm': 12.836149215698242, 'learning_rate': 4.353513080084194e-06, 'epoch': 0.12929738398316126}\n",
      "{'loss': 1.3426, 'grad_norm': 9.823179244995117, 'learning_rate': 4.3485015535732185e-06, 'epoch': 0.13029968928535632}\n",
      "{'loss': 1.4199, 'grad_norm': 8.514260292053223, 'learning_rate': 4.343490027062244e-06, 'epoch': 0.13130199458755137}\n",
      "{'loss': 1.7283, 'grad_norm': 11.965036392211914, 'learning_rate': 4.338478500551268e-06, 'epoch': 0.13230429988974643}\n",
      "{'loss': 1.5248, 'grad_norm': 7.573356628417969, 'learning_rate': 4.333466974040293e-06, 'epoch': 0.13330660519194146}\n",
      "{'loss': 1.1973, 'grad_norm': 18.616779327392578, 'learning_rate': 4.328455447529318e-06, 'epoch': 0.1343089104941365}\n",
      "{'loss': 1.6393, 'grad_norm': 19.712812423706055, 'learning_rate': 4.323443921018343e-06, 'epoch': 0.13531121579633157}\n",
      "{'loss': 1.8416, 'grad_norm': 12.296982765197754, 'learning_rate': 4.318432394507367e-06, 'epoch': 0.13631352109852662}\n",
      "{'loss': 1.6776, 'grad_norm': 18.7890625, 'learning_rate': 4.313420867996392e-06, 'epoch': 0.13731582640072165}\n",
      "{'loss': 2.1923, 'grad_norm': 13.145612716674805, 'learning_rate': 4.308409341485417e-06, 'epoch': 0.1383181317029167}\n",
      "{'loss': 1.9576, 'grad_norm': 10.513411521911621, 'learning_rate': 4.303397814974441e-06, 'epoch': 0.13932043700511176}\n",
      "{'loss': 1.4762, 'grad_norm': 13.781749725341797, 'learning_rate': 4.298386288463466e-06, 'epoch': 0.14032274230730682}\n",
      "{'loss': 2.3405, 'grad_norm': 12.868745803833008, 'learning_rate': 4.293374761952492e-06, 'epoch': 0.14132504760950185}\n",
      "{'loss': 1.7104, 'grad_norm': 14.760950088500977, 'learning_rate': 4.288363235441516e-06, 'epoch': 0.1423273529116969}\n",
      "{'loss': 1.3521, 'grad_norm': 9.739056587219238, 'learning_rate': 4.28335170893054e-06, 'epoch': 0.14332965821389196}\n",
      "{'loss': 1.6203, 'grad_norm': 38.734439849853516, 'learning_rate': 4.2783401824195655e-06, 'epoch': 0.144331963516087}\n",
      "{'loss': 1.7382, 'grad_norm': 27.075828552246094, 'learning_rate': 4.27332865590859e-06, 'epoch': 0.14533426881828204}\n",
      "{'loss': 1.4592, 'grad_norm': 11.367018699645996, 'learning_rate': 4.268317129397615e-06, 'epoch': 0.1463365741204771}\n",
      "{'loss': 1.9331, 'grad_norm': 10.976602554321289, 'learning_rate': 4.2633056028866395e-06, 'epoch': 0.14733887942267215}\n",
      "{'loss': 1.7379, 'grad_norm': 17.685457229614258, 'learning_rate': 4.258294076375664e-06, 'epoch': 0.14834118472486718}\n",
      "{'loss': 1.8488, 'grad_norm': 10.485870361328125, 'learning_rate': 4.253282549864689e-06, 'epoch': 0.14934349002706224}\n",
      "{'loss': 1.551, 'grad_norm': 17.783952713012695, 'learning_rate': 4.248271023353714e-06, 'epoch': 0.1503457953292573}\n",
      "{'loss': 1.851, 'grad_norm': 25.512510299682617, 'learning_rate': 4.243259496842739e-06, 'epoch': 0.15134810063145235}\n",
      "{'loss': 1.7882, 'grad_norm': 12.01619815826416, 'learning_rate': 4.238247970331764e-06, 'epoch': 0.15235040593364738}\n",
      "{'loss': 1.8473, 'grad_norm': 11.93115234375, 'learning_rate': 4.233236443820788e-06, 'epoch': 0.15335271123584243}\n",
      "{'loss': 1.6606, 'grad_norm': 8.259739875793457, 'learning_rate': 4.2282249173098126e-06, 'epoch': 0.1543550165380375}\n",
      "{'loss': 1.3912, 'grad_norm': 22.708045959472656, 'learning_rate': 4.223213390798838e-06, 'epoch': 0.15535732184023254}\n",
      "{'loss': 1.4504, 'grad_norm': 25.088563919067383, 'learning_rate': 4.218201864287862e-06, 'epoch': 0.15635962714242757}\n",
      "{'loss': 1.2143, 'grad_norm': 28.520030975341797, 'learning_rate': 4.213190337776887e-06, 'epoch': 0.15736193244462263}\n",
      "{'loss': 1.7482, 'grad_norm': 23.78306770324707, 'learning_rate': 4.2081788112659126e-06, 'epoch': 0.15836423774681768}\n",
      "{'loss': 1.1801, 'grad_norm': 20.64284324645996, 'learning_rate': 4.203167284754937e-06, 'epoch': 0.15936654304901274}\n",
      "{'loss': 2.4675, 'grad_norm': 12.839051246643066, 'learning_rate': 4.198155758243961e-06, 'epoch': 0.16036884835120777}\n",
      "{'loss': 1.2474, 'grad_norm': 14.165437698364258, 'learning_rate': 4.1931442317329865e-06, 'epoch': 0.16137115365340282}\n",
      "{'loss': 1.3127, 'grad_norm': 11.31954574584961, 'learning_rate': 4.188132705222011e-06, 'epoch': 0.16237345895559788}\n",
      "{'loss': 1.47, 'grad_norm': 13.719023704528809, 'learning_rate': 4.183121178711036e-06, 'epoch': 0.16337576425779293}\n",
      "{'loss': 1.857, 'grad_norm': 9.305301666259766, 'learning_rate': 4.1781096522000604e-06, 'epoch': 0.16437806955998796}\n",
      "{'loss': 1.7556, 'grad_norm': 10.951638221740723, 'learning_rate': 4.173098125689085e-06, 'epoch': 0.16538037486218302}\n",
      "{'loss': 1.3914, 'grad_norm': 13.351691246032715, 'learning_rate': 4.16808659917811e-06, 'epoch': 0.16638268016437807}\n",
      "{'loss': 1.1853, 'grad_norm': 10.841851234436035, 'learning_rate': 4.163075072667135e-06, 'epoch': 0.16738498546657313}\n",
      "{'loss': 1.5867, 'grad_norm': 8.403009414672852, 'learning_rate': 4.15806354615616e-06, 'epoch': 0.16838729076876816}\n",
      "{'loss': 2.126, 'grad_norm': 12.25013542175293, 'learning_rate': 4.153052019645184e-06, 'epoch': 0.1693895960709632}\n",
      "{'loss': 1.6736, 'grad_norm': 13.384834289550781, 'learning_rate': 4.148040493134209e-06, 'epoch': 0.17039190137315827}\n",
      "{'loss': 1.4152, 'grad_norm': 11.514062881469727, 'learning_rate': 4.1430289666232335e-06, 'epoch': 0.17139420667535332}\n",
      "{'loss': 1.7088, 'grad_norm': 41.96517562866211, 'learning_rate': 4.138017440112259e-06, 'epoch': 0.17239651197754835}\n",
      "{'loss': 2.0682, 'grad_norm': 14.696319580078125, 'learning_rate': 4.133005913601283e-06, 'epoch': 0.1733988172797434}\n",
      "{'loss': 1.1756, 'grad_norm': 10.4326171875, 'learning_rate': 4.127994387090308e-06, 'epoch': 0.17440112258193846}\n",
      "{'loss': 1.6386, 'grad_norm': 15.212648391723633, 'learning_rate': 4.122982860579333e-06, 'epoch': 0.17540342788413352}\n",
      "{'loss': 1.5932, 'grad_norm': 5.400369167327881, 'learning_rate': 4.117971334068358e-06, 'epoch': 0.17640573318632854}\n",
      "{'loss': 1.296, 'grad_norm': 42.000911712646484, 'learning_rate': 4.112959807557382e-06, 'epoch': 0.1774080384885236}\n",
      "{'loss': 1.5188, 'grad_norm': 29.08897590637207, 'learning_rate': 4.1079482810464075e-06, 'epoch': 0.17841034379071866}\n",
      "{'loss': 1.3953, 'grad_norm': 26.243457794189453, 'learning_rate': 4.102936754535432e-06, 'epoch': 0.1794126490929137}\n",
      "{'loss': 1.1341, 'grad_norm': 46.066368103027344, 'learning_rate': 4.097925228024456e-06, 'epoch': 0.18041495439510874}\n",
      "{'loss': 1.0604, 'grad_norm': 14.988798141479492, 'learning_rate': 4.092913701513481e-06, 'epoch': 0.1814172596973038}\n",
      "{'loss': 1.8492, 'grad_norm': 8.569936752319336, 'learning_rate': 4.087902175002506e-06, 'epoch': 0.18241956499949885}\n",
      "{'loss': 0.9158, 'grad_norm': 9.69682788848877, 'learning_rate': 4.082890648491531e-06, 'epoch': 0.1834218703016939}\n",
      "{'loss': 1.7567, 'grad_norm': 24.520051956176758, 'learning_rate': 4.077879121980556e-06, 'epoch': 0.18442417560388893}\n",
      "{'loss': 1.8917, 'grad_norm': 20.46912384033203, 'learning_rate': 4.07286759546958e-06, 'epoch': 0.185426480906084}\n",
      "{'loss': 1.6717, 'grad_norm': 16.267414093017578, 'learning_rate': 4.067856068958605e-06, 'epoch': 0.18642878620827905}\n",
      "{'loss': 2.0421, 'grad_norm': 8.546273231506348, 'learning_rate': 4.06284454244763e-06, 'epoch': 0.1874310915104741}\n",
      "{'loss': 1.9618, 'grad_norm': 12.40135669708252, 'learning_rate': 4.0578330159366545e-06, 'epoch': 0.18843339681266913}\n",
      "{'loss': 2.0322, 'grad_norm': 32.66621780395508, 'learning_rate': 4.05282148942568e-06, 'epoch': 0.18943570211486419}\n",
      "{'loss': 1.4785, 'grad_norm': 11.545618057250977, 'learning_rate': 4.047809962914704e-06, 'epoch': 0.19043800741705924}\n",
      "{'loss': 1.6688, 'grad_norm': 18.977313995361328, 'learning_rate': 4.042798436403728e-06, 'epoch': 0.1914403127192543}\n",
      "{'loss': 1.8924, 'grad_norm': 9.31162166595459, 'learning_rate': 4.037786909892754e-06, 'epoch': 0.19244261802144932}\n",
      "{'loss': 1.3588, 'grad_norm': 27.039155960083008, 'learning_rate': 4.032775383381779e-06, 'epoch': 0.19344492332364438}\n",
      "{'loss': 1.7176, 'grad_norm': 10.815805435180664, 'learning_rate': 4.027763856870803e-06, 'epoch': 0.19444722862583944}\n",
      "{'loss': 1.2276, 'grad_norm': 12.8059720993042, 'learning_rate': 4.022752330359828e-06, 'epoch': 0.1954495339280345}\n",
      "{'loss': 1.0525, 'grad_norm': 24.517833709716797, 'learning_rate': 4.017740803848853e-06, 'epoch': 0.19645183923022952}\n",
      "{'loss': 2.0298, 'grad_norm': 25.853668212890625, 'learning_rate': 4.012729277337877e-06, 'epoch': 0.19745414453242457}\n",
      "{'loss': 2.3031, 'grad_norm': 23.14749526977539, 'learning_rate': 4.007717750826902e-06, 'epoch': 0.19845644983461963}\n",
      "{'loss': 1.7856, 'grad_norm': 17.83686065673828, 'learning_rate': 4.002706224315927e-06, 'epoch': 0.19945875513681469}\n",
      "{'loss': 1.333, 'grad_norm': 39.46674346923828, 'learning_rate': 3.997694697804952e-06, 'epoch': 0.20046106043900971}\n",
      "{'loss': 2.1197, 'grad_norm': 21.149106979370117, 'learning_rate': 3.992683171293976e-06, 'epoch': 0.20146336574120477}\n",
      "{'loss': 1.5885, 'grad_norm': 16.386831283569336, 'learning_rate': 3.987671644783001e-06, 'epoch': 0.20246567104339983}\n",
      "{'loss': 1.5355, 'grad_norm': 20.027324676513672, 'learning_rate': 3.982660118272026e-06, 'epoch': 0.20346797634559488}\n",
      "{'loss': 1.7606, 'grad_norm': 16.0662899017334, 'learning_rate': 3.977648591761051e-06, 'epoch': 0.2044702816477899}\n",
      "{'loss': 2.353, 'grad_norm': 13.957605361938477, 'learning_rate': 3.9726370652500754e-06, 'epoch': 0.20547258694998496}\n",
      "{'loss': 1.1858, 'grad_norm': 11.279585838317871, 'learning_rate': 3.967625538739101e-06, 'epoch': 0.20647489225218002}\n",
      "{'loss': 1.8818, 'grad_norm': 9.988555908203125, 'learning_rate': 3.962614012228125e-06, 'epoch': 0.20747719755437508}\n",
      "{'loss': 1.7514, 'grad_norm': 12.27441692352295, 'learning_rate': 3.957602485717149e-06, 'epoch': 0.2084795028565701}\n",
      "{'loss': 1.6699, 'grad_norm': 15.707575798034668, 'learning_rate': 3.952590959206175e-06, 'epoch': 0.20948180815876516}\n",
      "{'loss': 1.9811, 'grad_norm': 9.229166030883789, 'learning_rate': 3.9475794326952e-06, 'epoch': 0.21048411346096021}\n",
      "{'loss': 0.8194, 'grad_norm': 16.97968292236328, 'learning_rate': 3.942567906184224e-06, 'epoch': 0.21148641876315527}\n",
      "{'loss': 1.4186, 'grad_norm': 21.55064582824707, 'learning_rate': 3.9375563796732485e-06, 'epoch': 0.2124887240653503}\n",
      "{'loss': 2.0464, 'grad_norm': 9.634988784790039, 'learning_rate': 3.932544853162274e-06, 'epoch': 0.21349102936754535}\n",
      "{'loss': 1.7849, 'grad_norm': 13.44455337524414, 'learning_rate': 3.927533326651298e-06, 'epoch': 0.2144933346697404}\n",
      "{'loss': 1.3443, 'grad_norm': 18.962038040161133, 'learning_rate': 3.922521800140323e-06, 'epoch': 0.21549563997193547}\n",
      "{'loss': 1.6899, 'grad_norm': 13.336822509765625, 'learning_rate': 3.917510273629348e-06, 'epoch': 0.2164979452741305}\n",
      "{'loss': 2.1564, 'grad_norm': 7.837423801422119, 'learning_rate': 3.912498747118373e-06, 'epoch': 0.21750025057632555}\n",
      "{'loss': 1.3926, 'grad_norm': 20.931943893432617, 'learning_rate': 3.907487220607397e-06, 'epoch': 0.2185025558785206}\n",
      "{'loss': 1.2436, 'grad_norm': 0.0, 'learning_rate': 3.902475694096422e-06, 'epoch': 0.21950486118071563}\n",
      "{'loss': 1.653, 'grad_norm': 8.648045539855957, 'learning_rate': 3.897464167585447e-06, 'epoch': 0.2205071664829107}\n",
      "{'loss': 1.2668, 'grad_norm': 26.706512451171875, 'learning_rate': 3.892452641074472e-06, 'epoch': 0.22150947178510574}\n",
      "{'loss': 1.4196, 'grad_norm': 18.40035057067871, 'learning_rate': 3.887441114563496e-06, 'epoch': 0.2225117770873008}\n",
      "{'loss': 1.4457, 'grad_norm': 16.719087600708008, 'learning_rate': 3.882429588052521e-06, 'epoch': 0.22351408238949583}\n",
      "{'loss': 1.7825, 'grad_norm': 13.52329158782959, 'learning_rate': 3.877418061541546e-06, 'epoch': 0.22451638769169088}\n",
      "{'loss': 2.0102, 'grad_norm': 11.773704528808594, 'learning_rate': 3.87240653503057e-06, 'epoch': 0.22551869299388594}\n",
      "{'loss': 1.7918, 'grad_norm': 11.722807884216309, 'learning_rate': 3.8673950085195955e-06, 'epoch': 0.226520998296081}\n",
      "{'loss': 2.397, 'grad_norm': 12.461357116699219, 'learning_rate': 3.862383482008621e-06, 'epoch': 0.22752330359827602}\n",
      "{'loss': 1.4619, 'grad_norm': 12.121415138244629, 'learning_rate': 3.857371955497644e-06, 'epoch': 0.22852560890047108}\n",
      "{'loss': 1.0886, 'grad_norm': 9.64728832244873, 'learning_rate': 3.8523604289866695e-06, 'epoch': 0.22952791420266613}\n",
      "{'loss': 0.9808, 'grad_norm': 23.392675399780273, 'learning_rate': 3.847348902475695e-06, 'epoch': 0.2305302195048612}\n",
      "{'loss': 1.5725, 'grad_norm': 7.871192932128906, 'learning_rate': 3.842337375964719e-06, 'epoch': 0.23153252480705622}\n",
      "{'loss': 1.8379, 'grad_norm': 14.381857872009277, 'learning_rate': 3.837325849453744e-06, 'epoch': 0.23253483010925127}\n",
      "{'loss': 1.5262, 'grad_norm': 10.031742095947266, 'learning_rate': 3.832314322942769e-06, 'epoch': 0.23353713541144633}\n",
      "{'loss': 1.4647, 'grad_norm': 9.104089736938477, 'learning_rate': 3.827302796431793e-06, 'epoch': 0.23453944071364138}\n",
      "{'loss': 1.2839, 'grad_norm': 12.35684585571289, 'learning_rate': 3.822291269920818e-06, 'epoch': 0.2355417460158364}\n",
      "{'loss': 1.3771, 'grad_norm': 11.943660736083984, 'learning_rate': 3.8172797434098426e-06, 'epoch': 0.23654405131803147}\n",
      "{'loss': 1.9919, 'grad_norm': 14.543713569641113, 'learning_rate': 3.8122682168988678e-06, 'epoch': 0.23754635662022652}\n",
      "{'loss': 1.0062, 'grad_norm': 28.480649948120117, 'learning_rate': 3.8072566903878926e-06, 'epoch': 0.23854866192242158}\n",
      "{'loss': 1.2494, 'grad_norm': 26.398330688476562, 'learning_rate': 3.802245163876917e-06, 'epoch': 0.2395509672246166}\n",
      "{'loss': 2.0073, 'grad_norm': 30.66295623779297, 'learning_rate': 3.7972336373659417e-06, 'epoch': 0.24055327252681166}\n",
      "{'loss': 1.5231, 'grad_norm': 11.49563980102539, 'learning_rate': 3.792222110854967e-06, 'epoch': 0.24155557782900672}\n",
      "{'loss': 1.4705, 'grad_norm': 35.36079406738281, 'learning_rate': 3.7872105843439917e-06, 'epoch': 0.24255788313120177}\n",
      "{'loss': 1.2553, 'grad_norm': 11.253860473632812, 'learning_rate': 3.7821990578330165e-06, 'epoch': 0.2435601884333968}\n",
      "{'loss': 1.96, 'grad_norm': 9.050069808959961, 'learning_rate': 3.777187531322041e-06, 'epoch': 0.24456249373559186}\n",
      "{'loss': 1.3155, 'grad_norm': 15.812612533569336, 'learning_rate': 3.7721760048110657e-06, 'epoch': 0.2455647990377869}\n",
      "{'loss': 1.3075, 'grad_norm': 0.0, 'learning_rate': 3.7671644783000904e-06, 'epoch': 0.24656710433998197}\n",
      "{'loss': 1.5439, 'grad_norm': 13.441875457763672, 'learning_rate': 3.7621529517891152e-06, 'epoch': 0.247569409642177}\n",
      "{'loss': 1.8033, 'grad_norm': 12.203527450561523, 'learning_rate': 3.75714142527814e-06, 'epoch': 0.24857171494437205}\n",
      "{'loss': 1.212, 'grad_norm': 11.235621452331543, 'learning_rate': 3.7521298987671652e-06, 'epoch': 0.2495740202465671}\n",
      "{'loss': 1.3484, 'grad_norm': 16.352949142456055, 'learning_rate': 3.747118372256189e-06, 'epoch': 0.25057632554876214}\n",
      "{'loss': 1.8326, 'grad_norm': 10.337897300720215, 'learning_rate': 3.7421068457452144e-06, 'epoch': 0.2515786308509572}\n",
      "{'loss': 1.5211, 'grad_norm': 6.842573165893555, 'learning_rate': 3.737095319234239e-06, 'epoch': 0.25258093615315225}\n",
      "{'loss': 1.8846, 'grad_norm': 11.406954765319824, 'learning_rate': 3.732083792723264e-06, 'epoch': 0.2535832414553473}\n",
      "{'loss': 1.3641, 'grad_norm': 31.617765426635742, 'learning_rate': 3.7270722662122887e-06, 'epoch': 0.25458554675754236}\n",
      "{'loss': 2.2411, 'grad_norm': 13.819793701171875, 'learning_rate': 3.722060739701313e-06, 'epoch': 0.2555878520597374}\n",
      "{'loss': 1.3189, 'grad_norm': 17.89590835571289, 'learning_rate': 3.717049213190338e-06, 'epoch': 0.25659015736193247}\n",
      "{'loss': 1.4778, 'grad_norm': 13.138537406921387, 'learning_rate': 3.7120376866793627e-06, 'epoch': 0.2575924626641275}\n",
      "{'loss': 1.1703, 'grad_norm': 20.254213333129883, 'learning_rate': 3.707026160168388e-06, 'epoch': 0.2585947679663225}\n",
      "{'loss': 1.6575, 'grad_norm': 37.96231460571289, 'learning_rate': 3.7020146336574127e-06, 'epoch': 0.2595970732685176}\n",
      "{'loss': 1.74, 'grad_norm': 15.434661865234375, 'learning_rate': 3.697003107146437e-06, 'epoch': 0.26059937857071264}\n",
      "{'loss': 1.3953, 'grad_norm': 11.00021743774414, 'learning_rate': 3.691991580635462e-06, 'epoch': 0.26160168387290766}\n",
      "{'loss': 1.3182, 'grad_norm': 10.718320846557617, 'learning_rate': 3.6869800541244866e-06, 'epoch': 0.26260398917510275}\n",
      "{'loss': 0.9225, 'grad_norm': 10.684673309326172, 'learning_rate': 3.6819685276135114e-06, 'epoch': 0.2636062944772978}\n",
      "{'loss': 1.5054, 'grad_norm': 12.818264961242676, 'learning_rate': 3.676957001102536e-06, 'epoch': 0.26460859977949286}\n",
      "{'loss': 2.0686, 'grad_norm': 18.079586029052734, 'learning_rate': 3.671945474591561e-06, 'epoch': 0.2656109050816879}\n",
      "{'loss': 1.6909, 'grad_norm': 23.270122528076172, 'learning_rate': 3.6669339480805853e-06, 'epoch': 0.2666132103838829}\n",
      "{'loss': 1.4219, 'grad_norm': 8.424216270446777, 'learning_rate': 3.66192242156961e-06, 'epoch': 0.267615515686078}\n",
      "{'loss': 1.49, 'grad_norm': 17.979999542236328, 'learning_rate': 3.6569108950586353e-06, 'epoch': 0.268617820988273}\n",
      "{'loss': 1.5616, 'grad_norm': 13.008005142211914, 'learning_rate': 3.65189936854766e-06, 'epoch': 0.26962012629046805}\n",
      "{'loss': 1.6684, 'grad_norm': 24.489530563354492, 'learning_rate': 3.646887842036685e-06, 'epoch': 0.27062243159266314}\n",
      "{'loss': 1.9283, 'grad_norm': 14.69632339477539, 'learning_rate': 3.6418763155257093e-06, 'epoch': 0.27162473689485817}\n",
      "{'loss': 1.4769, 'grad_norm': 10.88970947265625, 'learning_rate': 3.636864789014734e-06, 'epoch': 0.27262704219705325}\n",
      "{'loss': 1.17, 'grad_norm': 10.009825706481934, 'learning_rate': 3.631853262503759e-06, 'epoch': 0.2736293474992483}\n",
      "{'loss': 1.1676, 'grad_norm': 32.60182189941406, 'learning_rate': 3.6268417359927836e-06, 'epoch': 0.2746316528014433}\n",
      "{'loss': 1.6066, 'grad_norm': 21.56585121154785, 'learning_rate': 3.6218302094818084e-06, 'epoch': 0.2756339581036384}\n",
      "{'loss': 1.0985, 'grad_norm': 11.14734172821045, 'learning_rate': 3.616818682970833e-06, 'epoch': 0.2766362634058334}\n",
      "{'loss': 0.8379, 'grad_norm': 13.68912124633789, 'learning_rate': 3.611807156459858e-06, 'epoch': 0.27763856870802844}\n",
      "{'loss': 1.207, 'grad_norm': 21.110471725463867, 'learning_rate': 3.6067956299488828e-06, 'epoch': 0.2786408740102235}\n",
      "{'loss': 1.3075, 'grad_norm': 23.557226181030273, 'learning_rate': 3.6017841034379076e-06, 'epoch': 0.27964317931241855}\n",
      "{'loss': 1.286, 'grad_norm': 9.507440567016602, 'learning_rate': 3.5967725769269324e-06, 'epoch': 0.28064548461461364}\n",
      "{'loss': 1.4958, 'grad_norm': 35.49671936035156, 'learning_rate': 3.591761050415957e-06, 'epoch': 0.28164778991680867}\n",
      "{'loss': 1.4424, 'grad_norm': 8.291356086730957, 'learning_rate': 3.5867495239049815e-06, 'epoch': 0.2826500952190037}\n",
      "{'loss': 1.6858, 'grad_norm': 10.91098403930664, 'learning_rate': 3.5817379973940063e-06, 'epoch': 0.2836524005211988}\n",
      "{'loss': 1.9757, 'grad_norm': 14.203625679016113, 'learning_rate': 3.576726470883031e-06, 'epoch': 0.2846547058233938}\n",
      "{'loss': 1.3746, 'grad_norm': 18.257217407226562, 'learning_rate': 3.5717149443720563e-06, 'epoch': 0.28565701112558883}\n",
      "{'loss': 2.3547, 'grad_norm': 12.069156646728516, 'learning_rate': 3.566703417861081e-06, 'epoch': 0.2866593164277839}\n",
      "{'loss': 1.77, 'grad_norm': 12.458873748779297, 'learning_rate': 3.5616918913501054e-06, 'epoch': 0.28766162172997894}\n",
      "{'loss': 1.8457, 'grad_norm': 15.947501182556152, 'learning_rate': 3.5566803648391302e-06, 'epoch': 0.288663927032174}\n",
      "{'loss': 1.1609, 'grad_norm': 10.554816246032715, 'learning_rate': 3.551668838328155e-06, 'epoch': 0.28966623233436906}\n",
      "{'loss': 2.3201, 'grad_norm': 10.522927284240723, 'learning_rate': 3.54665731181718e-06, 'epoch': 0.2906685376365641}\n",
      "{'loss': 1.9505, 'grad_norm': 0.0, 'learning_rate': 3.5416457853062046e-06, 'epoch': 0.29167084293875917}\n",
      "{'loss': 1.5896, 'grad_norm': 12.19089126586914, 'learning_rate': 3.5366342587952294e-06, 'epoch': 0.2926731482409542}\n",
      "{'loss': 1.807, 'grad_norm': 8.879192352294922, 'learning_rate': 3.5316227322842537e-06, 'epoch': 0.2936754535431492}\n",
      "{'loss': 0.9749, 'grad_norm': 20.632017135620117, 'learning_rate': 3.526611205773279e-06, 'epoch': 0.2946777588453443}\n",
      "{'loss': 1.5466, 'grad_norm': 10.256750106811523, 'learning_rate': 3.5215996792623037e-06, 'epoch': 0.29568006414753933}\n",
      "{'loss': 1.3688, 'grad_norm': 21.611957550048828, 'learning_rate': 3.5165881527513285e-06, 'epoch': 0.29668236944973436}\n",
      "{'loss': 1.7311, 'grad_norm': 8.765212059020996, 'learning_rate': 3.5115766262403533e-06, 'epoch': 0.29768467475192945}\n",
      "{'loss': 2.1083, 'grad_norm': 16.57107162475586, 'learning_rate': 3.5065650997293777e-06, 'epoch': 0.2986869800541245}\n",
      "{'loss': 1.7086, 'grad_norm': 11.764296531677246, 'learning_rate': 3.5015535732184025e-06, 'epoch': 0.29968928535631956}\n",
      "{'loss': 1.4149, 'grad_norm': 17.222455978393555, 'learning_rate': 3.4965420467074273e-06, 'epoch': 0.3006915906585146}\n",
      "{'loss': 1.7104, 'grad_norm': 24.045595169067383, 'learning_rate': 3.491530520196452e-06, 'epoch': 0.3016938959607096}\n",
      "{'loss': 1.7884, 'grad_norm': 14.75878620147705, 'learning_rate': 3.4865189936854773e-06, 'epoch': 0.3026962012629047}\n",
      "{'loss': 1.1817, 'grad_norm': 22.68889617919922, 'learning_rate': 3.481507467174501e-06, 'epoch': 0.3036985065650997}\n",
      "{'loss': 1.0012, 'grad_norm': 8.92067813873291, 'learning_rate': 3.4764959406635264e-06, 'epoch': 0.30470081186729475}\n",
      "{'loss': 1.4972, 'grad_norm': 8.65169906616211, 'learning_rate': 3.471484414152551e-06, 'epoch': 0.30570311716948984}\n",
      "{'loss': 1.204, 'grad_norm': 33.331417083740234, 'learning_rate': 3.466472887641576e-06, 'epoch': 0.30670542247168486}\n",
      "{'loss': 1.6448, 'grad_norm': 19.320322036743164, 'learning_rate': 3.4614613611306008e-06, 'epoch': 0.30770772777387995}\n",
      "{'loss': 1.1121, 'grad_norm': 10.175414085388184, 'learning_rate': 3.4564498346196256e-06, 'epoch': 0.308710033076075}\n",
      "{'loss': 1.1808, 'grad_norm': 17.408458709716797, 'learning_rate': 3.45143830810865e-06, 'epoch': 0.30971233837827}\n",
      "{'loss': 1.4471, 'grad_norm': 10.749757766723633, 'learning_rate': 3.4464267815976747e-06, 'epoch': 0.3107146436804651}\n",
      "{'loss': 1.3073, 'grad_norm': 8.068094253540039, 'learning_rate': 3.4414152550867e-06, 'epoch': 0.3117169489826601}\n",
      "{'loss': 1.8638, 'grad_norm': 16.616943359375, 'learning_rate': 3.4364037285757247e-06, 'epoch': 0.31271925428485514}\n",
      "{'loss': 1.3437, 'grad_norm': 13.73776912689209, 'learning_rate': 3.4313922020647495e-06, 'epoch': 0.3137215595870502}\n",
      "{'loss': 1.0171, 'grad_norm': 14.82001781463623, 'learning_rate': 3.426380675553774e-06, 'epoch': 0.31472386488924525}\n",
      "{'loss': 1.1477, 'grad_norm': 16.5677547454834, 'learning_rate': 3.4213691490427986e-06, 'epoch': 0.31572617019144034}\n",
      "{'loss': 1.0936, 'grad_norm': 18.87725257873535, 'learning_rate': 3.4163576225318234e-06, 'epoch': 0.31672847549363536}\n",
      "{'loss': 1.8817, 'grad_norm': 15.375091552734375, 'learning_rate': 3.4113460960208482e-06, 'epoch': 0.3177307807958304}\n",
      "{'loss': 1.4427, 'grad_norm': 8.934829711914062, 'learning_rate': 3.406334569509873e-06, 'epoch': 0.3187330860980255}\n",
      "{'loss': 0.9516, 'grad_norm': 13.35211181640625, 'learning_rate': 3.4013230429988974e-06, 'epoch': 0.3197353914002205}\n",
      "{'loss': 1.9481, 'grad_norm': 11.355103492736816, 'learning_rate': 3.396311516487922e-06, 'epoch': 0.32073769670241553}\n",
      "{'loss': 1.5776, 'grad_norm': 46.969139099121094, 'learning_rate': 3.3912999899769474e-06, 'epoch': 0.3217400020046106}\n",
      "{'loss': 1.7067, 'grad_norm': 52.322391510009766, 'learning_rate': 3.386288463465972e-06, 'epoch': 0.32274230730680564}\n",
      "{'loss': 1.7287, 'grad_norm': 24.973987579345703, 'learning_rate': 3.381276936954997e-06, 'epoch': 0.3237446126090007}\n",
      "{'loss': 1.769, 'grad_norm': 15.128426551818848, 'learning_rate': 3.3762654104440217e-06, 'epoch': 0.32474691791119575}\n",
      "{'loss': 1.2509, 'grad_norm': 9.796106338500977, 'learning_rate': 3.371253883933046e-06, 'epoch': 0.3257492232133908}\n",
      "{'loss': 2.0843, 'grad_norm': 15.97517204284668, 'learning_rate': 3.366242357422071e-06, 'epoch': 0.32675152851558587}\n",
      "{'loss': 1.1207, 'grad_norm': 28.597137451171875, 'learning_rate': 3.3612308309110957e-06, 'epoch': 0.3277538338177809}\n",
      "{'loss': 2.1661, 'grad_norm': 14.113986015319824, 'learning_rate': 3.356219304400121e-06, 'epoch': 0.3287561391199759}\n",
      "{'loss': 1.4349, 'grad_norm': 15.859367370605469, 'learning_rate': 3.3512077778891457e-06, 'epoch': 0.329758444422171}\n",
      "{'loss': 1.207, 'grad_norm': 13.715836524963379, 'learning_rate': 3.34619625137817e-06, 'epoch': 0.33076074972436603}\n",
      "{'loss': 0.7489, 'grad_norm': 13.236647605895996, 'learning_rate': 3.341184724867195e-06, 'epoch': 0.3317630550265611}\n",
      "{'loss': 1.3261, 'grad_norm': 18.666467666625977, 'learning_rate': 3.3361731983562196e-06, 'epoch': 0.33276536032875614}\n",
      "{'loss': 1.5994, 'grad_norm': 24.384075164794922, 'learning_rate': 3.3311616718452444e-06, 'epoch': 0.33376766563095117}\n",
      "{'loss': 1.489, 'grad_norm': 20.714805603027344, 'learning_rate': 3.326150145334269e-06, 'epoch': 0.33476997093314625}\n",
      "{'loss': 1.4308, 'grad_norm': 9.97564697265625, 'learning_rate': 3.3211386188232935e-06, 'epoch': 0.3357722762353413}\n",
      "{'loss': 1.3937, 'grad_norm': 13.00240707397461, 'learning_rate': 3.3161270923123183e-06, 'epoch': 0.3367745815375363}\n",
      "{'loss': 1.7353, 'grad_norm': 8.551399230957031, 'learning_rate': 3.311115565801343e-06, 'epoch': 0.3377768868397314}\n",
      "{'loss': 1.711, 'grad_norm': 21.193958282470703, 'learning_rate': 3.3061040392903683e-06, 'epoch': 0.3387791921419264}\n",
      "{'loss': 1.4966, 'grad_norm': 8.58128547668457, 'learning_rate': 3.301092512779393e-06, 'epoch': 0.3397814974441215}\n",
      "{'loss': 1.042, 'grad_norm': 11.270684242248535, 'learning_rate': 3.296080986268418e-06, 'epoch': 0.34078380274631653}\n",
      "{'loss': 1.3826, 'grad_norm': 20.136354446411133, 'learning_rate': 3.2910694597574423e-06, 'epoch': 0.34178610804851156}\n",
      "{'loss': 1.9293, 'grad_norm': 38.56990432739258, 'learning_rate': 3.286057933246467e-06, 'epoch': 0.34278841335070664}\n",
      "{'loss': 1.6058, 'grad_norm': 10.226487159729004, 'learning_rate': 3.281046406735492e-06, 'epoch': 0.3437907186529017}\n",
      "{'loss': 1.3075, 'grad_norm': 15.281020164489746, 'learning_rate': 3.2760348802245166e-06, 'epoch': 0.3447930239550967}\n",
      "{'loss': 1.7874, 'grad_norm': 13.648702621459961, 'learning_rate': 3.271023353713542e-06, 'epoch': 0.3457953292572918}\n",
      "{'loss': 0.9877, 'grad_norm': 28.542434692382812, 'learning_rate': 3.2660118272025658e-06, 'epoch': 0.3467976345594868}\n",
      "{'loss': 1.2601, 'grad_norm': 9.219592094421387, 'learning_rate': 3.261000300691591e-06, 'epoch': 0.3477999398616819}\n",
      "{'loss': 1.3133, 'grad_norm': 15.098257064819336, 'learning_rate': 3.2559887741806158e-06, 'epoch': 0.3488022451638769}\n",
      "{'loss': 0.6656, 'grad_norm': 23.569271087646484, 'learning_rate': 3.2509772476696406e-06, 'epoch': 0.34980455046607195}\n",
      "{'loss': 1.2388, 'grad_norm': 22.97734832763672, 'learning_rate': 3.2459657211586653e-06, 'epoch': 0.35080685576826703}\n",
      "{'loss': 0.9039, 'grad_norm': 24.582782745361328, 'learning_rate': 3.2409541946476897e-06, 'epoch': 0.35180916107046206}\n",
      "{'loss': 1.3226, 'grad_norm': 10.82170295715332, 'learning_rate': 3.2359426681367145e-06, 'epoch': 0.3528114663726571}\n",
      "{'loss': 1.4099, 'grad_norm': 9.5347261428833, 'learning_rate': 3.2309311416257393e-06, 'epoch': 0.3538137716748522}\n",
      "{'loss': 1.5389, 'grad_norm': 22.957508087158203, 'learning_rate': 3.225919615114764e-06, 'epoch': 0.3548160769770472}\n",
      "{'loss': 1.7779, 'grad_norm': 11.714252471923828, 'learning_rate': 3.2209080886037893e-06, 'epoch': 0.3558183822792423}\n",
      "{'loss': 2.1655, 'grad_norm': 10.772004127502441, 'learning_rate': 3.215896562092814e-06, 'epoch': 0.3568206875814373}\n",
      "{'loss': 1.2843, 'grad_norm': 10.478466033935547, 'learning_rate': 3.2108850355818384e-06, 'epoch': 0.35782299288363234}\n",
      "{'loss': 1.0194, 'grad_norm': 22.47920799255371, 'learning_rate': 3.2058735090708632e-06, 'epoch': 0.3588252981858274}\n",
      "{'loss': 1.1189, 'grad_norm': 13.003634452819824, 'learning_rate': 3.200861982559888e-06, 'epoch': 0.35982760348802245}\n",
      "{'loss': 1.1163, 'grad_norm': 15.717702865600586, 'learning_rate': 3.195850456048913e-06, 'epoch': 0.3608299087902175}\n",
      "{'loss': 1.1102, 'grad_norm': 10.327693939208984, 'learning_rate': 3.1908389295379376e-06, 'epoch': 0.36183221409241256}\n",
      "{'loss': 1.801, 'grad_norm': 15.941591262817383, 'learning_rate': 3.185827403026962e-06, 'epoch': 0.3628345193946076}\n",
      "{'loss': 1.0359, 'grad_norm': 21.012516021728516, 'learning_rate': 3.1808158765159867e-06, 'epoch': 0.3638368246968026}\n",
      "{'loss': 1.5887, 'grad_norm': 9.547208786010742, 'learning_rate': 3.175804350005012e-06, 'epoch': 0.3648391299989977}\n",
      "{'loss': 1.9368, 'grad_norm': 11.62748908996582, 'learning_rate': 3.1707928234940367e-06, 'epoch': 0.36584143530119273}\n",
      "{'loss': 0.9303, 'grad_norm': 0.0, 'learning_rate': 3.1657812969830615e-06, 'epoch': 0.3668437406033878}\n",
      "{'loss': 1.1709, 'grad_norm': 13.114094734191895, 'learning_rate': 3.1607697704720863e-06, 'epoch': 0.36784604590558284}\n",
      "{'loss': 1.5394, 'grad_norm': 11.486555099487305, 'learning_rate': 3.1557582439611107e-06, 'epoch': 0.36884835120777787}\n",
      "{'loss': 1.4561, 'grad_norm': 11.554545402526855, 'learning_rate': 3.1507467174501355e-06, 'epoch': 0.36985065650997295}\n",
      "{'loss': 1.5316, 'grad_norm': 38.28511428833008, 'learning_rate': 3.1457351909391602e-06, 'epoch': 0.370852961812168}\n",
      "{'loss': 1.3022, 'grad_norm': 24.1400146484375, 'learning_rate': 3.140723664428185e-06, 'epoch': 0.371855267114363}\n",
      "{'loss': 1.2647, 'grad_norm': 21.799333572387695, 'learning_rate': 3.1357121379172102e-06, 'epoch': 0.3728575724165581}\n",
      "{'loss': 1.2144, 'grad_norm': 26.554100036621094, 'learning_rate': 3.130700611406234e-06, 'epoch': 0.3738598777187531}\n",
      "{'loss': 1.6354, 'grad_norm': 17.174514770507812, 'learning_rate': 3.1256890848952594e-06, 'epoch': 0.3748621830209482}\n",
      "{'loss': 1.4212, 'grad_norm': 31.078969955444336, 'learning_rate': 3.120677558384284e-06, 'epoch': 0.37586448832314323}\n",
      "{'loss': 1.5921, 'grad_norm': 11.6639986038208, 'learning_rate': 3.115666031873309e-06, 'epoch': 0.37686679362533826}\n",
      "{'loss': 1.7333, 'grad_norm': 23.145238876342773, 'learning_rate': 3.1106545053623338e-06, 'epoch': 0.37786909892753334}\n",
      "{'loss': 1.2297, 'grad_norm': 23.379379272460938, 'learning_rate': 3.105642978851358e-06, 'epoch': 0.37887140422972837}\n",
      "{'loss': 1.8524, 'grad_norm': 11.83124828338623, 'learning_rate': 3.100631452340383e-06, 'epoch': 0.3798737095319234}\n",
      "{'loss': 1.6984, 'grad_norm': 11.614715576171875, 'learning_rate': 3.0956199258294077e-06, 'epoch': 0.3808760148341185}\n",
      "{'loss': 0.8817, 'grad_norm': 9.69890022277832, 'learning_rate': 3.090608399318433e-06, 'epoch': 0.3818783201363135}\n",
      "{'loss': 1.1828, 'grad_norm': 30.41568946838379, 'learning_rate': 3.0855968728074577e-06, 'epoch': 0.3828806254385086}\n",
      "{'loss': 1.2153, 'grad_norm': 17.560192108154297, 'learning_rate': 3.0805853462964825e-06, 'epoch': 0.3838829307407036}\n",
      "{'loss': 1.4353, 'grad_norm': 28.14179039001465, 'learning_rate': 3.075573819785507e-06, 'epoch': 0.38488523604289865}\n",
      "{'loss': 1.5036, 'grad_norm': 9.335580825805664, 'learning_rate': 3.0705622932745316e-06, 'epoch': 0.38588754134509373}\n",
      "{'loss': 1.5075, 'grad_norm': 8.374024391174316, 'learning_rate': 3.0655507667635564e-06, 'epoch': 0.38688984664728876}\n",
      "{'loss': 1.22, 'grad_norm': 12.999019622802734, 'learning_rate': 3.060539240252581e-06, 'epoch': 0.3878921519494838}\n",
      "{'loss': 1.4492, 'grad_norm': 14.419724464416504, 'learning_rate': 3.055527713741606e-06, 'epoch': 0.38889445725167887}\n",
      "{'loss': 1.3825, 'grad_norm': 15.874531745910645, 'learning_rate': 3.0505161872306304e-06, 'epoch': 0.3898967625538739}\n",
      "{'loss': 2.1768, 'grad_norm': 8.903681755065918, 'learning_rate': 3.045504660719655e-06, 'epoch': 0.390899067856069}\n",
      "{'loss': 1.522, 'grad_norm': 14.583081245422363, 'learning_rate': 3.0404931342086804e-06, 'epoch': 0.391901373158264}\n",
      "{'loss': 1.743, 'grad_norm': 10.142126083374023, 'learning_rate': 3.035481607697705e-06, 'epoch': 0.39290367846045904}\n",
      "{'loss': 1.8271, 'grad_norm': 31.269718170166016, 'learning_rate': 3.03047008118673e-06, 'epoch': 0.3939059837626541}\n",
      "{'loss': 1.1435, 'grad_norm': 12.22289752960205, 'learning_rate': 3.0254585546757543e-06, 'epoch': 0.39490828906484915}\n",
      "{'loss': 0.883, 'grad_norm': 40.4107780456543, 'learning_rate': 3.020447028164779e-06, 'epoch': 0.3959105943670442}\n",
      "{'loss': 1.3211, 'grad_norm': 13.015692710876465, 'learning_rate': 3.015435501653804e-06, 'epoch': 0.39691289966923926}\n",
      "{'loss': 1.1975, 'grad_norm': 11.658223152160645, 'learning_rate': 3.0104239751428287e-06, 'epoch': 0.3979152049714343}\n",
      "{'loss': 1.342, 'grad_norm': 11.776025772094727, 'learning_rate': 3.005412448631854e-06, 'epoch': 0.39891751027362937}\n",
      "{'loss': 1.9211, 'grad_norm': 15.628507614135742, 'learning_rate': 3.0004009221208787e-06, 'epoch': 0.3999198155758244}\n",
      "{'loss': 1.2266, 'grad_norm': 13.00675106048584, 'learning_rate': 2.995389395609903e-06, 'epoch': 0.40092212087801943}\n",
      "{'loss': 1.1286, 'grad_norm': 58.998260498046875, 'learning_rate': 2.990377869098928e-06, 'epoch': 0.4019244261802145}\n",
      "{'loss': 1.3258, 'grad_norm': 17.90508460998535, 'learning_rate': 2.9853663425879526e-06, 'epoch': 0.40292673148240954}\n",
      "{'loss': 1.4692, 'grad_norm': 11.812637329101562, 'learning_rate': 2.9803548160769774e-06, 'epoch': 0.40392903678460457}\n",
      "{'loss': 1.6638, 'grad_norm': 9.26029109954834, 'learning_rate': 2.975343289566002e-06, 'epoch': 0.40493134208679965}\n",
      "{'loss': 1.2397, 'grad_norm': 19.755111694335938, 'learning_rate': 2.9703317630550265e-06, 'epoch': 0.4059336473889947}\n",
      "{'loss': 1.7031, 'grad_norm': 33.716346740722656, 'learning_rate': 2.9653202365440513e-06, 'epoch': 0.40693595269118976}\n",
      "{'loss': 1.4541, 'grad_norm': 14.89392375946045, 'learning_rate': 2.960308710033076e-06, 'epoch': 0.4079382579933848}\n",
      "{'loss': 1.4637, 'grad_norm': 11.518662452697754, 'learning_rate': 2.9552971835221013e-06, 'epoch': 0.4089405632955798}\n",
      "{'loss': 1.3543, 'grad_norm': 11.228718757629395, 'learning_rate': 2.950285657011126e-06, 'epoch': 0.4099428685977749}\n",
      "{'loss': 1.3368, 'grad_norm': 10.792806625366211, 'learning_rate': 2.9452741305001505e-06, 'epoch': 0.41094517389996993}\n",
      "{'loss': 1.7815, 'grad_norm': 35.65456771850586, 'learning_rate': 2.9402626039891753e-06, 'epoch': 0.41194747920216496}\n",
      "{'loss': 1.7538, 'grad_norm': 9.781180381774902, 'learning_rate': 2.9352510774782e-06, 'epoch': 0.41294978450436004}\n",
      "{'loss': 1.9807, 'grad_norm': 17.22549057006836, 'learning_rate': 2.930239550967225e-06, 'epoch': 0.41395208980655507}\n",
      "{'loss': 1.5116, 'grad_norm': 20.533235549926758, 'learning_rate': 2.9252280244562496e-06, 'epoch': 0.41495439510875015}\n",
      "{'loss': 1.1306, 'grad_norm': 20.50162696838379, 'learning_rate': 2.920216497945275e-06, 'epoch': 0.4159567004109452}\n",
      "{'loss': 1.8026, 'grad_norm': 13.373005867004395, 'learning_rate': 2.9152049714342988e-06, 'epoch': 0.4169590057131402}\n",
      "{'loss': 1.186, 'grad_norm': 18.64763069152832, 'learning_rate': 2.910193444923324e-06, 'epoch': 0.4179613110153353}\n",
      "{'loss': 1.1705, 'grad_norm': 0.0, 'learning_rate': 2.9051819184123488e-06, 'epoch': 0.4189636163175303}\n",
      "{'loss': 1.7492, 'grad_norm': 11.90272045135498, 'learning_rate': 2.9001703919013735e-06, 'epoch': 0.41996592161972535}\n",
      "{'loss': 1.4153, 'grad_norm': 13.048513412475586, 'learning_rate': 2.8951588653903983e-06, 'epoch': 0.42096822692192043}\n",
      "{'loss': 1.7134, 'grad_norm': 12.352996826171875, 'learning_rate': 2.8901473388794227e-06, 'epoch': 0.42197053222411546}\n",
      "{'loss': 1.6415, 'grad_norm': 11.944554328918457, 'learning_rate': 2.8851358123684475e-06, 'epoch': 0.42297283752631054}\n",
      "{'loss': 1.5216, 'grad_norm': 20.47274398803711, 'learning_rate': 2.8801242858574723e-06, 'epoch': 0.42397514282850557}\n",
      "{'loss': 1.0633, 'grad_norm': 18.61268424987793, 'learning_rate': 2.875112759346497e-06, 'epoch': 0.4249774481307006}\n",
      "{'loss': 1.5728, 'grad_norm': 13.491582870483398, 'learning_rate': 2.8701012328355223e-06, 'epoch': 0.4259797534328957}\n",
      "{'loss': 1.524, 'grad_norm': 17.556360244750977, 'learning_rate': 2.8650897063245462e-06, 'epoch': 0.4269820587350907}\n",
      "{'loss': 2.1429, 'grad_norm': 24.342939376831055, 'learning_rate': 2.8600781798135714e-06, 'epoch': 0.42798436403728574}\n",
      "{'loss': 1.4167, 'grad_norm': 10.695656776428223, 'learning_rate': 2.855066653302596e-06, 'epoch': 0.4289866693394808}\n",
      "{'loss': 1.5144, 'grad_norm': 20.741662979125977, 'learning_rate': 2.850055126791621e-06, 'epoch': 0.42998897464167585}\n",
      "{'loss': 1.027, 'grad_norm': 17.827062606811523, 'learning_rate': 2.8450436002806458e-06, 'epoch': 0.43099127994387093}\n",
      "{'loss': 2.0503, 'grad_norm': 11.728839874267578, 'learning_rate': 2.8400320737696706e-06, 'epoch': 0.43199358524606596}\n",
      "{'loss': 1.1535, 'grad_norm': 36.08964538574219, 'learning_rate': 2.835020547258695e-06, 'epoch': 0.432995890548261}\n",
      "{'loss': 1.1717, 'grad_norm': 13.048288345336914, 'learning_rate': 2.8300090207477197e-06, 'epoch': 0.43399819585045607}\n",
      "{'loss': 1.9144, 'grad_norm': 13.064313888549805, 'learning_rate': 2.824997494236745e-06, 'epoch': 0.4350005011526511}\n",
      "{'loss': 1.7034, 'grad_norm': 16.291851043701172, 'learning_rate': 2.8199859677257697e-06, 'epoch': 0.4360028064548461}\n",
      "{'loss': 2.2355, 'grad_norm': 17.240421295166016, 'learning_rate': 2.8149744412147945e-06, 'epoch': 0.4370051117570412}\n",
      "{'loss': 2.1658, 'grad_norm': 11.324398040771484, 'learning_rate': 2.809962914703819e-06, 'epoch': 0.43800741705923624}\n",
      "{'loss': 1.4707, 'grad_norm': 15.96157169342041, 'learning_rate': 2.8049513881928437e-06, 'epoch': 0.43900972236143126}\n",
      "{'loss': 1.442, 'grad_norm': 10.672243118286133, 'learning_rate': 2.7999398616818684e-06, 'epoch': 0.44001202766362635}\n",
      "{'loss': 1.659, 'grad_norm': 12.938211441040039, 'learning_rate': 2.7949283351708932e-06, 'epoch': 0.4410143329658214}\n",
      "{'loss': 1.1557, 'grad_norm': 12.626133918762207, 'learning_rate': 2.789916808659918e-06, 'epoch': 0.44201663826801646}\n",
      "{'loss': 1.9429, 'grad_norm': 17.20091438293457, 'learning_rate': 2.7849052821489432e-06, 'epoch': 0.4430189435702115}\n",
      "{'loss': 2.1011, 'grad_norm': 18.312950134277344, 'learning_rate': 2.779893755637967e-06, 'epoch': 0.4440212488724065}\n",
      "{'loss': 0.8931, 'grad_norm': 10.70543384552002, 'learning_rate': 2.7748822291269924e-06, 'epoch': 0.4450235541746016}\n",
      "{'loss': 1.6153, 'grad_norm': 12.193507194519043, 'learning_rate': 2.769870702616017e-06, 'epoch': 0.4460258594767966}\n",
      "{'loss': 1.4099, 'grad_norm': 8.518391609191895, 'learning_rate': 2.764859176105042e-06, 'epoch': 0.44702816477899165}\n",
      "{'loss': 1.6264, 'grad_norm': 8.770240783691406, 'learning_rate': 2.7598476495940667e-06, 'epoch': 0.44803047008118674}\n",
      "{'loss': 1.3317, 'grad_norm': 9.148032188415527, 'learning_rate': 2.754836123083091e-06, 'epoch': 0.44903277538338177}\n",
      "{'loss': 1.2709, 'grad_norm': 9.103766441345215, 'learning_rate': 2.749824596572116e-06, 'epoch': 0.45003508068557685}\n",
      "{'loss': 1.4614, 'grad_norm': 16.56279182434082, 'learning_rate': 2.7448130700611407e-06, 'epoch': 0.4510373859877719}\n",
      "{'loss': 1.1906, 'grad_norm': 11.350020408630371, 'learning_rate': 2.739801543550166e-06, 'epoch': 0.4520396912899669}\n",
      "{'loss': 1.5003, 'grad_norm': 19.12132453918457, 'learning_rate': 2.7347900170391907e-06, 'epoch': 0.453041996592162}\n",
      "{'loss': 1.1712, 'grad_norm': 9.768494606018066, 'learning_rate': 2.729778490528215e-06, 'epoch': 0.454044301894357}\n",
      "{'loss': 0.7011, 'grad_norm': 11.9503173828125, 'learning_rate': 2.72476696401724e-06, 'epoch': 0.45504660719655204}\n",
      "{'loss': 1.4902, 'grad_norm': 10.728852272033691, 'learning_rate': 2.7197554375062646e-06, 'epoch': 0.4560489124987471}\n",
      "{'loss': 0.7656, 'grad_norm': 9.168896675109863, 'learning_rate': 2.7147439109952894e-06, 'epoch': 0.45705121780094216}\n",
      "{'loss': 1.1106, 'grad_norm': 12.329445838928223, 'learning_rate': 2.709732384484314e-06, 'epoch': 0.45805352310313724}\n",
      "{'loss': 1.6672, 'grad_norm': 9.138884544372559, 'learning_rate': 2.704720857973339e-06, 'epoch': 0.45905582840533227}\n",
      "{'loss': 1.4648, 'grad_norm': 34.204811096191406, 'learning_rate': 2.6997093314623633e-06, 'epoch': 0.4600581337075273}\n",
      "{'loss': 1.8101, 'grad_norm': 15.759931564331055, 'learning_rate': 2.694697804951388e-06, 'epoch': 0.4610604390097224}\n",
      "{'loss': 1.9414, 'grad_norm': 10.405171394348145, 'learning_rate': 2.6896862784404133e-06, 'epoch': 0.4620627443119174}\n",
      "{'loss': 1.832, 'grad_norm': 8.167051315307617, 'learning_rate': 2.684674751929438e-06, 'epoch': 0.46306504961411243}\n",
      "{'loss': 1.738, 'grad_norm': 19.50925064086914, 'learning_rate': 2.679663225418463e-06, 'epoch': 0.4640673549163075}\n",
      "{'loss': 1.344, 'grad_norm': 35.99980926513672, 'learning_rate': 2.6746516989074873e-06, 'epoch': 0.46506966021850255}\n",
      "{'loss': 1.4795, 'grad_norm': 12.163204193115234, 'learning_rate': 2.669640172396512e-06, 'epoch': 0.46607196552069763}\n",
      "{'loss': 1.724, 'grad_norm': 18.25160026550293, 'learning_rate': 2.664628645885537e-06, 'epoch': 0.46707427082289266}\n",
      "{'loss': 1.2627, 'grad_norm': 0.0, 'learning_rate': 2.6596171193745616e-06, 'epoch': 0.4680765761250877}\n",
      "{'loss': 1.376, 'grad_norm': 14.20421314239502, 'learning_rate': 2.654605592863587e-06, 'epoch': 0.46907888142728277}\n",
      "{'loss': 0.7947, 'grad_norm': 10.442012786865234, 'learning_rate': 2.649594066352611e-06, 'epoch': 0.4700811867294778}\n",
      "{'loss': 1.7745, 'grad_norm': 16.168392181396484, 'learning_rate': 2.644582539841636e-06, 'epoch': 0.4710834920316728}\n",
      "{'loss': 1.2554, 'grad_norm': 0.0, 'learning_rate': 2.639571013330661e-06, 'epoch': 0.4720857973338679}\n",
      "{'loss': 2.0382, 'grad_norm': 14.588164329528809, 'learning_rate': 2.6345594868196856e-06, 'epoch': 0.47308810263606293}\n",
      "{'loss': 0.9216, 'grad_norm': 12.277191162109375, 'learning_rate': 2.6295479603087104e-06, 'epoch': 0.474090407938258}\n",
      "{'loss': 1.7036, 'grad_norm': 19.17494773864746, 'learning_rate': 2.624536433797735e-06, 'epoch': 0.47509271324045305}\n",
      "{'loss': 0.7677, 'grad_norm': 12.550275802612305, 'learning_rate': 2.6195249072867595e-06, 'epoch': 0.4760950185426481}\n",
      "{'loss': 1.2679, 'grad_norm': 22.670700073242188, 'learning_rate': 2.6145133807757843e-06, 'epoch': 0.47709732384484316}\n",
      "{'loss': 1.3091, 'grad_norm': 20.050188064575195, 'learning_rate': 2.609501854264809e-06, 'epoch': 0.4780996291470382}\n",
      "{'loss': 1.041, 'grad_norm': 10.764411926269531, 'learning_rate': 2.6044903277538343e-06, 'epoch': 0.4791019344492332}\n",
      "{'loss': 1.4216, 'grad_norm': 15.476218223571777, 'learning_rate': 2.599478801242859e-06, 'epoch': 0.4801042397514283}\n",
      "{'loss': 1.2136, 'grad_norm': 10.552305221557617, 'learning_rate': 2.5944672747318835e-06, 'epoch': 0.4811065450536233}\n",
      "{'loss': 1.4482, 'grad_norm': 11.06836986541748, 'learning_rate': 2.5894557482209082e-06, 'epoch': 0.4821088503558184}\n",
      "{'loss': 0.7906, 'grad_norm': 13.034297943115234, 'learning_rate': 2.584444221709933e-06, 'epoch': 0.48311115565801344}\n",
      "{'loss': 1.9973, 'grad_norm': 28.39470863342285, 'learning_rate': 2.579432695198958e-06, 'epoch': 0.48411346096020846}\n",
      "{'loss': 1.4664, 'grad_norm': 19.49979019165039, 'learning_rate': 2.5744211686879826e-06, 'epoch': 0.48511576626240355}\n",
      "{'loss': 1.0214, 'grad_norm': 19.78883171081543, 'learning_rate': 2.569409642177007e-06, 'epoch': 0.4861180715645986}\n",
      "{'loss': 1.8856, 'grad_norm': 20.915956497192383, 'learning_rate': 2.5643981156660318e-06, 'epoch': 0.4871203768667936}\n",
      "{'loss': 1.286, 'grad_norm': 23.580768585205078, 'learning_rate': 2.559386589155057e-06, 'epoch': 0.4881226821689887}\n",
      "{'loss': 1.3131, 'grad_norm': 19.24042320251465, 'learning_rate': 2.5543750626440818e-06, 'epoch': 0.4891249874711837}\n",
      "{'loss': 1.8909, 'grad_norm': 11.27094841003418, 'learning_rate': 2.5493635361331065e-06, 'epoch': 0.4901272927733788}\n",
      "{'loss': 1.8453, 'grad_norm': 11.141788482666016, 'learning_rate': 2.5443520096221313e-06, 'epoch': 0.4911295980755738}\n",
      "{'loss': 1.4606, 'grad_norm': 11.6906156539917, 'learning_rate': 2.5393404831111557e-06, 'epoch': 0.49213190337776885}\n",
      "{'loss': 1.4862, 'grad_norm': 11.774287223815918, 'learning_rate': 2.5343289566001805e-06, 'epoch': 0.49313420867996394}\n",
      "{'loss': 0.8962, 'grad_norm': 15.234051704406738, 'learning_rate': 2.5293174300892053e-06, 'epoch': 0.49413651398215896}\n",
      "{'loss': 1.7213, 'grad_norm': 0.0, 'learning_rate': 2.52430590357823e-06, 'epoch': 0.495138819284354}\n",
      "{'loss': 1.4724, 'grad_norm': 14.718605995178223, 'learning_rate': 2.5192943770672553e-06, 'epoch': 0.4961411245865491}\n",
      "{'loss': 1.0145, 'grad_norm': 32.63759231567383, 'learning_rate': 2.514282850556279e-06, 'epoch': 0.4971434298887441}\n",
      "{'loss': 1.473, 'grad_norm': 14.479358673095703, 'learning_rate': 2.5092713240453044e-06, 'epoch': 0.4981457351909392}\n",
      "{'loss': 0.9119, 'grad_norm': 17.47244644165039, 'learning_rate': 2.504259797534329e-06, 'epoch': 0.4991480404931342}\n",
      "{'loss': 1.1787, 'grad_norm': 8.619690895080566, 'learning_rate': 2.499248271023354e-06, 'epoch': 0.5001503457953292}\n",
      "{'loss': 1.7942, 'grad_norm': 9.259329795837402, 'learning_rate': 2.4942367445123788e-06, 'epoch': 0.5011526510975243}\n",
      "{'loss': 0.8428, 'grad_norm': 16.662353515625, 'learning_rate': 2.4892252180014036e-06, 'epoch': 0.5021549563997194}\n",
      "{'loss': 1.5521, 'grad_norm': 34.862525939941406, 'learning_rate': 2.4842136914904283e-06, 'epoch': 0.5031572617019144}\n",
      "{'loss': 1.565, 'grad_norm': 15.281172752380371, 'learning_rate': 2.4792021649794527e-06, 'epoch': 0.5041595670041095}\n",
      "{'loss': 1.7926, 'grad_norm': 19.836566925048828, 'learning_rate': 2.474190638468478e-06, 'epoch': 0.5051618723063045}\n",
      "{'loss': 1.4825, 'grad_norm': 8.32571792602539, 'learning_rate': 2.4691791119575027e-06, 'epoch': 0.5061641776084995}\n",
      "{'loss': 1.5231, 'grad_norm': 17.574378967285156, 'learning_rate': 2.464167585446527e-06, 'epoch': 0.5071664829106945}\n",
      "{'loss': 1.6093, 'grad_norm': 16.19314193725586, 'learning_rate': 2.459156058935552e-06, 'epoch': 0.5081687882128897}\n",
      "{'loss': 1.3969, 'grad_norm': 10.10873031616211, 'learning_rate': 2.4541445324245766e-06, 'epoch': 0.5091710935150847}\n",
      "{'loss': 1.2242, 'grad_norm': 8.334969520568848, 'learning_rate': 2.4491330059136014e-06, 'epoch': 0.5101733988172797}\n",
      "{'loss': 1.3246, 'grad_norm': 10.671363830566406, 'learning_rate': 2.4441214794026262e-06, 'epoch': 0.5111757041194748}\n",
      "{'loss': 1.975, 'grad_norm': 10.121564865112305, 'learning_rate': 2.439109952891651e-06, 'epoch': 0.5121780094216698}\n",
      "{'loss': 1.0583, 'grad_norm': 9.40758991241455, 'learning_rate': 2.434098426380676e-06, 'epoch': 0.5131803147238649}\n",
      "{'loss': 1.1886, 'grad_norm': 13.161541938781738, 'learning_rate': 2.4290868998697006e-06, 'epoch': 0.51418262002606}\n",
      "{'loss': 1.1992, 'grad_norm': 16.114717483520508, 'learning_rate': 2.4240753733587254e-06, 'epoch': 0.515184925328255}\n",
      "{'loss': 1.6778, 'grad_norm': 10.72879409790039, 'learning_rate': 2.41906384684775e-06, 'epoch': 0.51618723063045}\n",
      "{'loss': 1.1178, 'grad_norm': 12.294303894042969, 'learning_rate': 2.4140523203367745e-06, 'epoch': 0.517189535932645}\n",
      "{'loss': 1.8207, 'grad_norm': 10.47998332977295, 'learning_rate': 2.4090407938257997e-06, 'epoch': 0.5181918412348401}\n",
      "{'loss': 1.5232, 'grad_norm': 14.691841125488281, 'learning_rate': 2.4040292673148245e-06, 'epoch': 0.5191941465370352}\n",
      "{'loss': 1.0797, 'grad_norm': 17.852783203125, 'learning_rate': 2.399017740803849e-06, 'epoch': 0.5201964518392302}\n",
      "{'loss': 1.2405, 'grad_norm': 10.685676574707031, 'learning_rate': 2.3940062142928737e-06, 'epoch': 0.5211987571414253}\n",
      "{'loss': 1.1971, 'grad_norm': 12.102690696716309, 'learning_rate': 2.388994687781899e-06, 'epoch': 0.5222010624436203}\n",
      "{'loss': 1.4913, 'grad_norm': 24.22635269165039, 'learning_rate': 2.3839831612709232e-06, 'epoch': 0.5232033677458153}\n",
      "{'loss': 0.9207, 'grad_norm': 34.26325988769531, 'learning_rate': 2.378971634759948e-06, 'epoch': 0.5242056730480105}\n",
      "{'loss': 1.4581, 'grad_norm': 18.165098190307617, 'learning_rate': 2.373960108248973e-06, 'epoch': 0.5252079783502055}\n",
      "{'loss': 1.0483, 'grad_norm': 7.11582088470459, 'learning_rate': 2.3689485817379976e-06, 'epoch': 0.5262102836524005}\n",
      "{'loss': 1.438, 'grad_norm': 16.54222297668457, 'learning_rate': 2.3639370552270224e-06, 'epoch': 0.5272125889545956}\n",
      "{'loss': 1.2911, 'grad_norm': 9.75888442993164, 'learning_rate': 2.358925528716047e-06, 'epoch': 0.5282148942567906}\n",
      "{'loss': 1.6269, 'grad_norm': 19.996824264526367, 'learning_rate': 2.353914002205072e-06, 'epoch': 0.5292171995589857}\n",
      "{'loss': 1.2018, 'grad_norm': 27.377248764038086, 'learning_rate': 2.3489024756940968e-06, 'epoch': 0.5302195048611807}\n",
      "{'loss': 1.2524, 'grad_norm': 19.000144958496094, 'learning_rate': 2.343890949183121e-06, 'epoch': 0.5312218101633758}\n",
      "{'loss': 1.7848, 'grad_norm': 14.452991485595703, 'learning_rate': 2.3388794226721463e-06, 'epoch': 0.5322241154655708}\n",
      "{'loss': 0.9207, 'grad_norm': 8.84567642211914, 'learning_rate': 2.3338678961611707e-06, 'epoch': 0.5332264207677658}\n",
      "{'loss': 2.1425, 'grad_norm': 29.2972354888916, 'learning_rate': 2.3288563696501955e-06, 'epoch': 0.5342287260699609}\n",
      "{'loss': 1.4309, 'grad_norm': 8.47829818725586, 'learning_rate': 2.3238448431392207e-06, 'epoch': 0.535231031372156}\n",
      "{'loss': 1.9037, 'grad_norm': 16.35118293762207, 'learning_rate': 2.318833316628245e-06, 'epoch': 0.536233336674351}\n",
      "{'loss': 1.3541, 'grad_norm': 21.515789031982422, 'learning_rate': 2.31382179011727e-06, 'epoch': 0.537235641976546}\n",
      "{'loss': 1.3079, 'grad_norm': 18.091896057128906, 'learning_rate': 2.3088102636062946e-06, 'epoch': 0.5382379472787411}\n",
      "{'loss': 1.8861, 'grad_norm': 13.042096138000488, 'learning_rate': 2.3037987370953194e-06, 'epoch': 0.5392402525809361}\n",
      "{'loss': 1.5477, 'grad_norm': 9.718705177307129, 'learning_rate': 2.298787210584344e-06, 'epoch': 0.5402425578831312}\n",
      "{'loss': 1.8239, 'grad_norm': 16.793590545654297, 'learning_rate': 2.293775684073369e-06, 'epoch': 0.5412448631853263}\n",
      "{'loss': 1.5138, 'grad_norm': 38.478271484375, 'learning_rate': 2.2887641575623938e-06, 'epoch': 0.5422471684875213}\n",
      "{'loss': 1.1237, 'grad_norm': 17.664112091064453, 'learning_rate': 2.2837526310514186e-06, 'epoch': 0.5432494737897163}\n",
      "{'loss': 2.1186, 'grad_norm': 19.995885848999023, 'learning_rate': 2.278741104540443e-06, 'epoch': 0.5442517790919114}\n",
      "{'loss': 1.4844, 'grad_norm': 13.062657356262207, 'learning_rate': 2.273729578029468e-06, 'epoch': 0.5452540843941065}\n",
      "{'loss': 2.0371, 'grad_norm': 12.07638931274414, 'learning_rate': 2.268718051518493e-06, 'epoch': 0.5462563896963015}\n",
      "{'loss': 1.5575, 'grad_norm': 11.692235946655273, 'learning_rate': 2.2637065250075173e-06, 'epoch': 0.5472586949984966}\n",
      "{'loss': 2.2818, 'grad_norm': 8.838665008544922, 'learning_rate': 2.258694998496542e-06, 'epoch': 0.5482610003006916}\n",
      "{'loss': 1.5941, 'grad_norm': 18.878551483154297, 'learning_rate': 2.253683471985567e-06, 'epoch': 0.5492633056028866}\n",
      "{'loss': 1.6103, 'grad_norm': 13.095547676086426, 'learning_rate': 2.2486719454745917e-06, 'epoch': 0.5502656109050816}\n",
      "{'loss': 1.3149, 'grad_norm': 34.64140319824219, 'learning_rate': 2.2436604189636164e-06, 'epoch': 0.5512679162072768}\n",
      "{'loss': 1.8903, 'grad_norm': 18.099828720092773, 'learning_rate': 2.2386488924526412e-06, 'epoch': 0.5522702215094718}\n",
      "{'loss': 1.4201, 'grad_norm': 43.63645935058594, 'learning_rate': 2.233637365941666e-06, 'epoch': 0.5532725268116668}\n",
      "{'loss': 0.8841, 'grad_norm': 35.96046829223633, 'learning_rate': 2.228625839430691e-06, 'epoch': 0.5542748321138619}\n",
      "{'loss': 1.4832, 'grad_norm': 13.457538604736328, 'learning_rate': 2.2236143129197156e-06, 'epoch': 0.5552771374160569}\n",
      "{'loss': 1.4588, 'grad_norm': 15.560757637023926, 'learning_rate': 2.2186027864087404e-06, 'epoch': 0.556279442718252}\n",
      "{'loss': 1.382, 'grad_norm': 8.496943473815918, 'learning_rate': 2.2135912598977647e-06, 'epoch': 0.557281748020447}\n",
      "{'loss': 1.4926, 'grad_norm': 36.03435516357422, 'learning_rate': 2.20857973338679e-06, 'epoch': 0.5582840533226421}\n",
      "{'loss': 1.2876, 'grad_norm': 11.488348960876465, 'learning_rate': 2.2035682068758147e-06, 'epoch': 0.5592863586248371}\n",
      "{'loss': 1.0835, 'grad_norm': 38.61636734008789, 'learning_rate': 2.198556680364839e-06, 'epoch': 0.5602886639270321}\n",
      "{'loss': 1.574, 'grad_norm': 13.423036575317383, 'learning_rate': 2.193545153853864e-06, 'epoch': 0.5612909692292273}\n",
      "{'loss': 0.5097, 'grad_norm': 13.072749137878418, 'learning_rate': 2.188533627342889e-06, 'epoch': 0.5622932745314223}\n",
      "{'loss': 0.6938, 'grad_norm': 19.871047973632812, 'learning_rate': 2.1835221008319135e-06, 'epoch': 0.5632955798336173}\n",
      "{'loss': 1.1096, 'grad_norm': 9.422258377075195, 'learning_rate': 2.1785105743209383e-06, 'epoch': 0.5642978851358124}\n",
      "{'loss': 1.6442, 'grad_norm': 16.908992767333984, 'learning_rate': 2.173499047809963e-06, 'epoch': 0.5653001904380074}\n",
      "{'loss': 1.3977, 'grad_norm': 29.23328971862793, 'learning_rate': 2.168487521298988e-06, 'epoch': 0.5663024957402024}\n",
      "{'loss': 1.3597, 'grad_norm': 12.384237289428711, 'learning_rate': 2.1634759947880126e-06, 'epoch': 0.5673048010423976}\n",
      "{'loss': 1.4526, 'grad_norm': 20.85472297668457, 'learning_rate': 2.1584644682770374e-06, 'epoch': 0.5683071063445926}\n",
      "{'loss': 1.9805, 'grad_norm': 9.793322563171387, 'learning_rate': 2.153452941766062e-06, 'epoch': 0.5693094116467876}\n",
      "{'loss': 1.6036, 'grad_norm': 10.346040725708008, 'learning_rate': 2.148441415255087e-06, 'epoch': 0.5703117169489826}\n",
      "{'loss': 1.4021, 'grad_norm': 20.337221145629883, 'learning_rate': 2.1434298887441118e-06, 'epoch': 0.5713140222511777}\n",
      "{'loss': 1.856, 'grad_norm': 8.588353157043457, 'learning_rate': 2.1384183622331365e-06, 'epoch': 0.5723163275533728}\n",
      "{'loss': 1.3339, 'grad_norm': 22.379179000854492, 'learning_rate': 2.133406835722161e-06, 'epoch': 0.5733186328555678}\n",
      "{'loss': 1.1045, 'grad_norm': 9.409451484680176, 'learning_rate': 2.1283953092111857e-06, 'epoch': 0.5743209381577629}\n",
      "{'loss': 1.5913, 'grad_norm': 15.253217697143555, 'learning_rate': 2.123383782700211e-06, 'epoch': 0.5753232434599579}\n",
      "{'loss': 1.4979, 'grad_norm': 10.825401306152344, 'learning_rate': 2.1183722561892353e-06, 'epoch': 0.5763255487621529}\n",
      "{'loss': 1.0696, 'grad_norm': 22.461042404174805, 'learning_rate': 2.11336072967826e-06, 'epoch': 0.577327854064348}\n",
      "{'loss': 1.5132, 'grad_norm': 14.723007202148438, 'learning_rate': 2.108349203167285e-06, 'epoch': 0.5783301593665431}\n",
      "{'loss': 1.6222, 'grad_norm': 15.743871688842773, 'learning_rate': 2.1033376766563096e-06, 'epoch': 0.5793324646687381}\n",
      "{'loss': 1.4025, 'grad_norm': 18.00029945373535, 'learning_rate': 2.0983261501453344e-06, 'epoch': 0.5803347699709331}\n",
      "{'loss': 0.9366, 'grad_norm': 9.105899810791016, 'learning_rate': 2.093314623634359e-06, 'epoch': 0.5813370752731282}\n",
      "{'loss': 1.2375, 'grad_norm': 17.061124801635742, 'learning_rate': 2.088303097123384e-06, 'epoch': 0.5823393805753232}\n",
      "{'loss': 1.3971, 'grad_norm': 10.849459648132324, 'learning_rate': 2.0832915706124088e-06, 'epoch': 0.5833416858775183}\n",
      "{'loss': 1.3445, 'grad_norm': 0.0, 'learning_rate': 2.078280044101433e-06, 'epoch': 0.5843439911797134}\n",
      "{'loss': 1.7704, 'grad_norm': 18.3256893157959, 'learning_rate': 2.0732685175904584e-06, 'epoch': 0.5853462964819084}\n",
      "{'loss': 1.3464, 'grad_norm': 13.505138397216797, 'learning_rate': 2.068256991079483e-06, 'epoch': 0.5863486017841034}\n",
      "{'loss': 1.1839, 'grad_norm': 16.401838302612305, 'learning_rate': 2.0632454645685075e-06, 'epoch': 0.5873509070862984}\n",
      "{'loss': 0.6921, 'grad_norm': 11.735501289367676, 'learning_rate': 2.0582339380575327e-06, 'epoch': 0.5883532123884936}\n",
      "{'loss': 1.6083, 'grad_norm': 0.0, 'learning_rate': 2.0532224115465575e-06, 'epoch': 0.5893555176906886}\n",
      "{'loss': 0.7053, 'grad_norm': 27.759235382080078, 'learning_rate': 2.048210885035582e-06, 'epoch': 0.5903578229928836}\n",
      "{'loss': 1.6881, 'grad_norm': 24.45797348022461, 'learning_rate': 2.0431993585246067e-06, 'epoch': 0.5913601282950787}\n",
      "{'loss': 1.2758, 'grad_norm': 11.933806419372559, 'learning_rate': 2.0381878320136314e-06, 'epoch': 0.5923624335972737}\n",
      "{'loss': 1.8727, 'grad_norm': 15.23976993560791, 'learning_rate': 2.0331763055026562e-06, 'epoch': 0.5933647388994687}\n",
      "{'loss': 1.2877, 'grad_norm': 36.35111618041992, 'learning_rate': 2.028164778991681e-06, 'epoch': 0.5943670442016639}\n",
      "{'loss': 1.547, 'grad_norm': 0.0, 'learning_rate': 2.023153252480706e-06, 'epoch': 0.5953693495038589}\n",
      "{'loss': 1.9687, 'grad_norm': 9.151509284973145, 'learning_rate': 2.0181417259697306e-06, 'epoch': 0.5963716548060539}\n",
      "{'loss': 1.9947, 'grad_norm': 26.16470718383789, 'learning_rate': 2.0131301994587554e-06, 'epoch': 0.597373960108249}\n",
      "{'loss': 1.4532, 'grad_norm': 13.008451461791992, 'learning_rate': 2.00811867294778e-06, 'epoch': 0.598376265410444}\n",
      "{'loss': 1.0807, 'grad_norm': 17.211936950683594, 'learning_rate': 2.003107146436805e-06, 'epoch': 0.5993785707126391}\n",
      "{'loss': 1.1546, 'grad_norm': 22.021507263183594, 'learning_rate': 1.9980956199258293e-06, 'epoch': 0.6003808760148341}\n",
      "{'loss': 1.2529, 'grad_norm': 17.770530700683594, 'learning_rate': 1.993084093414854e-06, 'epoch': 0.6013831813170292}\n",
      "{'loss': 1.8917, 'grad_norm': 15.026745796203613, 'learning_rate': 1.9880725669038793e-06, 'epoch': 0.6023854866192242}\n",
      "{'loss': 1.3401, 'grad_norm': 13.299038887023926, 'learning_rate': 1.9830610403929037e-06, 'epoch': 0.6033877919214192}\n",
      "{'loss': 1.203, 'grad_norm': 11.69946002960205, 'learning_rate': 1.9780495138819285e-06, 'epoch': 0.6043900972236144}\n",
      "{'loss': 2.0021, 'grad_norm': 10.46647834777832, 'learning_rate': 1.9730379873709537e-06, 'epoch': 0.6053924025258094}\n",
      "{'loss': 1.3674, 'grad_norm': 8.72337818145752, 'learning_rate': 1.968026460859978e-06, 'epoch': 0.6063947078280044}\n",
      "{'loss': 1.1331, 'grad_norm': 16.066905975341797, 'learning_rate': 1.963014934349003e-06, 'epoch': 0.6073970131301994}\n",
      "{'loss': 1.7358, 'grad_norm': 22.475488662719727, 'learning_rate': 1.9580034078380276e-06, 'epoch': 0.6083993184323945}\n",
      "{'loss': 1.2361, 'grad_norm': 23.12981605529785, 'learning_rate': 1.9529918813270524e-06, 'epoch': 0.6094016237345895}\n",
      "{'loss': 1.2246, 'grad_norm': 20.399141311645508, 'learning_rate': 1.947980354816077e-06, 'epoch': 0.6104039290367846}\n",
      "{'loss': 1.2518, 'grad_norm': 10.450234413146973, 'learning_rate': 1.942968828305102e-06, 'epoch': 0.6114062343389797}\n",
      "{'loss': 1.5586, 'grad_norm': 12.08622932434082, 'learning_rate': 1.9379573017941268e-06, 'epoch': 0.6124085396411747}\n",
      "{'loss': 2.1228, 'grad_norm': 16.509273529052734, 'learning_rate': 1.9329457752831516e-06, 'epoch': 0.6134108449433697}\n",
      "{'loss': 1.3136, 'grad_norm': 59.05690383911133, 'learning_rate': 1.927934248772176e-06, 'epoch': 0.6144131502455648}\n",
      "{'loss': 2.7001, 'grad_norm': 10.307798385620117, 'learning_rate': 1.922922722261201e-06, 'epoch': 0.6154154555477599}\n",
      "{'loss': 1.7608, 'grad_norm': 14.432234764099121, 'learning_rate': 1.9179111957502255e-06, 'epoch': 0.6164177608499549}\n",
      "{'loss': 1.9674, 'grad_norm': 11.878849983215332, 'learning_rate': 1.9128996692392503e-06, 'epoch': 0.61742006615215}\n",
      "{'loss': 1.1945, 'grad_norm': 10.945359230041504, 'learning_rate': 1.907888142728275e-06, 'epoch': 0.618422371454345}\n",
      "{'loss': 1.3122, 'grad_norm': 9.69983959197998, 'learning_rate': 1.9028766162172999e-06, 'epoch': 0.61942467675654}\n",
      "{'loss': 1.5959, 'grad_norm': 13.844761848449707, 'learning_rate': 1.8978650897063246e-06, 'epoch': 0.6204269820587351}\n",
      "{'loss': 2.4614, 'grad_norm': 24.04725456237793, 'learning_rate': 1.8928535631953496e-06, 'epoch': 0.6214292873609302}\n",
      "{'loss': 1.1869, 'grad_norm': 9.123616218566895, 'learning_rate': 1.8878420366843742e-06, 'epoch': 0.6224315926631252}\n",
      "{'loss': 1.8011, 'grad_norm': 23.608352661132812, 'learning_rate': 1.882830510173399e-06, 'epoch': 0.6234338979653202}\n",
      "{'loss': 1.6888, 'grad_norm': 12.799588203430176, 'learning_rate': 1.8778189836624236e-06, 'epoch': 0.6244362032675153}\n",
      "{'loss': 1.4956, 'grad_norm': 11.742740631103516, 'learning_rate': 1.8728074571514484e-06, 'epoch': 0.6254385085697103}\n",
      "{'loss': 1.4993, 'grad_norm': 10.18542194366455, 'learning_rate': 1.8677959306404734e-06, 'epoch': 0.6264408138719054}\n",
      "{'loss': 1.5323, 'grad_norm': 10.598173141479492, 'learning_rate': 1.862784404129498e-06, 'epoch': 0.6274431191741004}\n",
      "{'loss': 1.94, 'grad_norm': 8.988020896911621, 'learning_rate': 1.8577728776185227e-06, 'epoch': 0.6284454244762955}\n",
      "{'loss': 1.3229, 'grad_norm': 11.134634971618652, 'learning_rate': 1.8527613511075477e-06, 'epoch': 0.6294477297784905}\n",
      "{'loss': 1.5162, 'grad_norm': 9.323567390441895, 'learning_rate': 1.8477498245965723e-06, 'epoch': 0.6304500350806855}\n",
      "{'loss': 0.8403, 'grad_norm': 15.57303237915039, 'learning_rate': 1.842738298085597e-06, 'epoch': 0.6314523403828807}\n",
      "{'loss': 1.0089, 'grad_norm': 10.074250221252441, 'learning_rate': 1.8377267715746217e-06, 'epoch': 0.6324546456850757}\n",
      "{'loss': 2.0565, 'grad_norm': 14.443657875061035, 'learning_rate': 1.8327152450636465e-06, 'epoch': 0.6334569509872707}\n",
      "{'loss': 1.5485, 'grad_norm': 8.537012100219727, 'learning_rate': 1.8277037185526715e-06, 'epoch': 0.6344592562894658}\n",
      "{'loss': 1.0196, 'grad_norm': 11.881120681762695, 'learning_rate': 1.822692192041696e-06, 'epoch': 0.6354615615916608}\n",
      "{'loss': 1.4709, 'grad_norm': 25.620168685913086, 'learning_rate': 1.8176806655307208e-06, 'epoch': 0.6364638668938559}\n",
      "{'loss': 1.5193, 'grad_norm': 19.11792755126953, 'learning_rate': 1.8126691390197456e-06, 'epoch': 0.637466172196051}\n",
      "{'loss': 1.191, 'grad_norm': 14.309096336364746, 'learning_rate': 1.8076576125087702e-06, 'epoch': 0.638468477498246}\n",
      "{'loss': 1.7093, 'grad_norm': 27.29726791381836, 'learning_rate': 1.8026460859977952e-06, 'epoch': 0.639470782800441}\n",
      "{'loss': 1.4173, 'grad_norm': 36.876399993896484, 'learning_rate': 1.7976345594868198e-06, 'epoch': 0.640473088102636}\n",
      "{'loss': 1.0774, 'grad_norm': 16.80419921875, 'learning_rate': 1.7926230329758445e-06, 'epoch': 0.6414753934048311}\n",
      "{'loss': 1.5951, 'grad_norm': 21.954030990600586, 'learning_rate': 1.7876115064648693e-06, 'epoch': 0.6424776987070262}\n",
      "{'loss': 1.4165, 'grad_norm': 12.30982494354248, 'learning_rate': 1.782599979953894e-06, 'epoch': 0.6434800040092212}\n",
      "{'loss': 1.2517, 'grad_norm': 20.605060577392578, 'learning_rate': 1.777588453442919e-06, 'epoch': 0.6444823093114163}\n",
      "{'loss': 1.5088, 'grad_norm': 9.223894119262695, 'learning_rate': 1.7725769269319437e-06, 'epoch': 0.6454846146136113}\n",
      "{'loss': 1.4313, 'grad_norm': 24.86235809326172, 'learning_rate': 1.7675654004209683e-06, 'epoch': 0.6464869199158063}\n",
      "{'loss': 1.9686, 'grad_norm': 13.893159866333008, 'learning_rate': 1.7625538739099933e-06, 'epoch': 0.6474892252180015}\n",
      "{'loss': 1.1157, 'grad_norm': 15.561156272888184, 'learning_rate': 1.757542347399018e-06, 'epoch': 0.6484915305201965}\n",
      "{'loss': 1.3519, 'grad_norm': 17.224748611450195, 'learning_rate': 1.7525308208880426e-06, 'epoch': 0.6494938358223915}\n",
      "{'loss': 0.9582, 'grad_norm': 0.0, 'learning_rate': 1.7475192943770674e-06, 'epoch': 0.6504961411245865}\n",
      "{'loss': 1.2305, 'grad_norm': 11.96933650970459, 'learning_rate': 1.742507767866092e-06, 'epoch': 0.6514984464267816}\n",
      "{'loss': 1.6353, 'grad_norm': 15.912944793701172, 'learning_rate': 1.737496241355117e-06, 'epoch': 0.6525007517289766}\n",
      "{'loss': 0.945, 'grad_norm': 10.041759490966797, 'learning_rate': 1.7324847148441418e-06, 'epoch': 0.6535030570311717}\n",
      "{'loss': 1.7616, 'grad_norm': 12.674259185791016, 'learning_rate': 1.7274731883331663e-06, 'epoch': 0.6545053623333668}\n",
      "{'loss': 1.9069, 'grad_norm': 15.342361450195312, 'learning_rate': 1.7224616618221911e-06, 'epoch': 0.6555076676355618}\n",
      "{'loss': 1.5902, 'grad_norm': 19.39878273010254, 'learning_rate': 1.7174501353112161e-06, 'epoch': 0.6565099729377568}\n",
      "{'loss': 1.5672, 'grad_norm': 19.233917236328125, 'learning_rate': 1.7124386088002407e-06, 'epoch': 0.6575122782399518}\n",
      "{'loss': 1.4324, 'grad_norm': 17.2698917388916, 'learning_rate': 1.7074270822892655e-06, 'epoch': 0.658514583542147}\n",
      "{'loss': 1.6275, 'grad_norm': 27.640165328979492, 'learning_rate': 1.70241555577829e-06, 'epoch': 0.659516888844342}\n",
      "{'loss': 1.125, 'grad_norm': 18.505197525024414, 'learning_rate': 1.6974040292673149e-06, 'epoch': 0.660519194146537}\n",
      "{'loss': 2.3172, 'grad_norm': 16.034236907958984, 'learning_rate': 1.6923925027563399e-06, 'epoch': 0.6615214994487321}\n",
      "{'loss': 1.4278, 'grad_norm': 20.681394577026367, 'learning_rate': 1.6873809762453644e-06, 'epoch': 0.6625238047509271}\n",
      "{'loss': 1.0934, 'grad_norm': 6.540082931518555, 'learning_rate': 1.6823694497343892e-06, 'epoch': 0.6635261100531222}\n",
      "{'loss': 1.4476, 'grad_norm': 20.398080825805664, 'learning_rate': 1.6773579232234142e-06, 'epoch': 0.6645284153553173}\n",
      "{'loss': 1.3688, 'grad_norm': 7.171396732330322, 'learning_rate': 1.6723463967124388e-06, 'epoch': 0.6655307206575123}\n",
      "{'loss': 1.324, 'grad_norm': 9.21703052520752, 'learning_rate': 1.6673348702014636e-06, 'epoch': 0.6665330259597073}\n",
      "{'loss': 1.1049, 'grad_norm': 8.94095230102539, 'learning_rate': 1.6623233436904882e-06, 'epoch': 0.6675353312619023}\n",
      "{'loss': 1.0249, 'grad_norm': 18.287742614746094, 'learning_rate': 1.657311817179513e-06, 'epoch': 0.6685376365640974}\n",
      "{'loss': 1.362, 'grad_norm': 11.900729179382324, 'learning_rate': 1.652300290668538e-06, 'epoch': 0.6695399418662925}\n",
      "{'loss': 1.6417, 'grad_norm': 10.458698272705078, 'learning_rate': 1.6472887641575625e-06, 'epoch': 0.6705422471684875}\n",
      "{'loss': 0.9463, 'grad_norm': 10.79769229888916, 'learning_rate': 1.6422772376465873e-06, 'epoch': 0.6715445524706826}\n",
      "{'loss': 1.1997, 'grad_norm': 25.51441192626953, 'learning_rate': 1.637265711135612e-06, 'epoch': 0.6725468577728776}\n",
      "{'loss': 1.5419, 'grad_norm': 11.129987716674805, 'learning_rate': 1.6322541846246367e-06, 'epoch': 0.6735491630750726}\n",
      "{'loss': 0.8618, 'grad_norm': 25.694908142089844, 'learning_rate': 1.6272426581136617e-06, 'epoch': 0.6745514683772678}\n",
      "{'loss': 1.655, 'grad_norm': 20.87164878845215, 'learning_rate': 1.6222311316026862e-06, 'epoch': 0.6755537736794628}\n",
      "{'loss': 1.4519, 'grad_norm': 17.908884048461914, 'learning_rate': 1.617219605091711e-06, 'epoch': 0.6765560789816578}\n",
      "{'loss': 1.8525, 'grad_norm': 9.883346557617188, 'learning_rate': 1.6122080785807358e-06, 'epoch': 0.6775583842838528}\n",
      "{'loss': 1.5944, 'grad_norm': 17.621267318725586, 'learning_rate': 1.6071965520697604e-06, 'epoch': 0.6785606895860479}\n",
      "{'loss': 1.3822, 'grad_norm': 16.965139389038086, 'learning_rate': 1.6021850255587854e-06, 'epoch': 0.679562994888243}\n",
      "{'loss': 0.9153, 'grad_norm': 9.145263671875, 'learning_rate': 1.5971734990478102e-06, 'epoch': 0.680565300190438}\n",
      "{'loss': 1.7269, 'grad_norm': 15.111018180847168, 'learning_rate': 1.5921619725368348e-06, 'epoch': 0.6815676054926331}\n",
      "{'loss': 1.4811, 'grad_norm': 8.631134033203125, 'learning_rate': 1.5871504460258598e-06, 'epoch': 0.6825699107948281}\n",
      "{'loss': 1.3343, 'grad_norm': 25.122413635253906, 'learning_rate': 1.5821389195148843e-06, 'epoch': 0.6835722160970231}\n",
      "{'loss': 1.4113, 'grad_norm': 15.944071769714355, 'learning_rate': 1.5771273930039091e-06, 'epoch': 0.6845745213992181}\n",
      "{'loss': 1.3297, 'grad_norm': 34.60544204711914, 'learning_rate': 1.572115866492934e-06, 'epoch': 0.6855768267014133}\n",
      "{'loss': 0.8866, 'grad_norm': 21.484474182128906, 'learning_rate': 1.5671043399819585e-06, 'epoch': 0.6865791320036083}\n",
      "{'loss': 0.7814, 'grad_norm': 37.18497085571289, 'learning_rate': 1.5620928134709835e-06, 'epoch': 0.6875814373058033}\n",
      "{'loss': 1.6967, 'grad_norm': 17.65485191345215, 'learning_rate': 1.5570812869600083e-06, 'epoch': 0.6885837426079984}\n",
      "{'loss': 1.7765, 'grad_norm': 14.500349044799805, 'learning_rate': 1.5520697604490328e-06, 'epoch': 0.6895860479101934}\n",
      "{'loss': 1.1584, 'grad_norm': 23.747350692749023, 'learning_rate': 1.5470582339380576e-06, 'epoch': 0.6905883532123885}\n",
      "{'loss': 2.0518, 'grad_norm': 12.176809310913086, 'learning_rate': 1.5420467074270822e-06, 'epoch': 0.6915906585145836}\n",
      "{'loss': 1.6522, 'grad_norm': 15.49749755859375, 'learning_rate': 1.5370351809161072e-06, 'epoch': 0.6925929638167786}\n",
      "{'loss': 1.2346, 'grad_norm': 13.932506561279297, 'learning_rate': 1.532023654405132e-06, 'epoch': 0.6935952691189736}\n",
      "{'loss': 1.7116, 'grad_norm': 8.453855514526367, 'learning_rate': 1.5270121278941566e-06, 'epoch': 0.6945975744211687}\n",
      "{'loss': 1.3883, 'grad_norm': 19.49812889099121, 'learning_rate': 1.5220006013831814e-06, 'epoch': 0.6955998797233638}\n",
      "{'loss': 1.1372, 'grad_norm': 40.73799514770508, 'learning_rate': 1.5169890748722064e-06, 'epoch': 0.6966021850255588}\n",
      "{'loss': 1.4364, 'grad_norm': 10.958378791809082, 'learning_rate': 1.511977548361231e-06, 'epoch': 0.6976044903277538}\n",
      "{'loss': 1.7845, 'grad_norm': 12.15709400177002, 'learning_rate': 1.5069660218502557e-06, 'epoch': 0.6986067956299489}\n",
      "{'loss': 1.8655, 'grad_norm': 17.341373443603516, 'learning_rate': 1.5019544953392803e-06, 'epoch': 0.6996091009321439}\n",
      "{'loss': 1.5968, 'grad_norm': 9.627890586853027, 'learning_rate': 1.4969429688283053e-06, 'epoch': 0.7006114062343389}\n",
      "{'loss': 1.579, 'grad_norm': 13.903176307678223, 'learning_rate': 1.49193144231733e-06, 'epoch': 0.7016137115365341}\n",
      "{'loss': 1.0181, 'grad_norm': 25.756546020507812, 'learning_rate': 1.4869199158063547e-06, 'epoch': 0.7026160168387291}\n",
      "{'loss': 1.4959, 'grad_norm': 17.66179084777832, 'learning_rate': 1.4819083892953794e-06, 'epoch': 0.7036183221409241}\n",
      "{'loss': 1.4817, 'grad_norm': 14.418830871582031, 'learning_rate': 1.4768968627844044e-06, 'epoch': 0.7046206274431192}\n",
      "{'loss': 1.2341, 'grad_norm': 11.722993850708008, 'learning_rate': 1.471885336273429e-06, 'epoch': 0.7056229327453142}\n",
      "{'loss': 1.1622, 'grad_norm': 21.854137420654297, 'learning_rate': 1.4668738097624538e-06, 'epoch': 0.7066252380475093}\n",
      "{'loss': 1.1042, 'grad_norm': 9.454957962036133, 'learning_rate': 1.4618622832514784e-06, 'epoch': 0.7076275433497043}\n",
      "{'loss': 2.4038, 'grad_norm': 11.195249557495117, 'learning_rate': 1.4568507567405032e-06, 'epoch': 0.7086298486518994}\n",
      "{'loss': 2.3214, 'grad_norm': 32.52790451049805, 'learning_rate': 1.4518392302295282e-06, 'epoch': 0.7096321539540944}\n",
      "{'loss': 1.18, 'grad_norm': 31.672033309936523, 'learning_rate': 1.4468277037185527e-06, 'epoch': 0.7106344592562894}\n",
      "{'loss': 1.7483, 'grad_norm': 36.074867248535156, 'learning_rate': 1.4418161772075775e-06, 'epoch': 0.7116367645584846}\n",
      "{'loss': 1.4902, 'grad_norm': 15.888368606567383, 'learning_rate': 1.4368046506966023e-06, 'epoch': 0.7126390698606796}\n",
      "{'loss': 1.0589, 'grad_norm': 10.153585433959961, 'learning_rate': 1.4317931241856269e-06, 'epoch': 0.7136413751628746}\n",
      "{'loss': 1.3345, 'grad_norm': 17.54024314880371, 'learning_rate': 1.4267815976746519e-06, 'epoch': 0.7146436804650697}\n",
      "{'loss': 1.5689, 'grad_norm': 7.811549186706543, 'learning_rate': 1.4217700711636765e-06, 'epoch': 0.7156459857672647}\n",
      "{'loss': 1.6258, 'grad_norm': 9.571669578552246, 'learning_rate': 1.4167585446527012e-06, 'epoch': 0.7166482910694597}\n",
      "{'loss': 2.1793, 'grad_norm': 13.727773666381836, 'learning_rate': 1.4117470181417262e-06, 'epoch': 0.7176505963716548}\n",
      "{'loss': 1.3758, 'grad_norm': 12.478890419006348, 'learning_rate': 1.4067354916307508e-06, 'epoch': 0.7186529016738499}\n",
      "{'loss': 1.2729, 'grad_norm': 8.761932373046875, 'learning_rate': 1.4017239651197756e-06, 'epoch': 0.7196552069760449}\n",
      "{'loss': 0.9308, 'grad_norm': 9.054332733154297, 'learning_rate': 1.3967124386088004e-06, 'epoch': 0.7206575122782399}\n",
      "{'loss': 1.5066, 'grad_norm': 10.213220596313477, 'learning_rate': 1.391700912097825e-06, 'epoch': 0.721659817580435}\n",
      "{'loss': 1.8092, 'grad_norm': 13.352546691894531, 'learning_rate': 1.38668938558685e-06, 'epoch': 0.7226621228826301}\n",
      "{'loss': 1.7859, 'grad_norm': 0.0, 'learning_rate': 1.3816778590758748e-06, 'epoch': 0.7236644281848251}\n",
      "{'loss': 1.1181, 'grad_norm': 18.23788070678711, 'learning_rate': 1.3766663325648993e-06, 'epoch': 0.7246667334870202}\n",
      "{'loss': 0.7243, 'grad_norm': 12.28699779510498, 'learning_rate': 1.3716548060539241e-06, 'epoch': 0.7256690387892152}\n",
      "{'loss': 2.2023, 'grad_norm': 8.640417098999023, 'learning_rate': 1.3666432795429487e-06, 'epoch': 0.7266713440914102}\n",
      "{'loss': 1.3486, 'grad_norm': 6.917254447937012, 'learning_rate': 1.3616317530319737e-06, 'epoch': 0.7276736493936052}\n",
      "{'loss': 2.0624, 'grad_norm': 29.01839256286621, 'learning_rate': 1.3566202265209985e-06, 'epoch': 0.7286759546958004}\n",
      "{'loss': 1.8449, 'grad_norm': 15.618517875671387, 'learning_rate': 1.351608700010023e-06, 'epoch': 0.7296782599979954}\n",
      "{'loss': 0.924, 'grad_norm': 9.149222373962402, 'learning_rate': 1.3465971734990478e-06, 'epoch': 0.7306805653001904}\n",
      "{'loss': 1.4564, 'grad_norm': 15.199481964111328, 'learning_rate': 1.3415856469880728e-06, 'epoch': 0.7316828706023855}\n",
      "{'loss': 1.6469, 'grad_norm': 27.736064910888672, 'learning_rate': 1.3365741204770974e-06, 'epoch': 0.7326851759045805}\n",
      "{'loss': 0.9447, 'grad_norm': 9.836743354797363, 'learning_rate': 1.3315625939661222e-06, 'epoch': 0.7336874812067756}\n",
      "{'loss': 1.5004, 'grad_norm': 16.898353576660156, 'learning_rate': 1.3265510674551468e-06, 'epoch': 0.7346897865089707}\n",
      "{'loss': 1.39, 'grad_norm': 15.609642028808594, 'learning_rate': 1.3215395409441718e-06, 'epoch': 0.7356920918111657}\n",
      "{'loss': 0.7666, 'grad_norm': 14.310450553894043, 'learning_rate': 1.3165280144331966e-06, 'epoch': 0.7366943971133607}\n",
      "{'loss': 1.4547, 'grad_norm': 21.88072967529297, 'learning_rate': 1.3115164879222211e-06, 'epoch': 0.7376967024155557}\n",
      "{'loss': 1.5183, 'grad_norm': 25.58195686340332, 'learning_rate': 1.306504961411246e-06, 'epoch': 0.7386990077177509}\n",
      "{'loss': 2.1594, 'grad_norm': 10.454694747924805, 'learning_rate': 1.301493434900271e-06, 'epoch': 0.7397013130199459}\n",
      "{'loss': 1.0929, 'grad_norm': 10.158299446105957, 'learning_rate': 1.2964819083892955e-06, 'epoch': 0.7407036183221409}\n",
      "{'loss': 1.6155, 'grad_norm': 8.304847717285156, 'learning_rate': 1.2914703818783203e-06, 'epoch': 0.741705923624336}\n",
      "{'loss': 1.6612, 'grad_norm': 16.787519454956055, 'learning_rate': 1.2864588553673449e-06, 'epoch': 0.742708228926531}\n",
      "{'loss': 1.375, 'grad_norm': 18.160873413085938, 'learning_rate': 1.2814473288563697e-06, 'epoch': 0.743710534228726}\n",
      "{'loss': 1.8818, 'grad_norm': 10.250872611999512, 'learning_rate': 1.2764358023453947e-06, 'epoch': 0.7447128395309212}\n",
      "{'loss': 1.567, 'grad_norm': 16.882890701293945, 'learning_rate': 1.2714242758344192e-06, 'epoch': 0.7457151448331162}\n",
      "{'loss': 1.0976, 'grad_norm': 11.434388160705566, 'learning_rate': 1.266412749323444e-06, 'epoch': 0.7467174501353112}\n",
      "{'loss': 1.3224, 'grad_norm': 14.774144172668457, 'learning_rate': 1.2614012228124688e-06, 'epoch': 0.7477197554375062}\n",
      "{'loss': 1.8333, 'grad_norm': 35.85459899902344, 'learning_rate': 1.2563896963014936e-06, 'epoch': 0.7487220607397013}\n",
      "{'loss': 2.5415, 'grad_norm': 35.216678619384766, 'learning_rate': 1.2513781697905184e-06, 'epoch': 0.7497243660418964}\n",
      "{'loss': 1.4721, 'grad_norm': 8.371736526489258, 'learning_rate': 1.2463666432795432e-06, 'epoch': 0.7507266713440914}\n",
      "{'loss': 1.0921, 'grad_norm': 13.370111465454102, 'learning_rate': 1.2413551167685677e-06, 'epoch': 0.7517289766462865}\n",
      "{'loss': 1.2882, 'grad_norm': 10.610965728759766, 'learning_rate': 1.2363435902575925e-06, 'epoch': 0.7527312819484815}\n",
      "{'loss': 1.1435, 'grad_norm': 12.394271850585938, 'learning_rate': 1.2313320637466173e-06, 'epoch': 0.7537335872506765}\n",
      "{'loss': 1.5911, 'grad_norm': 20.990636825561523, 'learning_rate': 1.226320537235642e-06, 'epoch': 0.7547358925528717}\n",
      "{'loss': 1.5356, 'grad_norm': 15.046619415283203, 'learning_rate': 1.2213090107246669e-06, 'epoch': 0.7557381978550667}\n",
      "{'loss': 1.3803, 'grad_norm': 8.934220314025879, 'learning_rate': 1.2162974842136915e-06, 'epoch': 0.7567405031572617}\n",
      "{'loss': 1.4615, 'grad_norm': 12.939654350280762, 'learning_rate': 1.2112859577027165e-06, 'epoch': 0.7577428084594567}\n",
      "{'loss': 1.5659, 'grad_norm': 14.658014297485352, 'learning_rate': 1.206274431191741e-06, 'epoch': 0.7587451137616518}\n",
      "{'loss': 1.6731, 'grad_norm': 26.595775604248047, 'learning_rate': 1.2012629046807658e-06, 'epoch': 0.7597474190638468}\n",
      "{'loss': 0.71, 'grad_norm': 33.543087005615234, 'learning_rate': 1.1962513781697906e-06, 'epoch': 0.7607497243660419}\n",
      "{'loss': 1.3048, 'grad_norm': 13.284706115722656, 'learning_rate': 1.1912398516588154e-06, 'epoch': 0.761752029668237}\n",
      "{'loss': 2.1138, 'grad_norm': 11.574664115905762, 'learning_rate': 1.1862283251478402e-06, 'epoch': 0.762754334970432}\n",
      "{'loss': 1.7868, 'grad_norm': 24.27022933959961, 'learning_rate': 1.1812167986368648e-06, 'epoch': 0.763756640272627}\n",
      "{'loss': 1.0888, 'grad_norm': 12.540980339050293, 'learning_rate': 1.1762052721258896e-06, 'epoch': 0.764758945574822}\n",
      "{'loss': 0.7133, 'grad_norm': 20.139802932739258, 'learning_rate': 1.1711937456149143e-06, 'epoch': 0.7657612508770172}\n",
      "{'loss': 1.3765, 'grad_norm': 22.86490821838379, 'learning_rate': 1.1661822191039391e-06, 'epoch': 0.7667635561792122}\n",
      "{'loss': 1.5706, 'grad_norm': 23.633359909057617, 'learning_rate': 1.161170692592964e-06, 'epoch': 0.7677658614814072}\n",
      "{'loss': 1.6843, 'grad_norm': 0.0, 'learning_rate': 1.1561591660819887e-06, 'epoch': 0.7687681667836023}\n",
      "{'loss': 1.727, 'grad_norm': 15.96298885345459, 'learning_rate': 1.1511476395710135e-06, 'epoch': 0.7697704720857973}\n",
      "{'loss': 1.4685, 'grad_norm': 31.879932403564453, 'learning_rate': 1.1461361130600383e-06, 'epoch': 0.7707727773879924}\n",
      "{'loss': 1.4733, 'grad_norm': 12.631579399108887, 'learning_rate': 1.1411245865490629e-06, 'epoch': 0.7717750826901875}\n",
      "{'loss': 1.9978, 'grad_norm': 12.054656028747559, 'learning_rate': 1.1361130600380876e-06, 'epoch': 0.7727773879923825}\n",
      "{'loss': 1.1136, 'grad_norm': 15.56416130065918, 'learning_rate': 1.1311015335271124e-06, 'epoch': 0.7737796932945775}\n",
      "{'loss': 0.9232, 'grad_norm': 11.804728507995605, 'learning_rate': 1.1260900070161372e-06, 'epoch': 0.7747819985967725}\n",
      "{'loss': 1.1973, 'grad_norm': 12.873053550720215, 'learning_rate': 1.121078480505162e-06, 'epoch': 0.7757843038989676}\n",
      "{'loss': 2.1195, 'grad_norm': 18.39056396484375, 'learning_rate': 1.1160669539941866e-06, 'epoch': 0.7767866092011627}\n",
      "{'loss': 1.9579, 'grad_norm': 10.10499382019043, 'learning_rate': 1.1110554274832116e-06, 'epoch': 0.7777889145033577}\n",
      "{'loss': 1.2593, 'grad_norm': 27.588115692138672, 'learning_rate': 1.1060439009722362e-06, 'epoch': 0.7787912198055528}\n",
      "{'loss': 1.1198, 'grad_norm': 24.94190788269043, 'learning_rate': 1.101032374461261e-06, 'epoch': 0.7797935251077478}\n",
      "{'loss': 1.5219, 'grad_norm': 11.82473087310791, 'learning_rate': 1.0960208479502857e-06, 'epoch': 0.7807958304099428}\n",
      "{'loss': 1.2796, 'grad_norm': 8.528437614440918, 'learning_rate': 1.0910093214393105e-06, 'epoch': 0.781798135712138}\n",
      "{'loss': 1.3294, 'grad_norm': 28.17711067199707, 'learning_rate': 1.0859977949283353e-06, 'epoch': 0.782800441014333}\n",
      "{'loss': 1.0372, 'grad_norm': 12.849823951721191, 'learning_rate': 1.08098626841736e-06, 'epoch': 0.783802746316528}\n",
      "{'loss': 0.7863, 'grad_norm': 26.517118453979492, 'learning_rate': 1.0759747419063847e-06, 'epoch': 0.784805051618723}\n",
      "{'loss': 1.2822, 'grad_norm': 13.564128875732422, 'learning_rate': 1.0709632153954097e-06, 'epoch': 0.7858073569209181}\n",
      "{'loss': 1.3288, 'grad_norm': 9.582756042480469, 'learning_rate': 1.0659516888844342e-06, 'epoch': 0.7868096622231132}\n",
      "{'loss': 2.2656, 'grad_norm': 14.616302490234375, 'learning_rate': 1.060940162373459e-06, 'epoch': 0.7878119675253082}\n",
      "{'loss': 1.3512, 'grad_norm': 9.170554161071777, 'learning_rate': 1.0559286358624838e-06, 'epoch': 0.7888142728275033}\n",
      "{'loss': 1.2644, 'grad_norm': 9.675957679748535, 'learning_rate': 1.0509171093515086e-06, 'epoch': 0.7898165781296983}\n",
      "{'loss': 1.3081, 'grad_norm': 12.999937057495117, 'learning_rate': 1.0459055828405334e-06, 'epoch': 0.7908188834318933}\n",
      "{'loss': 1.4897, 'grad_norm': 12.398663520812988, 'learning_rate': 1.040894056329558e-06, 'epoch': 0.7918211887340884}\n",
      "{'loss': 1.213, 'grad_norm': 16.141881942749023, 'learning_rate': 1.035882529818583e-06, 'epoch': 0.7928234940362835}\n",
      "{'loss': 1.4364, 'grad_norm': 23.450902938842773, 'learning_rate': 1.0308710033076075e-06, 'epoch': 0.7938257993384785}\n",
      "{'loss': 0.949, 'grad_norm': 11.809121131896973, 'learning_rate': 1.0258594767966323e-06, 'epoch': 0.7948281046406735}\n",
      "{'loss': 0.7257, 'grad_norm': 14.645112991333008, 'learning_rate': 1.0208479502856571e-06, 'epoch': 0.7958304099428686}\n",
      "{'loss': 1.442, 'grad_norm': 35.465476989746094, 'learning_rate': 1.015836423774682e-06, 'epoch': 0.7968327152450636}\n",
      "{'loss': 1.6018, 'grad_norm': 20.190019607543945, 'learning_rate': 1.0108248972637067e-06, 'epoch': 0.7978350205472587}\n",
      "{'loss': 1.5491, 'grad_norm': 13.298904418945312, 'learning_rate': 1.0058133707527313e-06, 'epoch': 0.7988373258494538}\n",
      "{'loss': 1.4277, 'grad_norm': 36.490596771240234, 'learning_rate': 1.000801844241756e-06, 'epoch': 0.7998396311516488}\n",
      "{'loss': 1.7768, 'grad_norm': 11.907781600952148, 'learning_rate': 9.95790317730781e-07, 'epoch': 0.8008419364538438}\n",
      "{'loss': 1.3357, 'grad_norm': 9.898262977600098, 'learning_rate': 9.907787912198056e-07, 'epoch': 0.8018442417560389}\n",
      "{'loss': 0.7893, 'grad_norm': 8.91207504272461, 'learning_rate': 9.857672647088304e-07, 'epoch': 0.8028465470582339}\n",
      "{'loss': 1.9651, 'grad_norm': 19.129451751708984, 'learning_rate': 9.807557381978552e-07, 'epoch': 0.803848852360429}\n",
      "{'loss': 1.1232, 'grad_norm': 15.855335235595703, 'learning_rate': 9.7574421168688e-07, 'epoch': 0.804851157662624}\n",
      "{'loss': 1.6386, 'grad_norm': 13.515528678894043, 'learning_rate': 9.707326851759048e-07, 'epoch': 0.8058534629648191}\n",
      "{'loss': 1.3098, 'grad_norm': 11.543404579162598, 'learning_rate': 9.657211586649293e-07, 'epoch': 0.8068557682670141}\n",
      "{'loss': 1.3816, 'grad_norm': 19.516738891601562, 'learning_rate': 9.607096321539541e-07, 'epoch': 0.8078580735692091}\n",
      "{'loss': 1.5139, 'grad_norm': 17.305559158325195, 'learning_rate': 9.55698105642979e-07, 'epoch': 0.8088603788714043}\n",
      "{'loss': 2.1689, 'grad_norm': 13.791899681091309, 'learning_rate': 9.506865791320037e-07, 'epoch': 0.8098626841735993}\n",
      "{'loss': 1.9923, 'grad_norm': 9.697566032409668, 'learning_rate': 9.456750526210284e-07, 'epoch': 0.8108649894757943}\n",
      "{'loss': 1.4399, 'grad_norm': 10.921751022338867, 'learning_rate': 9.406635261100532e-07, 'epoch': 0.8118672947779894}\n",
      "{'loss': 1.3893, 'grad_norm': 12.373015403747559, 'learning_rate': 9.35651999599078e-07, 'epoch': 0.8128696000801844}\n",
      "{'loss': 1.3498, 'grad_norm': 23.39508056640625, 'learning_rate': 9.306404730881028e-07, 'epoch': 0.8138719053823795}\n",
      "{'loss': 0.9315, 'grad_norm': 0.0, 'learning_rate': 9.256289465771274e-07, 'epoch': 0.8148742106845746}\n",
      "{'loss': 1.5164, 'grad_norm': 14.278924942016602, 'learning_rate': 9.206174200661522e-07, 'epoch': 0.8158765159867696}\n",
      "{'loss': 1.6682, 'grad_norm': 17.8605899810791, 'learning_rate': 9.15605893555177e-07, 'epoch': 0.8168788212889646}\n",
      "{'loss': 0.746, 'grad_norm': 24.75887680053711, 'learning_rate': 9.105943670442018e-07, 'epoch': 0.8178811265911596}\n",
      "{'loss': 0.6174, 'grad_norm': 33.18169403076172, 'learning_rate': 9.055828405332265e-07, 'epoch': 0.8188834318933547}\n",
      "{'loss': 0.9961, 'grad_norm': 0.0, 'learning_rate': 9.005713140222512e-07, 'epoch': 0.8198857371955498}\n",
      "{'loss': 1.3864, 'grad_norm': 17.881572723388672, 'learning_rate': 8.95559787511276e-07, 'epoch': 0.8208880424977448}\n",
      "{'loss': 1.4623, 'grad_norm': 35.47628402709961, 'learning_rate': 8.905482610003007e-07, 'epoch': 0.8218903477999399}\n",
      "{'loss': 1.4629, 'grad_norm': 14.491012573242188, 'learning_rate': 8.855367344893255e-07, 'epoch': 0.8228926531021349}\n",
      "{'loss': 1.0513, 'grad_norm': 11.963472366333008, 'learning_rate': 8.805252079783502e-07, 'epoch': 0.8238949584043299}\n",
      "{'loss': 1.7072, 'grad_norm': 11.768739700317383, 'learning_rate': 8.755136814673751e-07, 'epoch': 0.824897263706525}\n",
      "{'loss': 0.6216, 'grad_norm': 24.330955505371094, 'learning_rate': 8.705021549563998e-07, 'epoch': 0.8258995690087201}\n",
      "{'loss': 1.3515, 'grad_norm': 17.20665740966797, 'learning_rate': 8.654906284454246e-07, 'epoch': 0.8269018743109151}\n",
      "{'loss': 1.4529, 'grad_norm': 15.190399169921875, 'learning_rate': 8.604791019344492e-07, 'epoch': 0.8279041796131101}\n",
      "{'loss': 1.2643, 'grad_norm': 0.0, 'learning_rate': 8.554675754234741e-07, 'epoch': 0.8289064849153052}\n",
      "{'loss': 1.9992, 'grad_norm': 20.24798583984375, 'learning_rate': 8.504560489124988e-07, 'epoch': 0.8299087902175003}\n",
      "{'loss': 1.8762, 'grad_norm': 12.39655590057373, 'learning_rate': 8.454445224015236e-07, 'epoch': 0.8309110955196953}\n",
      "{'loss': 1.3596, 'grad_norm': 12.291393280029297, 'learning_rate': 8.404329958905483e-07, 'epoch': 0.8319134008218904}\n",
      "{'loss': 1.4985, 'grad_norm': 17.86966896057129, 'learning_rate': 8.354214693795732e-07, 'epoch': 0.8329157061240854}\n",
      "{'loss': 1.5298, 'grad_norm': 20.468957901000977, 'learning_rate': 8.304099428685979e-07, 'epoch': 0.8339180114262804}\n",
      "{'loss': 1.8021, 'grad_norm': 7.979927062988281, 'learning_rate': 8.253984163576225e-07, 'epoch': 0.8349203167284754}\n",
      "{'loss': 1.4061, 'grad_norm': 15.761537551879883, 'learning_rate': 8.203868898466473e-07, 'epoch': 0.8359226220306706}\n",
      "{'loss': 0.9894, 'grad_norm': 13.88547420501709, 'learning_rate': 8.153753633356721e-07, 'epoch': 0.8369249273328656}\n",
      "{'loss': 1.5167, 'grad_norm': 14.171914100646973, 'learning_rate': 8.103638368246969e-07, 'epoch': 0.8379272326350606}\n",
      "{'loss': 1.7749, 'grad_norm': 21.9610652923584, 'learning_rate': 8.053523103137216e-07, 'epoch': 0.8389295379372557}\n",
      "{'loss': 1.5285, 'grad_norm': 10.640290260314941, 'learning_rate': 8.003407838027464e-07, 'epoch': 0.8399318432394507}\n",
      "{'loss': 1.6661, 'grad_norm': 36.21421432495117, 'learning_rate': 7.953292572917712e-07, 'epoch': 0.8409341485416458}\n",
      "{'loss': 1.442, 'grad_norm': 7.8130903244018555, 'learning_rate': 7.903177307807959e-07, 'epoch': 0.8419364538438409}\n",
      "{'loss': 1.6018, 'grad_norm': 36.33713150024414, 'learning_rate': 7.853062042698206e-07, 'epoch': 0.8429387591460359}\n",
      "{'loss': 1.6862, 'grad_norm': 10.507092475891113, 'learning_rate': 7.802946777588453e-07, 'epoch': 0.8439410644482309}\n",
      "{'loss': 1.8093, 'grad_norm': 14.76690673828125, 'learning_rate': 7.752831512478702e-07, 'epoch': 0.8449433697504259}\n",
      "{'loss': 1.5569, 'grad_norm': 14.94806957244873, 'learning_rate': 7.702716247368949e-07, 'epoch': 0.8459456750526211}\n",
      "{'loss': 1.6516, 'grad_norm': 19.520183563232422, 'learning_rate': 7.652600982259197e-07, 'epoch': 0.8469479803548161}\n",
      "{'loss': 1.2752, 'grad_norm': 16.526243209838867, 'learning_rate': 7.602485717149444e-07, 'epoch': 0.8479502856570111}\n",
      "{'loss': 1.0605, 'grad_norm': 14.11726188659668, 'learning_rate': 7.552370452039692e-07, 'epoch': 0.8489525909592062}\n",
      "{'loss': 1.7324, 'grad_norm': 38.6170768737793, 'learning_rate': 7.502255186929939e-07, 'epoch': 0.8499548962614012}\n",
      "{'loss': 1.4338, 'grad_norm': 15.601237297058105, 'learning_rate': 7.452139921820187e-07, 'epoch': 0.8509572015635962}\n",
      "{'loss': 1.9342, 'grad_norm': 21.44141387939453, 'learning_rate': 7.402024656710434e-07, 'epoch': 0.8519595068657914}\n",
      "{'loss': 1.2237, 'grad_norm': 17.337865829467773, 'learning_rate': 7.351909391600683e-07, 'epoch': 0.8529618121679864}\n",
      "{'loss': 1.5494, 'grad_norm': 10.930466651916504, 'learning_rate': 7.30179412649093e-07, 'epoch': 0.8539641174701814}\n",
      "{'loss': 1.5242, 'grad_norm': 17.651348114013672, 'learning_rate': 7.251678861381177e-07, 'epoch': 0.8549664227723764}\n",
      "{'loss': 1.6635, 'grad_norm': 16.009979248046875, 'learning_rate': 7.201563596271424e-07, 'epoch': 0.8559687280745715}\n",
      "{'loss': 2.3455, 'grad_norm': 15.502015113830566, 'learning_rate': 7.151448331161673e-07, 'epoch': 0.8569710333767666}\n",
      "{'loss': 1.5331, 'grad_norm': 24.662372589111328, 'learning_rate': 7.10133306605192e-07, 'epoch': 0.8579733386789616}\n",
      "{'loss': 1.2215, 'grad_norm': 18.3436279296875, 'learning_rate': 7.051217800942167e-07, 'epoch': 0.8589756439811567}\n",
      "{'loss': 2.0458, 'grad_norm': 8.430785179138184, 'learning_rate': 7.001102535832415e-07, 'epoch': 0.8599779492833517}\n",
      "{'loss': 1.2241, 'grad_norm': 11.053901672363281, 'learning_rate': 6.950987270722663e-07, 'epoch': 0.8609802545855467}\n",
      "{'loss': 1.505, 'grad_norm': 8.63354206085205, 'learning_rate': 6.900872005612911e-07, 'epoch': 0.8619825598877419}\n",
      "{'loss': 1.4344, 'grad_norm': 15.088768005371094, 'learning_rate': 6.850756740503157e-07, 'epoch': 0.8629848651899369}\n",
      "{'loss': 1.0384, 'grad_norm': 10.852890968322754, 'learning_rate': 6.800641475393406e-07, 'epoch': 0.8639871704921319}\n",
      "{'loss': 1.4553, 'grad_norm': 12.152915954589844, 'learning_rate': 6.750526210283653e-07, 'epoch': 0.864989475794327}\n",
      "{'loss': 1.6343, 'grad_norm': 11.770933151245117, 'learning_rate': 6.700410945173901e-07, 'epoch': 0.865991781096522}\n",
      "{'loss': 1.8715, 'grad_norm': 17.91804313659668, 'learning_rate': 6.650295680064148e-07, 'epoch': 0.866994086398717}\n",
      "{'loss': 1.8706, 'grad_norm': 10.28923225402832, 'learning_rate': 6.600180414954397e-07, 'epoch': 0.8679963917009121}\n",
      "{'loss': 1.7741, 'grad_norm': 19.530410766601562, 'learning_rate': 6.550065149844644e-07, 'epoch': 0.8689986970031072}\n",
      "{'loss': 1.5012, 'grad_norm': 36.329010009765625, 'learning_rate': 6.49994988473489e-07, 'epoch': 0.8700010023053022}\n",
      "{'loss': 1.6555, 'grad_norm': 18.25803565979004, 'learning_rate': 6.449834619625138e-07, 'epoch': 0.8710033076074972}\n",
      "{'loss': 1.4419, 'grad_norm': 16.081790924072266, 'learning_rate': 6.399719354515386e-07, 'epoch': 0.8720056129096923}\n",
      "{'loss': 1.2826, 'grad_norm': 9.629546165466309, 'learning_rate': 6.349604089405634e-07, 'epoch': 0.8730079182118874}\n",
      "{'loss': 1.3522, 'grad_norm': 14.218725204467773, 'learning_rate': 6.299488824295881e-07, 'epoch': 0.8740102235140824}\n",
      "{'loss': 1.4783, 'grad_norm': 8.819851875305176, 'learning_rate': 6.249373559186129e-07, 'epoch': 0.8750125288162774}\n",
      "{'loss': 0.8409, 'grad_norm': 14.378384590148926, 'learning_rate': 6.199258294076377e-07, 'epoch': 0.8760148341184725}\n",
      "{'loss': 1.9368, 'grad_norm': 20.284717559814453, 'learning_rate': 6.149143028966624e-07, 'epoch': 0.8770171394206675}\n",
      "{'loss': 1.4918, 'grad_norm': 14.617264747619629, 'learning_rate': 6.099027763856871e-07, 'epoch': 0.8780194447228625}\n",
      "{'loss': 1.21, 'grad_norm': 17.239702224731445, 'learning_rate': 6.048912498747119e-07, 'epoch': 0.8790217500250577}\n",
      "{'loss': 2.0356, 'grad_norm': 12.458688735961914, 'learning_rate': 5.998797233637366e-07, 'epoch': 0.8800240553272527}\n",
      "{'loss': 0.9348, 'grad_norm': 42.75493621826172, 'learning_rate': 5.948681968527614e-07, 'epoch': 0.8810263606294477}\n",
      "{'loss': 0.9931, 'grad_norm': 26.230424880981445, 'learning_rate': 5.898566703417862e-07, 'epoch': 0.8820286659316428}\n",
      "{'loss': 0.9797, 'grad_norm': 14.464577674865723, 'learning_rate': 5.84845143830811e-07, 'epoch': 0.8830309712338378}\n",
      "{'loss': 1.0959, 'grad_norm': 20.216079711914062, 'learning_rate': 5.798336173198356e-07, 'epoch': 0.8840332765360329}\n",
      "{'loss': 1.7282, 'grad_norm': 12.79511547088623, 'learning_rate': 5.748220908088604e-07, 'epoch': 0.885035581838228}\n",
      "{'loss': 1.7286, 'grad_norm': 19.736520767211914, 'learning_rate': 5.698105642978852e-07, 'epoch': 0.886037887140423}\n",
      "{'loss': 1.5785, 'grad_norm': 13.997295379638672, 'learning_rate': 5.6479903778691e-07, 'epoch': 0.887040192442618}\n",
      "{'loss': 1.2511, 'grad_norm': 16.01488494873047, 'learning_rate': 5.597875112759347e-07, 'epoch': 0.888042497744813}\n",
      "{'loss': 1.33, 'grad_norm': 9.06913948059082, 'learning_rate': 5.547759847649595e-07, 'epoch': 0.8890448030470082}\n",
      "{'loss': 1.669, 'grad_norm': 22.59709358215332, 'learning_rate': 5.497644582539841e-07, 'epoch': 0.8900471083492032}\n",
      "{'loss': 1.9943, 'grad_norm': 8.797858238220215, 'learning_rate': 5.44752931743009e-07, 'epoch': 0.8910494136513982}\n",
      "{'loss': 1.4047, 'grad_norm': 8.764328002929688, 'learning_rate': 5.397414052320337e-07, 'epoch': 0.8920517189535933}\n",
      "{'loss': 1.6802, 'grad_norm': 11.847074508666992, 'learning_rate': 5.347298787210585e-07, 'epoch': 0.8930540242557883}\n",
      "{'loss': 1.2318, 'grad_norm': 9.57656192779541, 'learning_rate': 5.297183522100832e-07, 'epoch': 0.8940563295579833}\n",
      "{'loss': 1.3784, 'grad_norm': 14.19567584991455, 'learning_rate': 5.24706825699108e-07, 'epoch': 0.8950586348601784}\n",
      "{'loss': 1.3721, 'grad_norm': 37.42416000366211, 'learning_rate': 5.196952991881328e-07, 'epoch': 0.8960609401623735}\n",
      "{'loss': 1.5517, 'grad_norm': 9.524598121643066, 'learning_rate': 5.146837726771575e-07, 'epoch': 0.8970632454645685}\n",
      "{'loss': 1.8369, 'grad_norm': 18.99003028869629, 'learning_rate': 5.096722461661822e-07, 'epoch': 0.8980655507667635}\n",
      "{'loss': 1.9071, 'grad_norm': 11.890237808227539, 'learning_rate': 5.04660719655207e-07, 'epoch': 0.8990678560689586}\n",
      "{'loss': 1.4079, 'grad_norm': 18.523170471191406, 'learning_rate': 4.996491931442318e-07, 'epoch': 0.9000701613711537}\n",
      "{'loss': 1.1527, 'grad_norm': 23.53154754638672, 'learning_rate': 4.946376666332566e-07, 'epoch': 0.9010724666733487}\n",
      "{'loss': 1.6665, 'grad_norm': 22.828598022460938, 'learning_rate': 4.896261401222813e-07, 'epoch': 0.9020747719755438}\n",
      "{'loss': 1.2306, 'grad_norm': 9.165964126586914, 'learning_rate': 4.846146136113061e-07, 'epoch': 0.9030770772777388}\n",
      "{'loss': 1.2961, 'grad_norm': 23.39436912536621, 'learning_rate': 4.796030871003307e-07, 'epoch': 0.9040793825799338}\n",
      "{'loss': 0.7851, 'grad_norm': 15.570540428161621, 'learning_rate': 4.745915605893556e-07, 'epoch': 0.905081687882129}\n",
      "{'loss': 1.6764, 'grad_norm': 18.02048683166504, 'learning_rate': 4.695800340783803e-07, 'epoch': 0.906083993184324}\n",
      "{'loss': 1.5466, 'grad_norm': 19.25725555419922, 'learning_rate': 4.645685075674051e-07, 'epoch': 0.907086298486519}\n",
      "{'loss': 1.1668, 'grad_norm': 9.315505027770996, 'learning_rate': 4.595569810564298e-07, 'epoch': 0.908088603788714}\n",
      "{'loss': 1.6973, 'grad_norm': 17.1215763092041, 'learning_rate': 4.5454545454545457e-07, 'epoch': 0.9090909090909091}\n",
      "{'loss': 1.2923, 'grad_norm': 24.594697952270508, 'learning_rate': 4.495339280344793e-07, 'epoch': 0.9100932143931041}\n",
      "{'loss': 1.7821, 'grad_norm': 10.683162689208984, 'learning_rate': 4.445224015235041e-07, 'epoch': 0.9110955196952992}\n",
      "{'loss': 1.5091, 'grad_norm': 10.927135467529297, 'learning_rate': 4.3951087501252883e-07, 'epoch': 0.9120978249974943}\n",
      "{'loss': 1.3559, 'grad_norm': 22.66999053955078, 'learning_rate': 4.344993485015536e-07, 'epoch': 0.9131001302996893}\n",
      "{'loss': 1.0656, 'grad_norm': 15.956208229064941, 'learning_rate': 4.2948782199057835e-07, 'epoch': 0.9141024356018843}\n",
      "{'loss': 1.9894, 'grad_norm': 17.465587615966797, 'learning_rate': 4.2447629547960314e-07, 'epoch': 0.9151047409040793}\n",
      "{'loss': 1.0531, 'grad_norm': 35.77566146850586, 'learning_rate': 4.1946476896862787e-07, 'epoch': 0.9161070462062745}\n",
      "{'loss': 1.8306, 'grad_norm': 13.967841148376465, 'learning_rate': 4.1445324245765266e-07, 'epoch': 0.9171093515084695}\n",
      "{'loss': 1.4576, 'grad_norm': 17.80878448486328, 'learning_rate': 4.0944171594667734e-07, 'epoch': 0.9181116568106645}\n",
      "{'loss': 1.424, 'grad_norm': 16.142507553100586, 'learning_rate': 4.044301894357022e-07, 'epoch': 0.9191139621128596}\n",
      "{'loss': 1.5165, 'grad_norm': 10.077981948852539, 'learning_rate': 3.9941866292472686e-07, 'epoch': 0.9201162674150546}\n",
      "{'loss': 1.8686, 'grad_norm': 7.7627692222595215, 'learning_rate': 3.9440713641375165e-07, 'epoch': 0.9211185727172497}\n",
      "{'loss': 1.1804, 'grad_norm': 34.93126678466797, 'learning_rate': 3.893956099027764e-07, 'epoch': 0.9221208780194448}\n",
      "{'loss': 0.864, 'grad_norm': 9.968040466308594, 'learning_rate': 3.8438408339180117e-07, 'epoch': 0.9231231833216398}\n",
      "{'loss': 1.8717, 'grad_norm': 15.875228881835938, 'learning_rate': 3.793725568808259e-07, 'epoch': 0.9241254886238348}\n",
      "{'loss': 2.0491, 'grad_norm': 20.21355438232422, 'learning_rate': 3.743610303698507e-07, 'epoch': 0.9251277939260298}\n",
      "{'loss': 1.4993, 'grad_norm': 21.989925384521484, 'learning_rate': 3.693495038588754e-07, 'epoch': 0.9261300992282249}\n",
      "{'loss': 1.5336, 'grad_norm': 20.211231231689453, 'learning_rate': 3.643379773479002e-07, 'epoch': 0.92713240453042}\n",
      "{'loss': 1.4553, 'grad_norm': 12.1589994430542, 'learning_rate': 3.5932645083692495e-07, 'epoch': 0.928134709832615}\n",
      "{'loss': 1.2405, 'grad_norm': 15.6588134765625, 'learning_rate': 3.5431492432594974e-07, 'epoch': 0.9291370151348101}\n",
      "{'loss': 2.3353, 'grad_norm': 13.030010223388672, 'learning_rate': 3.493033978149744e-07, 'epoch': 0.9301393204370051}\n",
      "{'loss': 1.856, 'grad_norm': 13.25198745727539, 'learning_rate': 3.442918713039992e-07, 'epoch': 0.9311416257392001}\n",
      "{'loss': 1.2909, 'grad_norm': 32.573123931884766, 'learning_rate': 3.3928034479302394e-07, 'epoch': 0.9321439310413953}\n",
      "{'loss': 1.0764, 'grad_norm': 19.710147857666016, 'learning_rate': 3.342688182820487e-07, 'epoch': 0.9331462363435903}\n",
      "{'loss': 1.5652, 'grad_norm': 7.863669395446777, 'learning_rate': 3.2925729177107346e-07, 'epoch': 0.9341485416457853}\n",
      "{'loss': 1.3644, 'grad_norm': 21.034048080444336, 'learning_rate': 3.2424576526009825e-07, 'epoch': 0.9351508469479803}\n",
      "{'loss': 1.8308, 'grad_norm': 13.991098403930664, 'learning_rate': 3.1923423874912303e-07, 'epoch': 0.9361531522501754}\n",
      "{'loss': 1.4668, 'grad_norm': 0.0, 'learning_rate': 3.1422271223814777e-07, 'epoch': 0.9371554575523704}\n",
      "{'loss': 1.9272, 'grad_norm': 12.631057739257812, 'learning_rate': 3.092111857271725e-07, 'epoch': 0.9381577628545655}\n",
      "{'loss': 0.8804, 'grad_norm': 8.84423828125, 'learning_rate': 3.041996592161973e-07, 'epoch': 0.9391600681567606}\n",
      "{'loss': 1.7708, 'grad_norm': 10.688316345214844, 'learning_rate': 2.99188132705222e-07, 'epoch': 0.9401623734589556}\n",
      "{'loss': 1.4006, 'grad_norm': 19.28904914855957, 'learning_rate': 2.941766061942468e-07, 'epoch': 0.9411646787611506}\n",
      "{'loss': 1.4423, 'grad_norm': 10.592156410217285, 'learning_rate': 2.8916507968327155e-07, 'epoch': 0.9421669840633456}\n",
      "{'loss': 1.0601, 'grad_norm': 27.53533935546875, 'learning_rate': 2.841535531722963e-07, 'epoch': 0.9431692893655408}\n",
      "{'loss': 0.8447, 'grad_norm': 10.286441802978516, 'learning_rate': 2.7914202666132107e-07, 'epoch': 0.9441715946677358}\n",
      "{'loss': 1.2183, 'grad_norm': 10.162599563598633, 'learning_rate': 2.741305001503458e-07, 'epoch': 0.9451738999699308}\n",
      "{'loss': 0.9463, 'grad_norm': 23.005840301513672, 'learning_rate': 2.691189736393706e-07, 'epoch': 0.9461762052721259}\n",
      "{'loss': 1.1954, 'grad_norm': 10.845365524291992, 'learning_rate': 2.641074471283953e-07, 'epoch': 0.9471785105743209}\n",
      "{'loss': 1.5636, 'grad_norm': 15.500844955444336, 'learning_rate': 2.5909592061742006e-07, 'epoch': 0.948180815876516}\n",
      "{'loss': 1.3056, 'grad_norm': 22.193641662597656, 'learning_rate': 2.5408439410644484e-07, 'epoch': 0.9491831211787111}\n",
      "{'loss': 1.4525, 'grad_norm': 36.67418670654297, 'learning_rate': 2.490728675954696e-07, 'epoch': 0.9501854264809061}\n",
      "{'loss': 1.9476, 'grad_norm': 11.784167289733887, 'learning_rate': 2.4406134108449437e-07, 'epoch': 0.9511877317831011}\n",
      "{'loss': 1.3412, 'grad_norm': 12.11324691772461, 'learning_rate': 2.390498145735191e-07, 'epoch': 0.9521900370852961}\n",
      "{'loss': 1.311, 'grad_norm': 9.882229804992676, 'learning_rate': 2.3403828806254386e-07, 'epoch': 0.9531923423874912}\n",
      "{'loss': 1.274, 'grad_norm': 10.551224708557129, 'learning_rate': 2.2902676155156862e-07, 'epoch': 0.9541946476896863}\n",
      "{'loss': 1.4542, 'grad_norm': 9.57159423828125, 'learning_rate': 2.2401523504059338e-07, 'epoch': 0.9551969529918813}\n",
      "{'loss': 1.6321, 'grad_norm': 13.265791893005371, 'learning_rate': 2.1900370852961812e-07, 'epoch': 0.9561992582940764}\n",
      "{'loss': 1.1775, 'grad_norm': 9.96820068359375, 'learning_rate': 2.1399218201864288e-07, 'epoch': 0.9572015635962714}\n",
      "{'loss': 1.5884, 'grad_norm': 14.802139282226562, 'learning_rate': 2.0898065550766764e-07, 'epoch': 0.9582038688984664}\n",
      "{'loss': 1.8111, 'grad_norm': 24.58037567138672, 'learning_rate': 2.039691289966924e-07, 'epoch': 0.9592061742006616}\n",
      "{'loss': 1.7839, 'grad_norm': 10.34305191040039, 'learning_rate': 1.9895760248571716e-07, 'epoch': 0.9602084795028566}\n",
      "{'loss': 1.4396, 'grad_norm': 13.059171676635742, 'learning_rate': 1.9394607597474192e-07, 'epoch': 0.9612107848050516}\n",
      "{'loss': 1.499, 'grad_norm': 24.834171295166016, 'learning_rate': 1.8893454946376665e-07, 'epoch': 0.9622130901072466}\n",
      "{'loss': 1.0358, 'grad_norm': 17.679136276245117, 'learning_rate': 1.8392302295279142e-07, 'epoch': 0.9632153954094417}\n",
      "{'loss': 1.421, 'grad_norm': 21.146686553955078, 'learning_rate': 1.7891149644181618e-07, 'epoch': 0.9642177007116368}\n",
      "{'loss': 1.9053, 'grad_norm': 16.54266357421875, 'learning_rate': 1.7389996993084094e-07, 'epoch': 0.9652200060138318}\n",
      "{'loss': 1.6074, 'grad_norm': 10.528131484985352, 'learning_rate': 1.688884434198657e-07, 'epoch': 0.9662223113160269}\n",
      "{'loss': 1.2196, 'grad_norm': 25.130704879760742, 'learning_rate': 1.6387691690889046e-07, 'epoch': 0.9672246166182219}\n",
      "{'loss': 1.4648, 'grad_norm': 20.496782302856445, 'learning_rate': 1.588653903979152e-07, 'epoch': 0.9682269219204169}\n",
      "{'loss': 1.2924, 'grad_norm': 29.191164016723633, 'learning_rate': 1.5385386388693998e-07, 'epoch': 0.969229227222612}\n",
      "{'loss': 2.2046, 'grad_norm': 9.373769760131836, 'learning_rate': 1.4884233737596474e-07, 'epoch': 0.9702315325248071}\n",
      "{'loss': 0.8545, 'grad_norm': 16.289718627929688, 'learning_rate': 1.4383081086498947e-07, 'epoch': 0.9712338378270021}\n",
      "{'loss': 1.7376, 'grad_norm': 15.291837692260742, 'learning_rate': 1.3881928435401424e-07, 'epoch': 0.9722361431291972}\n",
      "{'loss': 1.231, 'grad_norm': 14.618189811706543, 'learning_rate': 1.33807757843039e-07, 'epoch': 0.9732384484313922}\n",
      "{'loss': 1.1367, 'grad_norm': 8.378745079040527, 'learning_rate': 1.2879623133206376e-07, 'epoch': 0.9742407537335872}\n",
      "{'loss': 1.6495, 'grad_norm': 21.910816192626953, 'learning_rate': 1.2378470482108852e-07, 'epoch': 0.9752430590357823}\n",
      "{'loss': 1.6157, 'grad_norm': 11.522786140441895, 'learning_rate': 1.1877317831011327e-07, 'epoch': 0.9762453643379774}\n",
      "{'loss': 1.5103, 'grad_norm': 10.447078704833984, 'learning_rate': 1.1376165179913803e-07, 'epoch': 0.9772476696401724}\n",
      "{'loss': 1.3257, 'grad_norm': 0.0, 'learning_rate': 1.0875012528816277e-07, 'epoch': 0.9782499749423674}\n",
      "{'loss': 1.304, 'grad_norm': 11.888004302978516, 'learning_rate': 1.0373859877718753e-07, 'epoch': 0.9792522802445625}\n",
      "{'loss': 1.2736, 'grad_norm': 9.41538143157959, 'learning_rate': 9.87270722662123e-08, 'epoch': 0.9802545855467576}\n",
      "{'loss': 1.6936, 'grad_norm': 10.552421569824219, 'learning_rate': 9.371554575523704e-08, 'epoch': 0.9812568908489526}\n",
      "{'loss': 1.5145, 'grad_norm': 35.98835754394531, 'learning_rate': 8.87040192442618e-08, 'epoch': 0.9822591961511477}\n",
      "{'loss': 1.093, 'grad_norm': 19.431032180786133, 'learning_rate': 8.369249273328656e-08, 'epoch': 0.9832615014533427}\n",
      "{'loss': 1.7592, 'grad_norm': 27.163745880126953, 'learning_rate': 7.868096622231131e-08, 'epoch': 0.9842638067555377}\n",
      "{'loss': 1.5431, 'grad_norm': 15.129636764526367, 'learning_rate': 7.366943971133609e-08, 'epoch': 0.9852661120577327}\n",
      "{'loss': 1.0044, 'grad_norm': 22.16148567199707, 'learning_rate': 6.865791320036083e-08, 'epoch': 0.9862684173599279}\n",
      "{'loss': 1.4407, 'grad_norm': 10.391447067260742, 'learning_rate': 6.36463866893856e-08, 'epoch': 0.9872707226621229}\n",
      "{'loss': 0.5951, 'grad_norm': 0.0, 'learning_rate': 5.863486017841035e-08, 'epoch': 0.9882730279643179}\n",
      "{'loss': 2.0284, 'grad_norm': 12.515835762023926, 'learning_rate': 5.36233336674351e-08, 'epoch': 0.989275333266513}\n",
      "{'loss': 1.0092, 'grad_norm': 19.172040939331055, 'learning_rate': 4.861180715645986e-08, 'epoch': 0.990277638568708}\n",
      "{'loss': 1.5086, 'grad_norm': 8.610652923583984, 'learning_rate': 4.360028064548462e-08, 'epoch': 0.9912799438709031}\n",
      "{'loss': 0.8014, 'grad_norm': 14.175853729248047, 'learning_rate': 3.858875413450937e-08, 'epoch': 0.9922822491730982}\n",
      "{'loss': 1.5487, 'grad_norm': 12.16171646118164, 'learning_rate': 3.357722762353413e-08, 'epoch': 0.9932845544752932}\n",
      "{'loss': 1.3714, 'grad_norm': 19.756925582885742, 'learning_rate': 2.856570111255889e-08, 'epoch': 0.9942868597774882}\n",
      "{'loss': 1.783, 'grad_norm': 18.67925262451172, 'learning_rate': 2.3554174601583647e-08, 'epoch': 0.9952891650796832}\n",
      "{'loss': 1.2904, 'grad_norm': 16.25937271118164, 'learning_rate': 1.85426480906084e-08, 'epoch': 0.9962914703818784}\n",
      "{'loss': 1.4767, 'grad_norm': 35.52646255493164, 'learning_rate': 1.3531121579633159e-08, 'epoch': 0.9972937756840734}\n",
      "{'loss': 1.6868, 'grad_norm': 13.076486587524414, 'learning_rate': 8.519595068657914e-09, 'epoch': 0.9982960809862684}\n",
      "{'loss': 1.2808, 'grad_norm': 17.052818298339844, 'learning_rate': 3.5080685576826705e-09, 'epoch': 0.9992983862884635}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6012395ebb4a2bb8fc8f55633f9069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_runtime': 910.8783, 'eval_samples_per_second': 2.729, 'eval_steps_per_second': 2.729, 'epoch': 1.0}\n",
      "{'train_runtime': 24446.6671, 'train_samples_per_second': 0.816, 'train_steps_per_second': 0.408, 'train_loss': 1.614406400062857, 'epoch': 1.0}\n",
      "[COMPLETE] Elapsed: 24446.97s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7fe2dff7a5d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train the TinyLlama model with the quest data\n",
    "tinyllama_trainer: Trainer = tinyllama_model.tokenize_and_train(quest_set)\n",
    "tinyllama_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26aa6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.4469, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tinyllama_model.model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = tinyllama_model.tokenizer(\n",
    "        \"I am thou, thou art i\", return_tensors=\"pt\", padding=True\n",
    "    ).to(tinyllama_model.model.device)\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].clone()\n",
    "    outputs = tinyllama_model.model(**inputs)\n",
    "    print(outputs.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89203fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
