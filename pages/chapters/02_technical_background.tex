\clearpage

\chapter{Technical Background}

\section{Large Language Models}
\subsection{GPT-2}
\subsection{Llama 3.2}
\subsection{TinyLlama}

\section{Parameter-Efficient Fine-Tuning (PEFT)}
\subsection{LoRA: Low-Rank Adaptation of LLMs}

\section{Model Quantization}
\subsection{Quantization Techniques (e.g., 4-bit, 8-bit)}
\subsection{Benefits and Trade-offs}

\section{Transformers and Text Generation}
\subsection{Causal Language Modelling}
\subsection{Tokenization and Prompt Formats}

\newpage
