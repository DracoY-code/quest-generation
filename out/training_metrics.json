{
  "gpt2": {
    "train_losses": [
      2.6818,
      2.6673,
      2.6932,
      2.6332,
      2.6388,
      2.6266,
      2.622,
      2.5711,
      2.5789,
      2.4868
    ],
    "eval_losses": [
      2.1573195457458496
    ],
    "learning_rates": [
      3e-06,
      6e-06,
      9e-06,
      1.2e-05,
      1.5e-05,
      1.8e-05,
      2.1e-05,
      2.4e-05,
      2.7000000000000002e-05,
      3e-05
    ],
    "grad_norms": [
      0.3146290183067322,
      0.45661231875419617,
      0.27802565693855286,
      0.36798006296157837,
      0.4167405962944031,
      0.4057275354862213,
      0.3772679269313812,
      0.46999871730804443,
      0.6387847065925598,
      0.6707265377044678
    ],
    "global_steps": [
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      102,
      102
    ],
    "epochs": [
      0.09803921568627451,
      0.19607843137254902,
      0.29411764705882354,
      0.39215686274509803,
      0.49019607843137253,
      0.5882352941176471,
      0.6862745098039216,
      0.7843137254901961,
      0.8823529411764706,
      0.9803921568627451,
      1.0
    ]
  },
  "gpt2-medium": {
    "train_losses": [
      2.3256,
      2.3187,
      2.3665,
      2.3241,
      2.2984,
      2.2742,
      2.2795,
      2.237,
      2.2015,
      2.1188
    ],
    "eval_losses": [
      1.8825511932373047
    ],
    "learning_rates": [
      3e-06,
      6e-06,
      9e-06,
      1.2e-05,
      1.5e-05,
      1.8e-05,
      2.1e-05,
      2.4e-05,
      2.7000000000000002e-05,
      3e-05
    ],
    "grad_norms": [
      0.3069506287574768,
      0.2813541293144226,
      0.2306906282901764,
      0.2805655002593994,
      0.4793981909751892,
      0.3226276636123657,
      0.3588409125804901,
      0.394062876701355,
      0.436593234539032,
      0.48396816849708557
    ],
    "global_steps": [
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      102,
      102
    ],
    "epochs": [
      0.09803921568627451,
      0.19607843137254902,
      0.29411764705882354,
      0.39215686274509803,
      0.49019607843137253,
      0.5882352941176471,
      0.6862745098039216,
      0.7843137254901961,
      0.8823529411764706,
      0.9803921568627451,
      1.0
    ]
  },
  "gpt2-large": {
    "train_losses": [
      2.0181,
      2.0203,
      2.0433,
      1.9901,
      1.9935,
      1.959,
      1.9214,
      1.8726,
      1.8076,
      1.6781
    ],
    "eval_losses": [
      1.5231956243515015
    ],
    "learning_rates": [
      3e-06,
      6e-06,
      9e-06,
      1.2e-05,
      1.5e-05,
      1.8e-05,
      2.1e-05,
      2.4e-05,
      2.7000000000000002e-05,
      3e-05
    ],
    "grad_norms": [
      0.2274000644683838,
      0.23313337564468384,
      0.23457348346710205,
      0.27480176091194153,
      0.30306562781333923,
      0.3335680365562439,
      0.3292894959449768,
      0.3862982392311096,
      0.43068403005599976,
      0.4557386338710785
    ],
    "global_steps": [
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      102,
      102
    ],
    "epochs": [
      0.09803921568627451,
      0.19607843137254902,
      0.29411764705882354,
      0.39215686274509803,
      0.49019607843137253,
      0.5882352941176471,
      0.6862745098039216,
      0.7843137254901961,
      0.8823529411764706,
      0.9803921568627451,
      1.0
    ]
  },
  "llama-3.2-1b-instruct": {
    "train_losses": [
      2.4511,
      2.4452,
      2.4754,
      2.3911,
      2.3868,
      2.3196,
      2.2332,
      2.1189,
      1.9977,
      1.8126
    ],
    "eval_losses": [
      1.6758792400360107
    ],
    "learning_rates": [
      3e-06,
      6e-06,
      9e-06,
      1.2e-05,
      1.5e-05,
      1.8e-05,
      2.1e-05,
      2.4e-05,
      2.7000000000000002e-05,
      3e-05
    ],
    "grad_norms": [
      1.0357692241668701,
      1.1105165481567383,
      1.0999761819839478,
      1.293423056602478,
      1.5135807991027832,
      1.837256908416748,
      1.4708731174468994,
      1.4291259050369263,
      1.7081077098846436,
      1.9814156293869019
    ],
    "global_steps": [
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      102,
      102
    ],
    "epochs": [
      0.09803921568627451,
      0.19607843137254902,
      0.29411764705882354,
      0.39215686274509803,
      0.49019607843137253,
      0.5882352941176471,
      0.6862745098039216,
      0.7843137254901961,
      0.8823529411764706,
      0.9803921568627451,
      1.0
    ]
  },
  "tinyllama-1.1b-chat": {
    "train_losses": [
      2.0596,
      2.0551,
      2.0746,
      1.9927,
      1.9256,
      1.8283,
      1.7111,
      1.5746,
      1.465,
      1.3555
    ],
    "eval_losses": [
      1.2684321403503418
    ],
    "learning_rates": [
      3e-06,
      6e-06,
      9e-06,
      1.2e-05,
      1.5e-05,
      1.8e-05,
      2.1e-05,
      2.4e-05,
      2.7000000000000002e-05,
      3e-05
    ],
    "grad_norms": [
      2.545828342437744,
      2.529114246368408,
      2.4147751331329346,
      2.2650671005249023,
      2.5697553157806396,
      2.09818172454834,
      1.3390394449234009,
      1.146890640258789,
      1.0917110443115234,
      1.0018268823623657
    ],
    "global_steps": [
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90,
      100,
      102,
      102
    ],
    "epochs": [
      0.09803921568627451,
      0.19607843137254902,
      0.29411764705882354,
      0.39215686274509803,
      0.49019607843137253,
      0.5882352941176471,
      0.6862745098039216,
      0.7843137254901961,
      0.8823529411764706,
      0.9803921568627451,
      1.0
    ]
  }
}