{
  "gpt2": {
    "train_losses": [
      3.7566,
      3.7501,
      3.7363
    ],
    "eval_losses": [
      3.451026678085327,
      3.4508025646209717,
      3.450542688369751
    ],
    "learning_rates": [
      1e-07,
      2e-07,
      3e-07
    ],
    "grad_norms": [
      0.5197933316230774,
      0.5473610758781433,
      0.4967455565929413
    ],
    "global_steps": [
      10,
      12,
      20,
      24,
      30,
      33,
      33
    ],
    "epochs": [
      0.8695652173913043,
      1.0,
      1.6956521739130435,
      2.0,
      2.5217391304347827,
      2.782608695652174
    ]
  },
  "gpt2-medium": {
    "train_losses": [
      3.3696,
      3.3752,
      3.3692
    ],
    "eval_losses": [
      3.173976182937622,
      3.1736626625061035,
      3.173295736312866
    ],
    "learning_rates": [
      1e-07,
      2e-07,
      3e-07
    ],
    "grad_norms": [
      0.3051488697528839,
      0.42861658334732056,
      0.36301547288894653
    ],
    "global_steps": [
      10,
      12,
      20,
      24,
      30,
      33,
      33
    ],
    "epochs": [
      0.8695652173913043,
      1.0,
      1.6956521739130435,
      2.0,
      2.5217391304347827,
      2.782608695652174
    ]
  },
  "gpt2-large": {
    "train_losses": [
      3.1362,
      3.1325,
      3.1103
    ],
    "eval_losses": [
      3.0677154064178467,
      3.067249059677124,
      3.066693067550659
    ],
    "learning_rates": [
      1e-07,
      2e-07,
      3e-07
    ],
    "grad_norms": [
      0.3436407148838043,
      0.3017879128456116,
      0.33828988671302795
    ],
    "global_steps": [
      10,
      12,
      20,
      24,
      30,
      33,
      33
    ],
    "epochs": [
      0.8695652173913043,
      1.0,
      1.6956521739130435,
      2.0,
      2.5217391304347827,
      2.782608695652174
    ]
  },
  "llama-3.2-1b-instruct": {
    "train_losses": [
      3.1957,
      3.1895,
      3.1614
    ],
    "eval_losses": [
      3.158547878265381,
      3.1567068099975586,
      3.154496192932129
    ],
    "learning_rates": [
      1e-07,
      2e-07,
      3e-07
    ],
    "grad_norms": [
      1.0860451459884644,
      1.2568928003311157,
      1.148056983947754
    ],
    "global_steps": [
      10,
      12,
      20,
      24,
      30,
      33,
      33
    ],
    "epochs": [
      0.8695652173913043,
      1.0,
      1.6956521739130435,
      2.0,
      2.5217391304347827,
      2.782608695652174
    ]
  },
  "tinyllama-1.1b-chat": {
    "train_losses": [
      2.5607,
      2.5473,
      2.5484
    ],
    "eval_losses": [
      2.468454122543335,
      2.4674222469329834,
      2.466186761856079
    ],
    "learning_rates": [
      1e-07,
      2e-07,
      3e-07
    ],
    "grad_norms": [
      0.7706165909767151,
      0.831169605255127,
      0.7596113085746765
    ],
    "global_steps": [
      10,
      12,
      20,
      24,
      30,
      33,
      33
    ],
    "epochs": [
      0.8695652173913043,
      1.0,
      1.6956521739130435,
      2.0,
      2.5217391304347827,
      2.782608695652174
    ]
  }
}